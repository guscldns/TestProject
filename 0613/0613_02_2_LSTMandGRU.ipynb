{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/0613/0613_02_2_LSTMandGRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "V3LU-1lPPBnv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uAWEUX9TPBGl",
        "outputId": "97922058-e3bf-444a-e296-4a8674a9f7ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Dense"
      ],
      "metadata": {
        "id": "EUxPPVtB3KdJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Keras로 LSTM 구현하기"
      ],
      "metadata": {
        "id": "wZ3XZUuSUNLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/api/layers/recurrent_layers/lstm/"
      ],
      "metadata": {
        "id": "fu6On_amU2jt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사실 실제로 SimpleRNN이 사용되는 경우는 거의 없습니다. 이보다는 LSTM이나 GRU을 주로 사용하는데, 이번에는 임의의 입력에 대해서 LSTM을 사용할 경우를 보겠습니다."
      ],
      "metadata": {
        "id": "Y8jXe-GJTsFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 품사 맞추는 문제\n",
        "John = [1,0,0,0]\n",
        "loves = [0,1,0,0]\n",
        "Jane = [0,0,1,0]\n",
        "Alex = [0,0,0,1]\n",
        "\n",
        "train_X = np.array([\n",
        "    [ John, loves, Jane ],\n",
        "    [ Jane, loves, Alex ]\n",
        "]).astype(np.float32)\n",
        "\n",
        "S = [0] # subject\n",
        "V = [1] # verb\n",
        "O = [2] # object\n",
        "\n",
        "idx2tag = ['S', 'V', 'O']\n",
        "\n",
        "train_Y = np.array([[S, V, O], [S, V, O]]).astype(np.float32)\n",
        "\n",
        "print(\"train_y\", train_Y)\n",
        "print(\"train_X의 shape\", train_X.shape)\n",
        "print(\"train_Y의 shape\", train_Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFTk_0UQ4DEj",
        "outputId": "ba7b69c4-12fd-452f-9ec3-90ca3714c735"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_y [[[0.]\n",
            "  [1.]\n",
            "  [2.]]\n",
            "\n",
            " [[0.]\n",
            "  [1.]\n",
            "  [2.]]]\n",
            "train_X의 shape (2, 3, 4)\n",
            "train_Y의 shape (2, 3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13luTXy9ahgy",
        "outputId": "193d6ff9-c295-49c5-dc8c-c62d17484365"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = LSTM(10)\n",
        "output = lstm(train_X)"
      ],
      "metadata": {
        "id": "Z7vPbQwSan-R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output # 마지막 시점의 hidden state 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOJKvaJBaqX4",
        "outputId": "c0a1c200-a1ac-42eb-bad4-93c2688d1902"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
              "array([[ 0.00882178, -0.07148983,  0.0270995 ,  0.06419743,  0.00447996,\n",
              "        -0.04266049, -0.09275564, -0.06368592,  0.08546617, -0.1283861 ],\n",
              "       [-0.09605565, -0.06962553,  0.0360249 , -0.02886875,  0.04161034,\n",
              "         0.06923639, -0.09273029, -0.07247909,  0.00335787, -0.15516956]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = LSTM(10, return_sequences = True)\n",
        "# return_sequences = True: 전체 시점 hidden state 기억\n",
        "output = lstm(train_X)"
      ],
      "metadata": {
        "id": "92nH30yKaz6x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output # 2 : 문장개수, 3: 문장 내 단어 개수 , 10 : 벡터크기\n",
        "# 모든 hidden state 기억"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCYnvKZka9nH",
        "outputId": "4885f8b1-059d-49c3-d41b-c585e311a894"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 10), dtype=float32, numpy=\n",
              "array([[[-0.08567462,  0.01310028,  0.07404231,  0.07413147,\n",
              "          0.03157669, -0.04797008, -0.01235444, -0.09060828,\n",
              "          0.02186766,  0.09455818],\n",
              "        [-0.12147957,  0.05490887, -0.00975332,  0.0514985 ,\n",
              "          0.07102291, -0.12763576,  0.07175852, -0.12585807,\n",
              "          0.02047815,  0.12104332],\n",
              "        [-0.10094232, -0.02099633, -0.07261018, -0.01461274,\n",
              "          0.09776165, -0.08455842,  0.09038998, -0.17359683,\n",
              "         -0.00709027,  0.03701221]],\n",
              "\n",
              "       [[ 0.01283624, -0.0566365 , -0.05810475, -0.03535709,\n",
              "          0.04424312,  0.00575065,  0.026756  , -0.08950444,\n",
              "         -0.04289158, -0.04234008],\n",
              "        [-0.07094418,  0.0069267 , -0.08463157, -0.01376065,\n",
              "          0.07221735, -0.08838222,  0.11074585, -0.13533238,\n",
              "         -0.03022134,  0.0549912 ],\n",
              "        [-0.05798961,  0.01057256, -0.13269782, -0.101689  ,\n",
              "          0.01003129, -0.0546943 ,  0.09848986, -0.18504518,\n",
              "         -0.02230441,  0.01970537]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = LSTM(10, return_sequences = True, return_state = True)\n",
        "# return_state = True : LSTM에 있는 hidden, cell state의 마지막 시점을 보여준다\n",
        "# (참고 : simple RNN에서는 Cell state가 없어서 hidden state만 출력해줬음)\n",
        "output = lstm(train_X)"
      ],
      "metadata": {
        "id": "tA4_2lfFbNFn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output\n",
        "# 1번째 : 전체 시점의 hidden state\n",
        "# 2번째 : output의 마지막 값과 모양이 같다 = 마지막 시점의 hidden state\n",
        "# 3번째 : 마지막 시점의 Cell state\n",
        "# 전체 t의 ht,  # 마지막 시점 ht, # 마지막 시점의 Ct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkb7IdgfbWXF",
        "outputId": "4d3beb31-239f-445b-c061-1fea1b948ec5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(2, 3, 10), dtype=float32, numpy=\n",
              " array([[[-0.10985142, -0.07429689, -0.07918032, -0.06295913,\n",
              "          -0.04264182, -0.01185398, -0.06610213,  0.07219309,\n",
              "          -0.02882399, -0.0522147 ],\n",
              "         [-0.00578104,  0.03338828, -0.10992517,  0.00506607,\n",
              "          -0.10579371,  0.04172195, -0.05331444, -0.01089991,\n",
              "           0.01014715,  0.04995363],\n",
              "         [-0.08640608,  0.08109606, -0.05255764,  0.04829006,\n",
              "          -0.05821335,  0.06525791, -0.11046748, -0.04840568,\n",
              "          -0.06078831, -0.03905934]],\n",
              " \n",
              "        [[-0.07460481,  0.05860521,  0.02743198,  0.03737866,\n",
              "          -0.00554104,  0.0335271 , -0.0683361 , -0.04420718,\n",
              "          -0.06454726, -0.07724275],\n",
              "         [ 0.00804293,  0.13052648, -0.04538567,  0.08557821,\n",
              "          -0.09587607,  0.06723301, -0.05096405, -0.08732398,\n",
              "          -0.02577588,  0.03248907],\n",
              "         [ 0.0538917 ,  0.12758343, -0.05072109,  0.02944586,\n",
              "          -0.03972085,  0.03893657, -0.10670094, -0.11267778,\n",
              "          -0.04459288, -0.00819369]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
              " array([[-0.08640608,  0.08109606, -0.05255764,  0.04829006, -0.05821335,\n",
              "          0.06525791, -0.11046748, -0.04840568, -0.06078831, -0.03905934],\n",
              "        [ 0.0538917 ,  0.12758343, -0.05072109,  0.02944586, -0.03972085,\n",
              "          0.03893657, -0.10670094, -0.11267778, -0.04459288, -0.00819369]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
              " array([[-0.19667017,  0.1657841 , -0.11250073,  0.09747592, -0.13920766,\n",
              "          0.11363998, -0.20117795, -0.11654446, -0.12320706, -0.0919081 ],\n",
              "        [ 0.11927102,  0.2192314 , -0.09109268,  0.0600151 , -0.08733916,\n",
              "          0.08529549, -0.19191211, -0.28382805, -0.08785157, -0.01799216]],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[0] # 전체 t의 ht , 2개 인건 문장이 2개라서"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP4DfsA4b5F8",
        "outputId": "552006c0-053b-47d9-ddd4-98a2ea3f2a5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 10), dtype=float32, numpy=\n",
              "array([[[-0.10985142, -0.07429689, -0.07918032, -0.06295913,\n",
              "         -0.04264182, -0.01185398, -0.06610213,  0.07219309,\n",
              "         -0.02882399, -0.0522147 ],\n",
              "        [-0.00578104,  0.03338828, -0.10992517,  0.00506607,\n",
              "         -0.10579371,  0.04172195, -0.05331444, -0.01089991,\n",
              "          0.01014715,  0.04995363],\n",
              "        [-0.08640608,  0.08109606, -0.05255764,  0.04829006,\n",
              "         -0.05821335,  0.06525791, -0.11046748, -0.04840568,\n",
              "         -0.06078831, -0.03905934]],\n",
              "\n",
              "       [[-0.07460481,  0.05860521,  0.02743198,  0.03737866,\n",
              "         -0.00554104,  0.0335271 , -0.0683361 , -0.04420718,\n",
              "         -0.06454726, -0.07724275],\n",
              "        [ 0.00804293,  0.13052648, -0.04538567,  0.08557821,\n",
              "         -0.09587607,  0.06723301, -0.05096405, -0.08732398,\n",
              "         -0.02577588,  0.03248907],\n",
              "        [ 0.0538917 ,  0.12758343, -0.05072109,  0.02944586,\n",
              "         -0.03972085,  0.03893657, -0.10670094, -0.11267778,\n",
              "         -0.04459288, -0.00819369]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[0][:, -1]"
      ],
      "metadata": {
        "id": "W6JLzRJpb5hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output[1] # 마지막 시점 ht"
      ],
      "metadata": {
        "id": "yhsA9_mwb9lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output[2] # 마지막 시점의 Ct"
      ],
      "metadata": {
        "id": "ljs5fw49cBez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3\n",
        "input_dim = 4\n",
        "sequence_length = 3\n",
        "learning_rate = 0.1\n",
        "\n",
        "\n",
        "lstm = LSTM(num_classes)\n",
        "output = lstm(train_X)\n",
        "\n",
        "print('hidden state : {}, shape: {}'.format(output, output.shape))"
      ],
      "metadata": {
        "id": "DIW2YsQnUTpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # return_sequences = True\n",
        "\n",
        "# lstm = LSTM(3, return_sequences=True, return_state=True)\n",
        "# whole_seq_output, final_memory_state, final_carry_state = lstm(train_X)\n",
        "\n",
        "# print('whole_seq_output: {}, shape: {}'.format(whole_seq_output, whole_seq_output.shape))\n",
        "# print('final_memory_state : {}, shape: {}'.format(final_memory_state, final_memory_state.shape))\n",
        "# print('final_carry_state : {}, shape: {}'.format(final_carry_state, final_carry_state.shape))\n",
        "# return_sequences = True\n",
        "\n",
        "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
        "whole_seq_output, final_hidden_state, final_cell_state = lstm(train_X)\n",
        "\n",
        "print('whole_seq_output: {}, shape: {}'.format(whole_seq_output, whole_seq_output.shape))\n",
        "print('final_hidden_state : {}, shape: {}'.format(final_hidden_state, final_hidden_state.shape))\n",
        "print('final_cell_state : {}, shape: {}'.format(final_cell_state, final_cell_state.shape))"
      ],
      "metadata": {
        "id": "eMRrjZxNUWpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wrDoWxneVeFG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential() #모델 호출\n",
        "model.add(\n",
        "    layers.LSTM(units= 5,\n",
        "                input_shape = (3,4),\n",
        "                return_sequences = True,\n",
        "                name='LSTM-1'))\n",
        "\n",
        "model.add(\n",
        "    layers.Dense(\n",
        "        units=3,\n",
        "        activation='softmax',\n",
        "        name='hidden-to-output')) # 출력을 위한 FFN\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer= 'adam',\n",
        "    metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q02WgSBMVeFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf7b1ad-4522-465f-861f-c78b5d7bd8d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.0693 - accuracy: 0.8333\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0635 - accuracy: 0.8333\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0577 - accuracy: 0.8333\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.0517 - accuracy: 0.8333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0455 - accuracy: 0.8333\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0392 - accuracy: 0.8333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0326 - accuracy: 0.8333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0259 - accuracy: 0.8333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0189 - accuracy: 0.8333\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0117 - accuracy: 0.8333\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0042 - accuracy: 0.8333\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9964 - accuracy: 0.8333\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9884 - accuracy: 0.8333\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9801 - accuracy: 0.8333\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9716 - accuracy: 0.8333\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9628 - accuracy: 0.8333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9537 - accuracy: 0.8333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9444 - accuracy: 0.8333\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9349 - accuracy: 0.8333\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9251 - accuracy: 0.8333\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9151 - accuracy: 0.8333\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9048 - accuracy: 0.8333\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8944 - accuracy: 0.8333\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8838 - accuracy: 0.8333\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8729 - accuracy: 0.8333\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8619 - accuracy: 0.8333\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8506 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8391 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8275 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8156 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8034 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7911 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7785 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7656 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7526 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7393 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7259 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7123 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6984 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6845 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6704 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6562 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6420 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6277 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6133 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5990 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5847 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5705 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5563 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5423 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5283 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5145 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5009 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4875 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4743 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4613 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4485 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4361 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4239 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4119 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4003 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3890 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3780 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3673 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3568 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3467 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3369 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3274 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3182 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3093 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3007 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2923 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2842 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2764 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2688 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2615 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2544 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2475 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2409 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2344 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2282 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2221 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2163 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2106 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2051 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1997 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1945 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1895 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1846 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1798 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1752 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1707 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1663 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1620 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1579 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1539 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1499 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1461 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1424 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1388 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcb1df62c90>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model.fit(train_X, train_Y, epochs= 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erlcuC6yVu3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85da9592-f9fd-40ea-b45f-32d0e06418f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.8940147  0.03449708 0.07148813]\n",
            " [0.04685312 0.9033953  0.04975158]\n",
            " [0.11443406 0.04352104 0.8420449 ]]\n",
            "[0 1 2]\n",
            "\tPrediction str:  SVO\n",
            "[[0.8195169  0.04282429 0.13765882]\n",
            " [0.03784835 0.90291107 0.05924062]\n",
            " [0.07242088 0.04501116 0.88256794]]\n",
            "[0 1 2]\n",
            "\tPrediction str:  SVO\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(train_X)\n",
        "for i, prediction in enumerate(predictions):\n",
        "  print(prediction)\n",
        "  print(np.argmax(prediction, axis=1))\n",
        "  result_str = [idx2tag[c] for c in np.argmax(prediction, axis=1) ]\n",
        "  print(\"\\tPrediction str: \", \"\".join(result_str))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgargDsAVu3i"
      },
      "source": [
        "모델을 이해하려면 weight 개수(W0\\~Wn)를 세어봐야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oPqHUNICVu3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b973d1f-5bae-43f8-f169-4f5fd03b16d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " LSTM-1 (LSTM)               (None, 3, 5)              200       \n",
            "                                                                 \n",
            " hidden-to-output (Dense)    (None, 3, 3)              18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 218\n",
            "Trainable params: 218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n",
        "# activation(LSTM에서는 activation이 계속 바뀌어서 함수를 따로 써주겠다)\n",
        "# ht = activation(Wx * Xt + Wh*h(t-1) + b)\n",
        "# 5*1 = activation(5*4 * 4*1)+ (5*5 * 5*1) + 5*1) # units= 5 줘서 5*1\n",
        "# param = 5*4 + 5*5 + 5*1  = 50 * activation = 50 * 4(activation가 시그모이드 3번 tanh가 1번이라 총 4번 = 4) = 200\n",
        "# RNN 보다 weight 개수가 4배다"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model_weight in model.weights:\n",
        "    print(model_weight.name, '=>', model_weight.shape)"
      ],
      "metadata": {
        "id": "UeeSNZ4oV1z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제1"
      ],
      "metadata": {
        "id": "s4yvLeLx4abv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(7, input_shape=(100,5)))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BATfHNX4aR0",
        "outputId": "a1a13406-38f5-4618-a6e8-1564d1990757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 7)                 364       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 364\n",
            "Trainable params: 364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- W_forget : (num_units + input_dim + 1) * num_units\n",
        "- W_input : (num_units + input_dim + 1) * num_units\n",
        "- W_output : (num_units + input_dim + 1) * num_units\n",
        "- W_cell : (num_units + input_dim + 1) * num_units"
      ],
      "metadata": {
        "id": "unV7265X-ZhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제2"
      ],
      "metadata": {
        "id": "fUApe9np4ktO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(5, input_shape = (2, 10)))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqHdlwGy4kll",
        "outputId": "12152ad2-7a3e-4e6f-8344-977526141131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 5)                 320       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 326\n",
            "Trainable params: 326\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- W_forget : (num_units + input_dim + 1) * num_units\n",
        "- W_input : (num_units + input_dim + 1) * num_units\n",
        "- W_output : (num_units + input_dim + 1) * num_units\n",
        "- W_cell : (num_units + input_dim + 1) * num_units"
      ],
      "metadata": {
        "id": "wgOMIFYm-da-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# weight 개수 카운팅"
      ],
      "metadata": {
        "id": "X9ioBYCi-efB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제3"
      ],
      "metadata": {
        "id": "piOmwqSq4aNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(5, input_shape = (2, 10), return_sequences=True))\n",
        "model.add(LSTM(7))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMFgSK9I4aHT",
        "outputId": "2ef9d32d-f7ed-4382-b515-796ba5652e18"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 2, 5)              320       \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 7)                 364       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 692\n",
            "Trainable params: 692\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 레이어의 파라미터 개수\n",
        "# ht = activation(Wx * Xt + Wh*h(t-1) + b)\n",
        "# 5*1 = 4*(((5*10) *(10*1)) + ((5*5) * (5*1)) + (5*1)) = 50+30 = 80 *4 = 320\n",
        "# output : none, 2, 5"
      ],
      "metadata": {
        "id": "3vqoSLcBV2OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두번째 레이어의 파라미터 개수\n",
        "# ht = activation(Wx * Xt + Wh*h(t-1) + b)\n",
        "# 7*1 = 4*(((7*5) *(5*1)) + ((7*7) * (7*1)) + (7*1)) (35+49+7) *4 = 364\n",
        "# output : none, 7 # return true아니라서 7까지만 출력"
      ],
      "metadata": {
        "id": "8wH6uSKU5aac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 세번째 레이어의 파라미터 개수\n",
        "# print((activation 없음)>>  (Wx * x) + b >> ((1*7) *(7*1)) + (1*1) >> =7+1 =8\n",
        "# output : none, 1"
      ],
      "metadata": {
        "id": "GshfgJTC5j3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Keras로 GRU 구현하기"
      ],
      "metadata": {
        "id": "SDyNG1swysm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/api/layers/recurrent_layers/gru/"
      ],
      "metadata": {
        "id": "VcdVCSuwysnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkXAAlE0kMEI",
        "outputId": "b1352a89-5dfa-4aff-9348-420f209f82c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0.]],\n",
              "\n",
              "       [[0., 0., 1., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru = GRU(10)\n",
        "output = gru(train_X)"
      ],
      "metadata": {
        "id": "Z_eKGp9Zkf83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output # 마지막 시점의 Hidden vector 가 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3f0f4d-0f37-421b-d528-557c4dd8d767",
        "id": "qc2tS1Fqkf84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
              "array([[ 0.25510576,  0.14532486,  0.16247232, -0.06723822,  0.10383694,\n",
              "        -0.12867996,  0.07351287,  0.03705239, -0.19907582, -0.02601814],\n",
              "       [ 0.23845002,  0.3301523 ,  0.13880032,  0.08107516,  0.22277805,\n",
              "        -0.18187267, -0.18029368, -0.20013377, -0.13222887,  0.03550896]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru = GRU(10, return_sequences=True)\n",
        "output = gru(train_X)"
      ],
      "metadata": {
        "id": "rmRMceQ_kSpX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output # 모든 시점의 Hidden vector 가 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMnXhWZEkUSE",
        "outputId": "ecc38ae0-0b34-472f-8075-de559a98b8fa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 10), dtype=float32, numpy=\n",
              "array([[[-0.06485951, -0.1335059 , -0.10532144,  0.09507397,\n",
              "          0.07057574,  0.03021935, -0.05934305, -0.15715463,\n",
              "         -0.08967832, -0.10092197],\n",
              "        [-0.11201885,  0.07808554, -0.241065  ,  0.06933547,\n",
              "          0.15301757,  0.13467762,  0.02141472, -0.17853157,\n",
              "         -0.10067677, -0.08699638],\n",
              "        [ 0.05858942,  0.17569372,  0.03951798,  0.03153273,\n",
              "          0.15760893,  0.1431498 ,  0.05959178, -0.01257851,\n",
              "          0.10036712, -0.08597995]],\n",
              "\n",
              "       [[ 0.13442338,  0.13162382,  0.14367786,  0.04126311,\n",
              "          0.10143887,  0.08337055,  0.0380693 ,  0.07523782,\n",
              "          0.14650837, -0.02565111],\n",
              "        [-0.00231821,  0.21326742, -0.1105819 ,  0.07830205,\n",
              "          0.16378188,  0.1808161 ,  0.08687209, -0.1046818 ,\n",
              "          0.04808076, -0.02992109],\n",
              "        [ 0.07103775,  0.17564774,  0.1126399 , -0.1268832 ,\n",
              "          0.02420799, -0.02393562,  0.01753471,  0.01738961,\n",
              "          0.02839365, -0.08465049]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru = GRU(10, return_sequences=True, return_state=True)\n",
        "output = gru(train_X)"
      ],
      "metadata": {
        "id": "JRVgpgpnkmDN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output # 모든 시점의 Hidden vector , 두번째는 마지막 시점의 Hidden state출력(CELL STATE 없어서 출력 안 됨)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a751d9d5-0190-44fb-9521-fb6c7b50bf27",
        "id": "qqu97IAJkmDO"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(2, 3, 10), dtype=float32, numpy=\n",
              " array([[[ 0.18438318,  0.08697686, -0.18993029, -0.09965076,\n",
              "          -0.04078727, -0.08273635, -0.16549124,  0.13684937,\n",
              "           0.11966605,  0.07066972],\n",
              "         [ 0.13169135,  0.07750485, -0.21429253,  0.10722788,\n",
              "           0.00731747,  0.09138015, -0.22116654, -0.03568701,\n",
              "          -0.13551486, -0.08909343],\n",
              "         [ 0.04103464, -0.13933074, -0.30667865, -0.07610669,\n",
              "          -0.04550781,  0.07511689, -0.04365234,  0.01984416,\n",
              "          -0.14235719, -0.18737191]],\n",
              " \n",
              "        [[ 0.01067854, -0.16299233, -0.22308521, -0.16681366,\n",
              "          -0.04624448,  0.03072454,  0.07662097,  0.03962259,\n",
              "          -0.08012903, -0.18264744],\n",
              "         [ 0.01651171, -0.04118147, -0.23682374,  0.05924007,\n",
              "           0.00626924,  0.16529144, -0.09806661, -0.0763464 ,\n",
              "          -0.19214824, -0.18765046],\n",
              "         [-0.22930133, -0.04102037, -0.15229234,  0.08601587,\n",
              "          -0.16825573,  0.06054401, -0.08505721, -0.10695049,\n",
              "           0.01016033, -0.23325798]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
              " array([[ 0.04103464, -0.13933074, -0.30667865, -0.07610669, -0.04550781,\n",
              "          0.07511689, -0.04365234,  0.01984416, -0.14235719, -0.18737191],\n",
              "        [-0.22930133, -0.04102037, -0.15229234,  0.08601587, -0.16825573,\n",
              "          0.06054401, -0.08505721, -0.10695049,  0.01016033, -0.23325798]],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru = GRU(num_classes)\n",
        "output = gru(train_X)\n",
        "\n",
        "print('hidden state : {}, shape: {}'.format(output, output.shape))"
      ],
      "metadata": {
        "id": "6Nwqw_wyysnC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return_sequences = True\n",
        "gru = GRU(3, return_sequences=True, return_state=True)\n",
        "whole_sequence_output, final_state= gru(train_X)\n",
        "\n",
        "print('whole_seq_output: {}, shape: {}'.format(whole_seq_output, whole_seq_output.shape))\n",
        "print('final_state : {}, shape: {}'.format(final_state, final_state.shape))"
      ],
      "metadata": {
        "id": "vUYfG_J3ysnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca8776d-40ec-41bd-f7c3-3623e98c857e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whole_seq_output: [[[-0.09133016 -0.02071412  0.14170164]\n",
            "  [ 0.02361282  0.06159054  0.03471249]\n",
            "  [ 0.06012786 -0.04471743 -0.08892121]]\n",
            "\n",
            " [[ 0.03587217 -0.0941782  -0.11587585]\n",
            "  [ 0.08149255  0.02020295 -0.18497597]\n",
            "  [ 0.03355836 -0.02213107 -0.14921774]]], shape: (2, 3, 3)\n",
            "final_state : [[ 0.10870809  0.3283546  -0.2419539 ]\n",
            " [-0.13706805 -0.10124536 -0.31973392]], shape: (2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "n13akaClysnC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential() #모델 호출\n",
        "model.add(\n",
        "    layers.GRU(\n",
        "        units=5,\n",
        "        input_shape =(3, 4),\n",
        "        return_sequences = True,\n",
        "        reset_after=False,# 논문에 있는 버전으로 해달라 (논문 x = True)\n",
        "        name='GRU-1')) # RNN 호출\n",
        "\n",
        "# reset_after : keras 구현을 하면서 병렬처리를 위해 공식을 수정(bias를 2개로 나눔)하였는데, 원래 논문에 나온 공식으로 계산하기 위해 False로 수정\n",
        "\n",
        "model.add(\n",
        "    layers.Dense(\n",
        "        units=3,\n",
        "        activation='softmax',\n",
        "        name='hidden-to-output')) # 출력을 위한 FFN\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG-hBKJWysnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c82c78-b389-49b9-a619-c1de24410485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1492 - accuracy: 0.1667\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1400 - accuracy: 0.1667\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1317 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1240 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1170 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1105 - accuracy: 0.1667\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1044 - accuracy: 0.1667\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0929 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0874 - accuracy: 0.6667\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0820 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0766 - accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0712 - accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0656 - accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0598 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0539 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0477 - accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0412 - accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0344 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0272 - accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0196 - accuracy: 0.6667\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0116 - accuracy: 0.8333\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0032 - accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9943 - accuracy: 0.6667\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9849 - accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9751 - accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9647 - accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9538 - accuracy: 0.8333\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9425 - accuracy: 0.8333\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9306 - accuracy: 0.8333\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9182 - accuracy: 0.8333\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9052 - accuracy: 0.8333\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8918 - accuracy: 0.8333\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8780 - accuracy: 0.8333\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8636 - accuracy: 0.8333\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8489 - accuracy: 0.8333\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8338 - accuracy: 0.8333\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8183 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.8025 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7865 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7702 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7538 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7372 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7206 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7040 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6873 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6707 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6542 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6378 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6215 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6054 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5895 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5739 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5584 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5433 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5283 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5137 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4993 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4853 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4715 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4580 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4320 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4194 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3835 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3721 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3611 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3504 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3399 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3298 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3200 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3104 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2923 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2837 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2753 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2673 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2595 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2520 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2448 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2378 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2311 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2247 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2185 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2125 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2067 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2011 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1958 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1906 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1857 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1809 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1763 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1718 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1675 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1634 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1594 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1556 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1519 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcb1dbe1710>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "model.fit(train_X, train_Y, epochs= 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQQ6bRosysnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3258a930-25ec-4d7e-fdd7-1cfbb765d116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.8838949  0.03892433 0.07718088]\n",
            " [0.03276091 0.89175344 0.07548558]\n",
            " [0.12529185 0.05806499 0.8166431 ]]\n",
            "[0 1 2]\n",
            "\tPrediction str:  SVO\n",
            "[[0.8183433  0.04454137 0.13711534]\n",
            " [0.03734664 0.8973856  0.06526773]\n",
            " [0.07024387 0.06087027 0.8688859 ]]\n",
            "[0 1 2]\n",
            "\tPrediction str:  SVO\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(train_X)\n",
        "for i, prediction in enumerate(predictions):\n",
        "  print(prediction)\n",
        "  print(np.argmax(prediction, axis=1))\n",
        "  result_str = [idx2tag[c] for c in np.argmax(prediction, axis=1) ]\n",
        "  print(\"\\tPrediction str: \", \"\".join(result_str))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHjLtdazysnD"
      },
      "source": [
        "모델을 이해하려면 weight 개수(W0\\~Wn)를 세어봐야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR3ohllDysnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f56b064-d1e1-4486-83d6-9d1be22ccca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " GRU-1 (GRU)                 (None, 3, 3)              72        \n",
            "                                                                 \n",
            " hidden-to-output (Dense)    (None, 3, 3)              12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84\n",
            "Trainable params: 84\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# GRU는 RNN와 LSTM 사이에 있다\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model_weight in model.weights:\n",
        "    print(model_weight.name, '=>', model_weight.shape)"
      ],
      "metadata": {
        "id": "Uy0MKRyLysnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99Dk_Odi5rgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제1"
      ],
      "metadata": {
        "id": "I2rUh3ul5uyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(GRU(9, input_dim = 10, return_sequences=True, reset_after=False))\n",
        "# reset_after : keras 구현을 하면서 병렬처리를 위해 공식을 수정(bias를 2개로 나눔)하였는데, 원래 논문에 나온 공식으로 계산하기 위해 False로 수정\n",
        "model.add(GRU(6, reset_after = False))\n",
        "model.add(Dense(3))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b055acee-0e27-43db-d418-74667f76ea1c",
        "id": "JAykizT85uyx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_6 (GRU)                 (None, None, 9)           540       \n",
            "                                                                 \n",
            " gru_7 (GRU)                 (None, 6)                 288       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 849\n",
            "Trainable params: 849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- W_reset : (num_units + input_dim + 1) * num_units\n",
        "- W_update : (num_units + input_dim + 1) * num_units\n",
        "- W_new : (num_units + input_dim + 1) * num_units\n"
      ],
      "metadata": {
        "id": "ukP2frBF_AJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 레이어의 파리미터 개수"
      ],
      "metadata": {
        "id": "amdHJ3TD5uyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두번째 레이어의 파라미터 개수"
      ],
      "metadata": {
        "id": "B8Vu4AYR5uyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 세번째 레이어의 파리미터 개수"
      ],
      "metadata": {
        "id": "qY-kw6jE5uyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reference"
      ],
      "metadata": {
        "id": "p_IsqbYB8ZCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://github.com/ukairia777/tensorflow-nlp-tutorial/blob/main/08.%20RNN/8-4.%20understanding_simplernn_and_lstm.ipynb"
      ],
      "metadata": {
        "id": "DREMZ3E18WdL"
      }
    }
  ]
}