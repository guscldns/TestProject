{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/%EA%B8%B0%EC%B4%88%ED%86%B5%EA%B3%84/naive_sol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhue9ipbXIxs"
      },
      "source": [
        "# 확률을 사용한 프로그래밍 프로젝트: 나이브 베이즈 스팸 메일 필터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCFspPCgXIxu"
      },
      "source": [
        "## 나이브베이즈Naive Bayes\n",
        "\n",
        "- 주어진 문서 $X$를 스팸인지 햄(정상 메일)인지 구분하기 위해 베이즈 정리를 이용하는 모델 나이브베이즈를 구현해본다.\n",
        "\n",
        "\n",
        "$$\n",
        "P(C \\mid X) = \\frac{P(X \\mid C)P(C)}{P(X)}\n",
        "$$\n",
        "\n",
        "- 위 베이즈 정리에서 $P(C)$는 클래스의 사전확률prior로 스팸 메일 필터에서 클래스 변수 $C$는 스팸($C=SPAM$) 또는 햄($C=HAM$)이 되며 문서를 스팸과 햄으로 나눌때 두 클래스간 비율이 된다.\n",
        "\n",
        "- $P(X \\mid C)$는 클래스 조건부 확률로 주어진 클래스에서 $X$가 얼마나 존재 할만한 지를 나타내는 값이다. 다르게 말하면 클래스 $C$에 대한 가능도likelihood 이다.\n",
        "\n",
        "- $P(X)$는 문서 $X$가 존재할 확률이며 클래스 조건부 확률 $P(X \\mid C)$를 $P(C)$에 대해 평균을 낸 값이다. 확률의 곱법칙과 합법칙을 사용하면 다음과 같다.\n",
        "\n",
        "$$\n",
        "P(X) = P(X \\mid C=SPAM)P(C=SPAM) + P(X \\mid C=HAM)P(C=HAM)\n",
        "$$\n",
        "\n",
        "- 마지막으로 $P(C \\mid X)$는 사후확률posterior로써 결과적으로 알고 싶은 문서 $X$에 대한 원인의 확률이다.(이 문서가 어떤 클래스(상자)에서 발생했는가!)\n",
        "\n",
        "- $P(C \\mid X)$를 알기위해 $P(X \\mid C)$와 $P(C)$를 알아야 한다. 사전확률과 가능도를 알면 위 베이즈 정리에 의해 사후 확률을 계산할 수 있다.\n",
        "\n",
        "- 나이브베이즈는 $P(X \\mid C)$의 계산을 위해 조건부 독립을 가정한다. 문서 $X$가 다음처럼 특징feature으로 변환되었을 때\n",
        "\n",
        "$$\n",
        "X := (x_1, x_2, ..., x_n)\n",
        "$$\n",
        "\n",
        "- 조건부 독립에 의해 다음처럼 가정하게 된다.\n",
        "\n",
        "$$\n",
        "P(X \\mid C) = P(x_1, x_2, ..., x_n \\mid C) = P(x_1 \\mid C) \\times P(x_1 \\mid C) \\times \\cdots \\times P(x_n \\mid C)\n",
        "$$\n",
        "\n",
        "- 결론적으로 나이브베이즈를 학습한다는 것은 학습 데이터를 특징화 하고 그 특징을 독립으로 가정한 다음 클래스에 대한 가능도 $P(X \\mid C)$를 계산하는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uUnDcD2XIxv"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p961XSHXIxw"
      },
      "source": [
        "- 제공된 데이터 파일을 판다스pandas 데이터프레임으로 로딩한다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 파일 가져오기\n",
        "!gdown 16FxXGZDQK_8C5nW9o5H5lUAVRBG2YwKa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aI68dVEYyHG",
        "outputId": "52a0d49f-d5f5-45ab-a81b-79b1efa15001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16FxXGZDQK_8C5nW9o5H5lUAVRBG2YwKa\n",
            "To: /content/spam.csv\n",
            "\r  0% 0.00/154k [00:00<?, ?B/s]\r100% 154k/154k [00:00<00:00, 80.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5AECtLnXIxw",
        "outputId": "59ee537b-d33b-45fe-bae6-48a7ae577785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3423 entries, 0 to 3422\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   subject  3423 non-null   object\n",
            " 1   spam     3423 non-null   bool  \n",
            "dtypes: bool(1), object(1)\n",
            "memory usage: 30.2+ KB\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('spam.csv')\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3dH_aCdXIxw"
      },
      "source": [
        "## 문서 특징화\n",
        "\n",
        "- 다루는 데이터는 텍스트이므로 어떤 식으로든 이를 숫자로 바꿔야 한다.\n",
        "- 여기서는 텍스트를 숫자로 바꾸는 가장 고전적이면서도 간단한 방법인 BoW(Bag of Words) 방식을 사용한다.\n",
        "- BoW 구축 방법은 아래 순서를 따른다.\n",
        "    - 텍스트를 토큰이라는 단위로 쪼갤 방법을 마련한다. 토큰이란 단어가 될 수 도 있고 단어가 더 쪼개진 더 작은 단위가 될 수 도 있다. 여기서는 가장 간단하게 공백을 기준으로 단어를 자르고 잘린 단어를 토큰으로 사용한다.\n",
        "    - 모델이 사용할 전체 단어를 포함하고 있는 단어장vocabulary `V`를 구축한다. 이는 모든 학습 데이터에 있는 텍스트를 이전 단계에서 준비한 토큰화 방법으로 자른 다음 얻게 되는 모든 단어에서 중복을 제거하면 얻을 수 있다.\n",
        "    - 숫자로 바꾸고자하는 텍스트를 토큰화하고 `V`에서 해당 토큰들이 있는지 확인한다.\n",
        "    - 길이가 `V`의 개수와 같은 0으로 채워진 벡터를 마련하고 앞서 `V`에 존재하는 토큰의 위치에 1을 기록한다.\n",
        "- 위와 같은 방법으로 텍스트를 특징화하면 텍스트는 길이에 상관없이 무조건 길이가 `V`의 개수와 같은 벡터로 바뀌게 된다.\n",
        "- 또한 변환된 벡터는 대부분 0이고 듬성듬성 1이 채워진 희소한 벡터가 되며 원래 텍스트의 단어순서는 모두 무시된 상태가 된다.\n",
        "- 이런 특징은 머신러닝 측면에서 썩 좋은 특징이라 할 수 없기 때문에 다른 더 우수한 텍스트-벡터 변환 방법들이 많이 존재한다.\n",
        "- 아래는 방금 소개한 방법의 간단한 예를 보여준다.\n",
        "\n",
        "    ```\n",
        "    # 단어장\n",
        "    V = [\"is\", \"it\", \"it's\", \"over\", \"find\", \"base\", \"till\", \"untill\"]\n",
        "\n",
        "    # 바꾸고자 하는 문장\n",
        "    text = \"It ain't over till it's over.\"\n",
        "\n",
        "    # 중복제거 토큰화\n",
        "    tokens = [\"it\", \"ain't\", \"over\", \"till\", \"it's\"]\n",
        "\n",
        "    # 특징화 벡터\n",
        "    feature = [0, 1, 1, 1, 0, 0, 1, 0]\n",
        "    ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiIOGIIfXIxx"
      },
      "source": [
        "### tokenize\n",
        "\n",
        "\n",
        "- 아래 `tokenize` 함수는 주어진 문장을 소문자로 만들고 공백 기준으로 토큰화 한 후 중복을 제거해 단어의 리스트를 반환한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMvfnv8xXIxx"
      },
      "outputs": [],
      "source": [
        "def tokenize(message):\n",
        "    message = message.lower()                       # 모두 소문자로 바꿈\n",
        "    all_words = re.findall(\"[a-z0-9']+\", message)   # 숫자,알파벳(소문자)로 된 낱말만 추출\n",
        "    return list(set(all_words))                     # 중복제거하고 되돌림"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpqSqm1oXIxx",
        "outputId": "08890d65-a1ca-4cb4-c9e8-c0f65cdc9c34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gives',\n",
              " 'true',\n",
              " '101',\n",
              " \"'spam'\",\n",
              " 'spam',\n",
              " 'this',\n",
              " 'positives',\n",
              " 'as',\n",
              " 'classified']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# tokenizez 테스트\n",
        "tokenize(\"This gives 101 true positives (spam classified as 'spam') @?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jKEFHUGXIxx"
      },
      "source": [
        "### 단어장 `V`\n",
        "\n",
        "- 단어장 `V`를 구축하기 위해 데이터 셋을 학습과 테스트로 나눈다.\n",
        "- 전체 데이터 개수가 3423개이므로 3000개, 423개 씩 나눈다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hom7n5aXIxy"
      },
      "outputs": [],
      "source": [
        "data_train = data[:3000]\n",
        "data_test = data[3000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습 데이터는 다음처럼 이메일의 제목과 타겟으로 구성되어있다.\n",
        "\n",
        "- 타겟값은 Spam메일일 경우 True, 정상 메일이면 False이다."
      ],
      "metadata": {
        "id": "ywrpDVdTZBBv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "f-dnQ6QmXIxy",
        "outputId": "7695bf82-5fc9-4f0f-f81c-3e1d5389f5ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                subject   spam\n",
              "0                       [ILUG] Garden Ornaments | mvcmv   True\n",
              "1                        Re: mplayer not working for me  False\n",
              "2                                         Re: exmh bug?  False\n",
              "3     MacOS X (Re: [SAtalk] [OT] Habeas-talk (was: 2...  False\n",
              "4                                             Re: girls   True\n",
              "...                                                 ...    ...\n",
              "2995        [Lockergnome Digital Media]  Humblest Alarm  False\n",
              "2996                    DVD capture: Unbreaking the Mac  False\n",
              "2997       New light on a lost world of shattered icons  False\n",
              "2998                                 Re: [meta-forkage]  False\n",
              "2999                [use Perl] Headlines for 2002-09-14  False\n",
              "\n",
              "[3000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec8be356-507f-49e6-8942-521cab7f4573\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ILUG] Garden Ornaments | mvcmv</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Re: mplayer not working for me</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Re: exmh bug?</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MacOS X (Re: [SAtalk] [OT] Habeas-talk (was: 2...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Re: girls</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>[Lockergnome Digital Media]  Humblest Alarm</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>DVD capture: Unbreaking the Mac</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>New light on a lost world of shattered icons</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>Re: [meta-forkage]</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>[use Perl] Headlines for 2002-09-14</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec8be356-507f-49e6-8942-521cab7f4573')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec8be356-507f-49e6-8942-521cab7f4573 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec8be356-507f-49e6-8942-521cab7f4573');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-69396326-6fe6-4212-80fe-c2a0c050c0ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69396326-6fe6-4212-80fe-c2a0c050c0ba')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-69396326-6fe6-4212-80fe-c2a0c050c0ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFmFSe9VXIxy"
      },
      "source": [
        "- `data_train`에 있는 모든 샘플들에 대해서 토크나이징한 토큰들을 모두 리스트에 저장하여 단어장 `V`를 구성한다.\n",
        "- 이때 `V`에는 중복된 단어가 없어야 한다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiLAdpyGXIxy"
      },
      "outputs": [],
      "source": [
        "# train의 모든 문장 토크나이징해서 단어 사전 만들기\n",
        "# hint: 파이썬 사전 자료형을 사용하면 간단하게 중복을 제거할 수 있음\n",
        "# 사용예: {1,2,3}.union({3,4,5}) -> {1,2,3,4,5}\n",
        "\n",
        "# 파이썬 사전형 변수를 초기화\n",
        "V = set()\n",
        "\n",
        "# 모든 학습 데이터에 있는 메일 제목을 순회하면서\n",
        "# 제목을 토크나이징하고 토큰을 모아서 단어장 V를 완성\n",
        "for i, d in enumerate(data_train['subject']):\n",
        "    V = V.union( tokenize(d) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLhmonAGXIxz",
        "outputId": "f0c0dbe2-f03f-476c-93ab-8389e6702b5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4251"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# 단어장을 리스트로 변환하고 총 단어장 길이를 출력\n",
        "V = list(V)\n",
        "len(V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvAfhV9eXIxz",
        "outputId": "ffe43523-0952-40d8-9712-451b5fa68c23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['director',\n",
              "  'e1',\n",
              "  'possible',\n",
              "  'mi5',\n",
              "  'stolen',\n",
              "  \"michael's\",\n",
              "  'executed',\n",
              "  \"'i'm\",\n",
              "  'ultrasound',\n",
              "  'build'],\n",
              " ['doing',\n",
              "  'coffee',\n",
              "  'auto',\n",
              "  'month',\n",
              "  'benefitting',\n",
              "  'lord',\n",
              "  'drop',\n",
              "  'ben',\n",
              "  'streams',\n",
              "  '37771'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 리스트로 저장된 단어장 V의 앞 10개 뒤 10개 확인\n",
        "V[:10], V[-10:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkqquUtIXIxz"
      },
      "source": [
        "- 단어장 `V`를 이용해서 `V`에서 단어의 위치를 나타내는 인덱스를 입력하면 단어를 돌려주는 `id2token` 사전과 반대로 단어를 입력하면 인덱스를 돌려주는 `token2id`를 생성한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDgoKAlcXIxz"
      },
      "outputs": [],
      "source": [
        "id2token = {i:v for i, v in enumerate(V) }\n",
        "token2id = {v:i for i, v in enumerate(V)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2token[10], token2id['annual']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "barK25dcVjI6",
        "outputId": "9bbcd53e-9456-4d35-c6d6-30e11fbfe1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('annual', 10)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k59YLtXYXIxz"
      },
      "source": [
        "## 사전확률 $P(C)$ 계산\n",
        "\n",
        "- 사전 확률은 `data_train`에 있는 스팸 메일 수와 햄 메일 수의 비율로 간단하게 계산할 수 있다.\n",
        "\n",
        "- `data_train`은 판다스 데이터프레임 변수이므로 데이터프레임 변수를 다루는것에 익숙치 않다면 넘파이 어레이로 변경해서 처리할 수 있다.\n",
        "\n",
        "- `data_train.values`로 넘파이 어레이로 변경할 수 있다.\n",
        "```python\n",
        "data_train.values\n",
        "array([['[ILUG] Garden Ornaments | mvcmv', True],\n",
        "       ['Re: mplayer not working for me', False],\n",
        "       ['Re: exmh bug?', False],\n",
        "       ...,\n",
        "       ['New light on a lost world of shattered icons', False],\n",
        "       ['Re: [meta-forkage]', False],\n",
        "       ['[use Perl] Headlines for 2002-09-14', False]], dtype=object)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROmghhr7XIxz",
        "outputId": "3143a7dc-5325-4d51-f2c5-63f433516bc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8536666666666667, 0.14633333333333334)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Prior\n",
        "# data_train의 스팸메일 수와 햄메일 수를 이용해\n",
        "# P_ham( P(C='HAM') ), P_ham( P(C='SPAM') )을 계산한다.\n",
        "# 계산 결과 P_ham = 0.853, P_spam = 0.146 정도 나와야 함\n",
        "num_ham = (data_train['spam'] == False).astype(int).sum()\n",
        "num_spam = (data_train['spam'] == True).astype(int).sum()\n",
        "\n",
        "P_ham = num_ham / (num_ham + num_spam)\n",
        "P_spam = num_spam / (num_ham + num_spam)\n",
        "\n",
        "P_ham, P_spam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycZv8UtqXIxz"
      },
      "source": [
        "## 가능도 $P(X \\mid C)$ 계산\n",
        "\n",
        "- 가장 중요한 클래스 조건부 확률, 가능도를 계산한다.\n",
        "- 클래스 조건부 확률이므로 우선 데이터를 스팸과 햄으로 나눈다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KgqIRM9XIxz"
      },
      "outputs": [],
      "source": [
        "data_train_spam = data_train[data_train['spam']==True]\n",
        "data_train_ham = data_train[data_train['spam']==False]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCLjX59cXIxz"
      },
      "source": [
        "- $j$번째 토큰에 대한 가능도는 다음처럼 정의된다. 여기서 $j$번째는 단어장 `V`에서 해당 토큰의 위치를 의미한다.\n",
        "\n",
        "$$\n",
        "P\\left(x_j \\mid C\\right) = \\frac{n_C\\left(x_j\\right) + k}{N_C + 2k}\n",
        "$$\n",
        "\n",
        "- 이렇게 가능도를 계산하는 모델을 베르누이 나이브 베이즈라고 한다.\n",
        "\n",
        "- 위 식에서 $n_C\\left(x_j\\right)$는 단어장 기준 $j$번때 토큰이 학습 데이터 셋 문서 중 $C$ 클래스 문서에 나타난 수를 의미하고 $N_C$는 학습 데이터 셋의 $C$ 클래스인 문서 수를 의미한다.\n",
        "\n",
        "- 예를 들어 스팸메일에 대해서 정리하면 다음과 같다.\n",
        "\n",
        "$$\n",
        "P\\left(x_j \\mid C=Spam\\right) = \\frac{x_j\\text{를 포함하는 스펨메일 수}}{x_j\\text{를 포함하는 스팸메일 수} + x_j\\text{를 포함하지 않는 스펨메일 수}}\n",
        "$$\n",
        "\n",
        "- $k$는 스무딩 팩터로 $n_C\\left(x_j\\right)$가 0이 되더라도 가능도 값이 0이 됨을 막는 역할을 하게 된다. 다시 말해 해당 클래스 문서에 한번도 나타나지 않는 단어라 하더라도 가능도 값을 0으로는 만들지 않겠다는 것이다. 만약 어떤 토큰의 가능도가 0이 되어 버리면 나이브 가정에 의해 전체 가능도를 각 토큰의 가능도의 곱으로 계산할 때 무조건 문서에 대한 가능도가 0이 되는 문제가 생기게 되는데 이를 방지하기 위함이다.\n",
        "\n",
        "$$\n",
        "P\\left(x_j \\mid C=Spam\\right) = \\frac{x_j\\text{를 포함하는 스펨메일 수}+k}{(x_j\\text{를 포함하는 스팸메일 수}+k) + (x_j\\text{를 포함하지 않는 스펨메일 수}+k)}\n",
        "$$\n",
        "\n",
        "- 다음 순서를 따라 진행한다.\n",
        "    - 전체 사이즈 `(sample_size, vocab_size)`인 0으로 채워진 행렬을 만든다.\n",
        "    - 샘플에 대한 인덱스 `i`, 토큰 위치에 대한 인덱스 `j`를 이용해 단어가 등장한 위치에 1을 기록한다.\n",
        "    - 전체 행렬이 완성되면 행방향으로 모두 더하고 스무딩을 적용하고 반환한다.\n",
        "    \n",
        "- 위 구현 과정은 예시일 뿐 다른 방식으로 구현해도 상관없다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhzN7vRNXIxz"
      },
      "outputs": [],
      "source": [
        "def get_likelihood(data, vocab_size, k=0.5):\n",
        "    # data: 클래스로 분루된 샘플들\n",
        "    # vocab_size: 단어장의 크기\n",
        "    # k: smoothing factor\n",
        "\n",
        "    likelihood = np.zeros((data.shape[0], vocab_size))\n",
        "\n",
        "    # data의 'subject' 항목을 for문으로 순회하면서\n",
        "    # subject를 token으로 바꾸고\n",
        "    # token들을 다시 j인덱스로 순회하면\n",
        "    # i가 문서번호, j가 토큰 번호가 됨\n",
        "    # 이 상태에서\n",
        "    # likelihood[i,j] 에 i번째 문서에 j번째 토큰이 나타나면 1씩 더해준다.\n",
        "    for i, x in enumerate(data['subject']):\n",
        "        # i: 문서 번호\n",
        "        # x: 문서\n",
        "        tokens = tokenize(x) # 중복 단어 제거됨\n",
        "        for t in tokens:\n",
        "            j = token2id[t]\n",
        "            likelihood[i, j] += 1\n",
        "\n",
        "    # likelihood에 0, 1만 기록되게 되고 axis=0으로 sum하여 각 토큰이\n",
        "    # 특정 클래스에서 등장한 횟수를 얻을 수 있음\n",
        "    # 이후 스모딩 팩터 k를 위 수식처럼 적용\n",
        "    likelihood = (likelihood.sum(axis=0) + k) / (data.shape[0] + 2*k)\n",
        "\n",
        "    return likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy0_zFKmXIx0"
      },
      "outputs": [],
      "source": [
        "# 스무딩 팩터를 0.5로 지정하고 모든 토큰에 대한 클래스 조건부 확률을 계산한다.\n",
        "k = 0.5\n",
        "P_X_bar_spam = get_likelihood(data_train_spam, len(V), k)\n",
        "P_X_bar_ham = get_likelihood(data_train_ham, len(V), k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diHviVwcXIx0",
        "outputId": "ce32e7ac-6e9e-4a82-d6a4-1984900959e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4251,), (4251,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# 각 확률이 토큰 개수만큼 계산되었는지 확인한다.\n",
        "P_X_bar_spam.shape, P_X_bar_ham.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxHY6z8XXIx0",
        "outputId": "8e6efb86-dfad-4d87-92a6-8f5fa7ffeccf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['e1', 'possible', 'build', 'earn', 'ccaxc', 'singles', '8119',\n",
              "       'rekq96sjre5', 'caught', '08', 'iiu', '206', '000', 'try',\n",
              "       'software'], dtype='<U51')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# 제대로 계산되었다면 스무딩에 의해 스팸메일에 한번도 등장하지 않는 토큰이\n",
        "# 약 0.001136 정도의 확률을 가지게 되므로\n",
        "# 0.00114보다 큰 확률을 가지는 단어를 확인해본다.\n",
        "\n",
        "# P_X_bar_spam[P_X_bar_spam > 0.00114]\n",
        "\n",
        "np.array(V)[P_X_bar_spam > 0.00114][:15]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5배 정도 높은 조건부 확률을 가지는 단어를 조사\n",
        "# 스팸에 포함될 듯한 단어거 조금은 보이는가?\n",
        "np.array(V)[P_X_bar_spam > 0.005][:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybw0fA86NmLv",
        "outputId": "0524c79e-f413-4f30-c1ee-3be1cde965e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['possible', 'earn', 'singles', '000', 'try', 'software', 'friend',\n",
              "       'breast', 'secret', 'why', 'just', 'sps', 'available', 'safe',\n",
              "       'risk'], dtype='<U51')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZpQqZ4DXIx0"
      },
      "source": [
        "## 나이브베이즈 분류기 작성"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 계산된 `P_X_bar_spam`, `P_X_bar_ham`을 이용해 나이브 베이즈 분류기를 작성한다.\n",
        "\n",
        "- `naive_bayes_clf(X)`는 문장 `X`를 받아서 다음 순서로 진행한다.\n",
        "\n",
        "- `X`를 토큰화하여 단어장 V길이의 0, 1로 채워진 특징 벡터로 변환\n",
        "- 스팸 클래스에 대한 가능도를 다음 식으로 계산한다.\n",
        "\n",
        "$$\n",
        "P(X \\mid C=Spam) = P(v_1 \\mid C=Spam) \\times P(v_2 \\mid C=Spam) \\times \\cdots \\times P(v_{|V|} \\mid C=Spam)\n",
        "$$\n",
        "\n",
        "- 위 식에서 $v_1$, ..., $v_{|V|}$는 단어장의 단어를 나타낸다.\n",
        "\n",
        "- 가능도 항 $P(v_1 \\mid C=Spam)$은 단어 $v_1$이 스팸에 등장할 확률을 의미한다. 만약 주어진 문서 $X$에 $v_1$이 등장하지 않았으면 $P(v_1 \\mid C=Spam)$를 $1-P(v_1 \\mid C=Spam)$로 바꿔서 곱한다.\n",
        "\n",
        "- 따라서 식을 다음으로 변경한다. 간략한 표기를 위해 $C=spam$을 $S$로 바꿔적었다.\n",
        "\n",
        "$$\n",
        "P(X \\mid S) = P(v_1 \\mid S)^{x_1}(1-P(v_1 \\mid S))^{1-x_1} \\times P(v_2 \\mid S)^{x_2}(1-P(v_2 \\mid S))^{1-x_2} \\times \\cdots \\times P(v_{|V|} \\mid S)^{x_{|V|}}(1-P(v_{|V|} \\mid S))^{1-x_{|V|}}\n",
        "$$\n",
        "\n",
        "- 위 식에서 $x_1$, ..., $x_{|V|}$는 $X$가 특징 벡터로 바뀌었을 때 각 자리에 해당하는 0 또는 1을 가지는 특징값들이다.\n",
        "\n",
        "- 위 식은 확률값이 계속 곱해지는 식이기 때문에 매우 작은 숫자를 곱하게 되 수치적으로 불안정하다. 로그를 취해 덧셈으로 바꾼다.\n",
        "\n",
        "$$\n",
        "\\log P(X \\mid S) = \\sum_i x_i \\log P(v_i | S) + (1-x_i) \\log (1-P(v_i | S))\n",
        "$$\n",
        "\n",
        "- 계산을 마친후 양변에 $\\exp$를 취한다.\n",
        "\n",
        "$$\n",
        "P(X \\mid S) = \\exp\\left(\\sum_i x_i \\log P(v_i | S) + (1-x_i) \\log (1-P(v_i | S)) \\right) \\tag{1}\n",
        "$$\n",
        "\n",
        "- 같은 방식으로 $X$가 정상 메일(Ham)일 가능도도 계산한다.\n",
        "\n",
        "$$\n",
        "P(X \\mid H) = \\exp\\left(\\sum_i x_i \\log P(v_i | H) + (1-x_i) \\log (1-P(v_i | H)) \\right) \\tag{2}\n",
        "$$\n",
        "\n",
        "- 최종적으로 다음 사후 확률을 반환 한다.\n",
        "\n",
        "$$\n",
        "P(S \\mid X) = \\frac{P(X \\mid S) P(S)}{P(X \\mid S) P(S) + P(X \\mid H) P(H)} \\tag{3}\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(H \\mid X) = \\frac{P(X \\mid H) P(H)}{P(X \\mid S) P(S) + P(X \\mid H) P(H)} \\tag{4}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "KnMrAP92f7T3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UneQEUyuXIx0"
      },
      "outputs": [],
      "source": [
        "def naive_bayes_clf(X):\n",
        "    # sentence to features\n",
        "    tokens = tokenize(X)\n",
        "    token_ids = [token2id[t]  for t in tokens if token2id.get(t, None)]\n",
        "    feature = np.zeros(len(V))\n",
        "\n",
        "    # 여기서 문장 X가 [0, 1, 0, 1, ...] 이런식의 특성 벡터로 변하게 됨\n",
        "    # 벡터의 길이는 V에 들어 있는 토큰 수\n",
        "    feature[token_ids] = 1.\n",
        "\n",
        "    ############################################################################\n",
        "    # calc. P(X|S) and P(X|H) eq(1),(2)\n",
        "    ############################################################################\n",
        "\n",
        "    # vector version\n",
        "    likelihood_spam = np.exp(np.sum(np.log(feature*P_X_bar_spam + (1-feature)*(1-P_X_bar_spam))))\n",
        "    likelihood_ham = np.exp(np.sum(np.log(feature*P_X_bar_ham + (1-feature)*(1-P_X_bar_ham))))\n",
        "\n",
        "    # # for loop version\n",
        "    # likelihood_spam = 0.0\n",
        "    # for i, xi in enumerate(feature):\n",
        "    #     if xi == 1:\n",
        "    #         likelihood_spam += np.log(P_X_bar_spam[i])\n",
        "    #     else:\n",
        "    #         likelihood_spam += np.log(1-P_X_bar_spam[i])\n",
        "    # likelihood_spam = np.exp(likelihood_spam)\n",
        "\n",
        "    # likelihood_ham = 0.0\n",
        "    # for i, xi in enumerate(feature):\n",
        "    #     if xi == 1:\n",
        "    #         likelihood_ham += np.log(P_X_bar_ham[i])\n",
        "    #     else:\n",
        "    #         likelihood_ham += np.log(1-P_X_bar_ham[i])\n",
        "    # likelihood_ham = np.exp(likelihood_ham)\n",
        "\n",
        "\n",
        "    ############################################################################\n",
        "    # calc. P(X|S)P(S) and P(X|H)P(H)\n",
        "    ############################################################################\n",
        "    likelihood_spam = likelihood_spam*P_spam\n",
        "    likelihood_ham = likelihood_ham*P_ham\n",
        "\n",
        "\n",
        "    ############################################################################\n",
        "    # normalize `likelihood_spam`, `likelihood_ham` eq(3),(4)\n",
        "    ############################################################################\n",
        "    return np.array([likelihood_ham, likelihood_spam]) / (likelihood_ham + likelihood_spam)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습, 테스트 세트에 대해서 성능 평가"
      ],
      "metadata": {
        "id": "PoQAsg47pNas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "7wZ94TkGpUVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_train = []\n",
        "preds_train = []\n",
        "\n",
        "for sample in data_train.values:\n",
        "    title, target = sample\n",
        "    y_train.append(target)\n",
        "\n",
        "    pred = naive_bayes_clf(title)\n",
        "    if pred[0] < pred[1]:\n",
        "        preds_train.append(True)\n",
        "    else:\n",
        "        preds_train.append(False)\n"
      ],
      "metadata": {
        "id": "6cvYouj7pUbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c68b24-b084-4a91-d34b-6c1a7e87b1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 464 ms, sys: 7.89 ms, total: 472 ms\n",
            "Wall time: 474 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_test = []\n",
        "preds_test = []\n",
        "\n",
        "for sample in data_test.values:\n",
        "    title, target = sample\n",
        "    y_test.append(target)\n",
        "\n",
        "    pred = naive_bayes_clf(title)\n",
        "    if pred[0] < pred[1]:\n",
        "        preds_test.append(True)\n",
        "    else:\n",
        "        preds_test.append(False)\n"
      ],
      "metadata": {
        "id": "uA06PdZuqyLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab428a3-95d3-469e-d256-9ad3375bd42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 70.4 ms, sys: 962 µs, total: 71.3 ms\n",
            "Wall time: 73 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( classification_report(y_train, preds_train) )\n",
        "confusion_matrix(y_train, preds_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5nMiA-vpUR7",
        "outputId": "c9621900-af20-44cf-928c-9b275f085dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.97      0.99      0.98      2561\n",
            "        True       0.92      0.83      0.87       439\n",
            "\n",
            "    accuracy                           0.96      3000\n",
            "   macro avg       0.95      0.91      0.93      3000\n",
            "weighted avg       0.96      0.96      0.96      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2530,   31],\n",
              "       [  74,  365]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( classification_report(y_test, preds_test) )\n",
        "confusion_matrix(y_test, preds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FniR8KLFq0Wj",
        "outputId": "b2c6ef9f-5974-4d95-b8da-2dfadc1a5679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.94      0.98      0.96       359\n",
            "        True       0.85      0.62      0.72        64\n",
            "\n",
            "    accuracy                           0.93       423\n",
            "   macro avg       0.89      0.80      0.84       423\n",
            "weighted avg       0.92      0.93      0.92       423\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[352,   7],\n",
              "       [ 24,  40]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00_fvEU7XIx0"
      },
      "source": [
        "## 테스트\n",
        "\n",
        "- 학습세트와 테스트 세트에 없는 임의의 제목에 대해서 테스트\n",
        "\n",
        "- 다음 20개 샘플은 학습데이터 `spam.csv`에는 없는 완전히 새로운 메일 제목을 ChatGPT로 생성한 것임\n",
        "\n",
        "- 샘플은 `(제목, 스팸유무)` 로 구성됨\n",
        "\n",
        "- 학습된 모델을 사용하여 각 샘플에 대해 다음 형식으로 출력\n",
        "```\n",
        "정답    예측     HAM확률 SPAM확률  제목\n",
        "[SPAM], [SPAM]   0.03%,  99.97%:   Double your income instantly - Click here to find out how!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWPgL7WqXIx0",
        "outputId": "5e076d12-c2e4-4c19-b727-0f9ae8f5bc01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[ HAM], [ HAM]  87.44%,  12.56%: Request for Order Delivery Confirmation - Order Number #JPXU-2596\u001b[0m\n",
            "\u001b[32m[SPAM], [SPAM]   8.22%,  91.78%: You have unread messages from the IRS - Act now!\u001b[0m\n",
            "\u001b[32m[ HAM], [ HAM]  98.44%,   1.56%: Job Application: Smith for AI Director\u001b[0m\n",
            "\u001b[32m[ HAM], [ HAM]  99.86%,   0.14%: New Course Offering: Introduction to Python Programming\u001b[0m\n",
            "\u001b[32m[SPAM], [SPAM]   0.41%,  99.59%: Exclusive VIP offer: Get rich overnight!\u001b[0m\n",
            "\u001b[32m[SPAM], [SPAM]   0.38%,  99.62%: Hot singles in your area are waiting for you!\u001b[0m\n",
            "\u001b[32m[SPAM], [SPAM]  35.40%,  64.60%: You won't believe what celebrities are hiding!\u001b[0m\n",
            "\u001b[32m[SPAM], [SPAM]   0.15%,  99.85%: Lose 30 pounds in just 3 days with this miracle pill!\u001b[0m\n",
            "\u001b[32m[ HAM], [ HAM]  99.79%,   0.21%: Newsletter: [Company Name] September Updates\u001b[0m\n",
            "\u001b[32m[ HAM], [ HAM]  99.97%,   0.03%: Weekly Project Update: September 1-7\u001b[0m\n",
            "\u001b[32m[SPAM], [SPAM]   0.91%,  99.09%: Unlock your secret fortune NOW!\u001b[0m\n",
            "\u001b[32m[SPAM], [SPAM]   0.03%,  99.97%: Double your income instantly - Click here to find out how!\u001b[0m\n",
            "\u001b[32m[ HAM], [ HAM]  99.75%,   0.25%: Invoice #12345 for Services Rendered\u001b[0m\n",
            "\u001b[32m[SPAM], [SPAM]   0.00%, 100.00%: Claim your free iPhone 13 now - limited time offer!\u001b[0m\n",
            "\u001b[32m[SPAM], [SPAM]   8.19%,  91.81%: Congratulations! You've won $1,000,000!\u001b[0m\n",
            "\u001b[32m[SPAM], [SPAM]  17.30%,  82.70%: Warning! Your computer is infected with 3 viruses!\u001b[0m\n",
            "\u001b[32m[ HAM], [ HAM]  85.64%,  14.36%: Your Flight Itinerary: Confirmation #ABC123\u001b[0m\n",
            "\u001b[32m[ HAM], [ HAM]  98.07%,   1.93%: Meeting Agenda for Monday, September 18th\u001b[0m\n",
            "\u001b[32m[ HAM], [ HAM]  91.30%,   8.70%: RSVP: End-of-Year Party\u001b[0m\n",
            "\u001b[32m[ HAM], [ HAM]  74.96%,  25.04%: Feedback Requested: Q3 Marketing Strategy\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "test_samples = [\n",
        "    (\"Congratulations! You've won $1,000,000!\",'SPAM'),\n",
        "    (\"Unlock your secret fortune NOW!\",'SPAM'),\n",
        "    (\"Hot singles in your area are waiting for you!\",'SPAM'),\n",
        "    (\"You won't believe what celebrities are hiding!\",'SPAM'),\n",
        "    (\"Lose 30 pounds in just 3 days with this miracle pill!\",'SPAM'),\n",
        "    (\"Exclusive VIP offer: Get rich overnight!\",'SPAM'),\n",
        "    (\"Warning! Your computer is infected with 3 viruses!\",'SPAM'),\n",
        "    (\"Claim your free iPhone 13 now - limited time offer!\",'SPAM'),\n",
        "    (\"You have unread messages from the IRS - Act now!\",'SPAM'),\n",
        "    (\"Double your income instantly - Click here to find out how!\",'SPAM'),\n",
        "    (\"Meeting Agenda for Monday, September 18th\", 'HAM'),\n",
        "    (\"Invoice #12345 for Services Rendered\", 'HAM'),\n",
        "    (\"Weekly Project Update: September 1-7\", 'HAM'),\n",
        "    (\"Feedback Requested: Q3 Marketing Strategy\", 'HAM'),\n",
        "    (\"Request for Order Delivery Confirmation - Order Number #JPXU-2596\", 'HAM'),\n",
        "    (\"RSVP: End-of-Year Party\", 'HAM'),\n",
        "    (\"New Course Offering: Introduction to Python Programming\", 'HAM'),\n",
        "    (\"Your Flight Itinerary: Confirmation #ABC123\", 'HAM'),\n",
        "    (\"Job Application: Smith for AI Director\", 'HAM'),\n",
        "    (\"Newsletter: [Company Name] September Updates\", 'HAM')]\n",
        "\n",
        "random.shuffle(test_samples)\n",
        "\n",
        "correct = 0\n",
        "for sample in test_samples:\n",
        "    pred = naive_bayes_clf(sample[0])\n",
        "\n",
        "    if pred[0] < pred[1]:\n",
        "        if sample[1] != 'SPAM':\n",
        "            color_code_s = \"\\033[31m\"\n",
        "            color_code_e = \"\\033[0m\"\n",
        "        else:\n",
        "            color_code_s = \"\\033[32m\"\n",
        "            color_code_e = \"\\033[0m\"\n",
        "\n",
        "        # 앞에 정답 뒤에 예측\n",
        "        print(f\"{color_code_s}[{sample[1]:>4}], [SPAM] {pred[0]*100:6.2f}%, {pred[1]*100:6.2f}%: {sample[0]}{color_code_e}\")\n",
        "    else:\n",
        "        if sample[1] != 'HAM':\n",
        "            color_code_s = \"\\033[31m\"\n",
        "            color_code_e = \"\\033[0m\"\n",
        "        else:\n",
        "            color_code_s = \"\\033[32m\"\n",
        "            color_code_e = \"\\033[0m\"\n",
        "\n",
        "        print(f\"{color_code_s}[{sample[1]:>4}], [ HAM] {pred[0]*100:6.2f}%, {pred[1]*100:6.2f}%: {sample[0]}{color_code_e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scikit-learn 으로 검증\n",
        "\n",
        "- 지금까지 코딩한 모델의 유효성을 검증하기 위해 scikit-learn에서 제공하는 나이브베이즈인 `BernoulliNB`를 사용하여 결과를 비교한다.\n",
        "\n",
        "- 먼저 문장을 길이 (|V|,)인 특징 벡터로 바꾸는 함수를 작성한다."
      ],
      "metadata": {
        "id": "ReZWIQJkY4C4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9O5A4PHXIx0"
      },
      "outputs": [],
      "source": [
        "def transform_to_features(data):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for d in data.values:\n",
        "        title, target = d\n",
        "\n",
        "        tokens = tokenize(title)\n",
        "        token_ids = [token2id[t]  for t in tokens if token2id.get(t, None)]\n",
        "        feature = np.zeros(len(V))\n",
        "        X.append(feature)\n",
        "\n",
        "        y.append(0 if target == False else 1)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 작성된 함수에 `data_train`, `data_test`를 입력하고 문장들을 특징벡터로 변환한다."
      ],
      "metadata": {
        "id": "i4-04EDlZYyP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ3suAgcXIx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479b18f9-c9e4-4136-d8c3-d0cccbf27596"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3000, 4251), (423, 4251))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "X_train, y_train =  transform_to_features(data_train)\n",
        "X_test, y_test =  transform_to_features(data_test)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- scikit-learn으로 부터 모델을 로딩하고 준비된 학습 데이터를 사용하여 `fit`시키고 결과를 확인한다.\n",
        "\n",
        "- 얻어진 결과와 직접 만든 모델의 결과를 비교해본다."
      ],
      "metadata": {
        "id": "k7U5Wd75ZeRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB"
      ],
      "metadata": {
        "id": "XiAUHhDgVw5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = BernoulliNB(alpha=0.5)"
      ],
      "metadata": {
        "id": "2JxaH8QxWR8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "EnY6ii9vWbFn",
        "outputId": "8035f09a-8047-421d-9ffb-aa8b9c36b1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=0.5)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB(alpha=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB(alpha=0.5)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_train = clf.predict(X_train)\n",
        "pred_test = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "EmEXxE8JWhhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( classification_report(y_train, preds_train) )\n",
        "confusion_matrix(y_train, preds_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXzYrwl3XZHB",
        "outputId": "7be00a21-cfc7-43cb-e9b4-bfc18df53c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      2561\n",
            "           1       0.92      0.83      0.87       439\n",
            "\n",
            "    accuracy                           0.96      3000\n",
            "   macro avg       0.95      0.91      0.93      3000\n",
            "weighted avg       0.96      0.96      0.96      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2530,   31],\n",
              "       [  74,  365]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( classification_report(y_test, preds_test) )\n",
        "confusion_matrix(y_test, preds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heNMk8urXeBB",
        "outputId": "20082a1a-d0d1-4a65-8ddc-56b73f41ad46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       359\n",
            "           1       0.85      0.62      0.72        64\n",
            "\n",
            "    accuracy                           0.93       423\n",
            "   macro avg       0.89      0.80      0.84       423\n",
            "weighted avg       0.92      0.93      0.92       423\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[352,   7],\n",
              "       [ 24,  40]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPVmKWa4XjBa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pd",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}