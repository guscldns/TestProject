{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/%EA%B8%B0%EC%B4%88%ED%86%B5%EA%B3%84/logreg_sol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fsQOxKQWkxm"
      },
      "source": [
        "# 미분과 최적화를 사용한 프로그래밍 프로젝트: 로지스틱 회귀 스팸 메일 필터"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 로딩"
      ],
      "metadata": {
        "id": "YtrbGpZjMQV1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADbr1DQSWkxo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 작성된 모델을 평가 하기 위한 추가 라이브러리 로딩\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비"
      ],
      "metadata": {
        "id": "p6V-nuU5MMXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 파일 가져오기\n",
        "!gdown 16FxXGZDQK_8C5nW9o5H5lUAVRBG2YwKa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqIyWwZDWlgT",
        "outputId": "4750a494-840e-46ca-82d9-af1c12c864ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16FxXGZDQK_8C5nW9o5H5lUAVRBG2YwKa\n",
            "To: /content/spam.csv\n",
            "\r  0% 0.00/154k [00:00<?, ?B/s]\r100% 154k/154k [00:00<00:00, 3.27MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEotUnqcWkxp",
        "outputId": "78dc351c-218a-4507-fd93-c4b8aa982fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3423 entries, 0 to 3422\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   subject  3423 non-null   object\n",
            " 1   spam     3423 non-null   bool  \n",
            "dtypes: bool(1), object(1)\n",
            "memory usage: 30.2+ KB\n"
          ]
        }
      ],
      "source": [
        "# pandas 라이브러리를 이용해 DataFrame 형식으로 데이터 읽어오기\n",
        "data = pd.read_csv('spam.csv')\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79B_CxxsWkxp"
      },
      "outputs": [],
      "source": [
        "# 3000개 학습 세트로 423개 테스트 세트로 나누기\n",
        "data_train = data[:3000]\n",
        "data_test = data[3000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터 샘플은 다음처럼 제목과 스팸인지 아닌지를 구별하는 타겟으로 구성되어 있음\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nY5iW_vOMbh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.loc[0:0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "8MLmfqgXND70",
        "outputId": "7424db37-79f4-425f-d8f6-d8c41f76ed16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           subject  spam\n",
              "0  [ILUG] Garden Ornaments | mvcmv  True"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78b3159f-dec7-4c14-b4da-7c3d19e62d02\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ILUG] Garden Ornaments | mvcmv</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78b3159f-dec7-4c14-b4da-7c3d19e62d02')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78b3159f-dec7-4c14-b4da-7c3d19e62d02 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78b3159f-dec7-4c14-b4da-7c3d19e62d02');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bow\n",
        "\n",
        "- 로지스틱 회귀 모델에 제목을 입력하고 모델의 출력으로 스팸(True)인지 아닌지(False)를 출력하게 하려면 메일의 제목은 문자가 아니라 숫자로 변경되어야 함\n",
        "\n",
        "- 문자를 숫자로 변경하는 다양한 방식이 있지만 여기서는 가장 간단한 방식은 BoW(Bag of Words) 방식을 사용\n",
        "\n",
        "- BoW는 학습 샘플에 등장하는 모든 단어를 사용해 단어장을 만들고 샘플에 단어가 해당 단어장에 몇번째 등장하는 단어인지를 조회해 문장을 숫자로 바꾸는 방식\n",
        "\n",
        "- 다음은 간단한 예를 보여주고 있음\n",
        "```\n",
        "V = ['love', 'I', 'me', 'you', 'hate']\n",
        "subject = \"I love you\"\n",
        "subject_int = [1, 0, 3]\n",
        "```\n",
        "\n",
        "- 위 처럼 바꾼후 단어장 길이의 0으로 채워진 벡터를 만들고 `subject_int`에 나타난 인덱스 자리만 1로 바꿔 마무리\n",
        "```\n",
        "subject_enc = [1, 1, 0, 1, 0]\n",
        "```\n",
        "\n",
        "- 이런 방식으로 모든 문장을 단어장 길이를 크기로 가지는 0, 1로 이뤄진 벡터로 변환 할 수 있음\n",
        "\n",
        "- 이 방식의 장점은 구현이 간단하며 숫자로 변환된 문장이 무조건 동일한 길이의 벡터가 된다는 점이며\n",
        "\n",
        "- 단점은 단어의 순서가 사라져 문장 구조에 대한 정보를 잃게 됨"
      ],
      "metadata": {
        "id": "c1Pa4jUnNMXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 사이킷런 라이브러리는 위와 같은 작업을 구현해 놓은 `CounterVectorizer()`를 제공함"
      ],
      "metadata": {
        "id": "xhwUkp6APEDW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "UIJ5IQaSWkxq",
        "outputId": "9ea9640e-bf0c-48b2-a40e-d77aecc6ee3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "cv = CountVectorizer()\n",
        "cv.fit(data_train['subject'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPK6ZcQKWkxq",
        "outputId": "9a219c94-7f99-4fc4-b3e5-1b9a209636b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4153"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 내부적으로 구축된 단어장 길이를 조회\n",
        "len(cv.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTakEtsBWkxq"
      },
      "outputs": [],
      "source": [
        "# 구축된 cv로 학습 샘플과 테스트 샘플을 숫자로 변환\n",
        "X_train = cv.transform(data_train['subject']).toarray()\n",
        "y_train = data_train['spam'].astype(float).to_numpy()\n",
        "\n",
        "X_test = cv.transform(data_test['subject']).toarray()\n",
        "y_test = data_test['spam'].astype(float).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F3obJnfUaJ5",
        "outputId": "dca22c1e-0ac7-4b49-a59a-21c894c9e765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 4153)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 만들기"
      ],
      "metadata": {
        "id": "w-y5OCIgSZ1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라이브러리 제공 모델 학습"
      ],
      "metadata": {
        "id": "w4s71dTOSeu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 먼저 수업에서 배운 가장 간단한 최적화 방식인 러닝레이트를 고정한 최속강하법으로 모델을 학습시킴\n",
        "\n",
        "- 이를 위해 사이킷런에서 제공하는 `SGDClassifier`를 사용\n"
      ],
      "metadata": {
        "id": "99j7Hi4XPnpP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "x4lIOzGMWkxr",
        "outputId": "967f7b51-9bb9-4859-bd25-eba94754a7fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(eta0=0.01, fit_intercept=False, l1_ratio=0.0,\n",
              "              learning_rate='constant', loss='log_loss', max_iter=150)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(eta0=0.01, fit_intercept=False, l1_ratio=0.0,\n",
              "              learning_rate=&#x27;constant&#x27;, loss=&#x27;log_loss&#x27;, max_iter=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(eta0=0.01, fit_intercept=False, l1_ratio=0.0,\n",
              "              learning_rate=&#x27;constant&#x27;, loss=&#x27;log_loss&#x27;, max_iter=150)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "logreg = SGDClassifier(loss='log_loss', penalty='l2',\n",
        "                       alpha=0.0001, l1_ratio=0.0,\n",
        "                       fit_intercept=False, max_iter=150,\n",
        "                       learning_rate='constant', eta0=0.01)\n",
        "logreg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QzwjUdVWkxr"
      },
      "source": [
        "### 직접 만들어 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 손실함수 포워드 패스\n",
        "\n",
        "$$\n",
        "L(\\mathbf{w}) = - \\sum_{i=1}^N y_i \\log \\left(\\sigma(\\mathbf{w} \\cdot  \\mathbf{x}_i) \\right) + (1-y_i) \\log \\left(1 - \\sigma(\\mathbf{w} \\cdot \\mathbf{x}_i) \\right) \\tag{1}\n",
        "$$\n",
        "\n",
        "- 위 식에서\n",
        "\n",
        "- $N$은 샘플의 개수\n",
        "\n",
        "- $y_i$는 $i$번째 샘플의 타겟인 0 아니면 1인 숫자\n",
        "\n",
        "- $\\mathbf{x}_i$는 $(D,)$인 벡터이고 현재 문제에서 $D=4153$\n",
        "\n",
        "- $\\mathbf{w}$는 입력 $\\mathbf{x}_i$의 각 숫자에 곱해질 $(D,)$인 가중치 벡터\n",
        "\n",
        "- 따라서 $\\mathbf{w} \\cdot \\mathbf{x}_i$는 두 벡터의 내적을 나타냄\n",
        "\n",
        "- $\\sigma(x)=\\frac{1}{1+\\exp(-x)}$ 인 로지스틱 시그모이드 함수\n",
        "\n",
        "\n",
        "- 위 손실 함수의 함수값을 계산하는 코드를 `Loss.forward(self, w, X, y)`에 코딩한다.\n",
        "\n",
        "- `self.cost` 변수에 함수값 저장\n",
        "\n",
        "- 넘파이를 활용해도 좋고 `for`문으로 직관적으로 구현해도 좋음"
      ],
      "metadata": {
        "id": "CDiuyDnjVjZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 손실함수 포워드 패스 규제\n",
        "\n",
        "- `self.cost`에 위 식(1)이 계산되었다면 규제항을 추가\n",
        "\n",
        "- 규제 항은 아래 식으로 추가됨\n",
        "\n",
        "$$\n",
        "L_{\\text{reg}}(\\mathbf{w}) = L(\\mathbf{w}) + \\frac{\\lambda}{2} \\lVert \\mathbf{w} \\rVert^2 \\tag{2}\n",
        "$$\n",
        "\n",
        "- 위 식에서\n",
        "\n",
        "- $\\lambda$는 규제 효과를 조정하는 주어지는 상수\n",
        "\n",
        "- $\\lVert \\mathbf{w} \\rVert^2 = w_1^2 + w_2^2 + \\cdots + w_D^2$\n",
        "\n",
        "- `Loss.forward()`함수는 최종적으로 위 식 $L_{\\text{reg}}$ 값을 반환"
      ],
      "metadata": {
        "id": "5UZHfDHIVojH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 손실함수 백워드 패스\n",
        "\n",
        "- 약간의 미분 과정을 거치면 규제 없는 손실함수 $L(\\mathbf{w})$에 대한 $\\mathbf{w}$의 미분은 다음처럼 주어짐\n",
        "\n",
        "$$\n",
        "\\frac{\\partial }{\\partial \\mathbf{w}} L(\\mathbf{w}) = \\sum_{i=1}^N \\left\\{-y_i + \\sigma(\\mathbf{w} \\cdot \\mathbf{x}_i) \\right\\} \\mathbf{x}^\\intercal_i \\tag{3}\n",
        "$$\n",
        "\n",
        "- 위 식은 $\\mathbf{w}$에 대한 그래디언트는 $\\mathbf{x}_i$를 더해서 만들어지는데 이 때 각 $\\mathbf{x}_i$에 대한 덧셈 가중치를 $\\mathbf{x}_i$에 대한 모델의 출력이 만들어내는 에러 $\\left\\{-y_i + \\sigma(\\mathbf{w} \\cdot \\mathbf{x}_i) \\right\\}$만큼 설정한다는 의미\n",
        "\n",
        "- 위 손실 함수의 그래디언트를 계산하는 코드를 `Loss.backward(self, w, X, y)`에 코딩한다.\n",
        "\n",
        "- `self.dw`에 그래디언트 값 저장\n",
        "\n",
        "- 넘파이를 활용해도 좋고 `for`문으로 직관적으로 구현해도 좋음"
      ],
      "metadata": {
        "id": "YsvMNW7kVuKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 손실함수 백워드 패스 규제\n",
        "\n",
        "- `self.dw`에 위 식(2)가 계산되었다면 규제항의 미분값을 추가\n",
        "\n",
        "- 규제 항의 미분은 다음과 같음\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial \\mathbf{w}} \\left(\\frac{\\lambda}{2}  \\lVert  \\mathbf{w} \\rVert^2 \\right) = \\lambda \\mathbf{w} \\tag{4}\n",
        "$$\n",
        "\n",
        "- 따라서 최종 그래디언트는 다음과 같음\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial \\mathbf{w}} L_{\\text{reg}}(\\mathbf{w}) = \\frac{\\partial}{\\partial \\mathbf{w}} L(\\mathbf{w}) + \\lambda \\mathbf{w} \\tag{5}\n",
        "$$\n",
        "\n",
        "- `Loss.backward()`함수는 최종적으로 위 식 값을 반환"
      ],
      "metadata": {
        "id": "NWyFBoBYVuCl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M02Qx4GbWkxs"
      },
      "outputs": [],
      "source": [
        "def logistic(x):\n",
        "    return 1.0 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "class Loss :\n",
        "    def __init__(self, X, y, lamda):\n",
        "        self.X = X # ( 데이터 개수 N, 데이터 차원 D )\n",
        "        self.N = X.shape[0]\n",
        "        self.y = y # ( 데이터 개수 N, )\n",
        "        self.lamda = lamda\n",
        "\n",
        "        # 우리가 구해야 하는 파라미터 w, 최초는 무작위로 설정\n",
        "        self.w = np.random.randn(X.shape[1])\n",
        "\n",
        "        # 코스트 초기화\n",
        "        self.cost = 0.0\n",
        "\n",
        "        # 미분 계수 초기화\n",
        "        self.dw = 0.0\n",
        "\n",
        "    def forward(self, w, X, y):\n",
        "        \"\"\"\n",
        "        아래 식에 맞춰 로스 함수를 코딩\n",
        "        - sum_i( y_i*log(sigma(w*x_i)) + (1-y_i)*log(1-sigma(w*x_i)) )\n",
        "        \"\"\"\n",
        "\n",
        "        # self.cost에 손실함수 값을 계산해서 대입\n",
        "        # (N,)                   (N,D), (D,)\n",
        "        sigma = logistic( np.dot(  X,    w  ) )\n",
        "        self.cost = - np.sum( y * np.log(sigma) + (1-y)*np.log(1-sigma) )\n",
        "\n",
        "        # regularization\n",
        "        # reg 변수에 규제 항 값을 대입하고\n",
        "        # self.cost에 reg를 추가해서 반환\n",
        "        reg = (self.lamda/2)*np.sum(w**2)\n",
        "        self.cost += reg\n",
        "\n",
        "        return self.cost\n",
        "\n",
        "    def backward(self, w, X, y):\n",
        "        # self.dw에 규제 없는 손실함수의 미분 값을 대입\n",
        "        # sum_i { -y_i + sigma(w^T * x_i) } x_i^T\n",
        "        # self.dw = np.dot( X.T, -y + logistic(np.dot(X, w)) )\n",
        "\n",
        "        self.dw = np.zeros(X.shape[1])\n",
        "        for i in range(self.N):\n",
        "            self.dw += (logistic(np.dot(X[i], w)) - y[i]) * X[i]\n",
        "\n",
        "        # regularization\n",
        "        # reg 변수에 규제 항 미분 값을 대입하고\n",
        "        # self.dw에 reg를 추가해서 반환\n",
        "        reg = self.lamda * w\n",
        "        self.dw += reg\n",
        "\n",
        "        return self.dw\n",
        "\n",
        "    def train(self, lr=0.01, epoch=100, verbose=False, verbose_step=100) :\n",
        "        # lr: 러닝 레이트\n",
        "        # epoch: 에폭수\n",
        "        # verbose: 학습 과정 중간 출력 여부 지정\n",
        "        # verbose_step: 학습 과정 출력 간격\n",
        "\n",
        "        ep_mean_costs = []\n",
        "\n",
        "        # 전체 에폭만큼 루프를 돌면서\n",
        "        for i in range(epoch):\n",
        "            costs = []\n",
        "\n",
        "            # [1] self.w에 대해서 포워드 함수값을 계산해서 self.cost를 계산\n",
        "            self.forward(self.w, self.X, self.y)\n",
        "\n",
        "            # [2] self.w에 대한 미분계수 self.dw를 계산\n",
        "            self.backward(self.w, self.X, self.y)\n",
        "\n",
        "            # [3] self.dw를 이용하여 self.w를 업데이트(스탭 이동)\n",
        "            #     학습률은 lr을 사용\n",
        "            self.w = self.w - lr * self.dw\n",
        "\n",
        "            # 줄어드는 코스트를 저장해서 반환하기 위해 계산된 코스트를 저장\n",
        "            costs.append(self.cost)\n",
        "\n",
        "            mean_costs = np.mean(costs)\n",
        "\n",
        "            # 중간 과정을 출력해야 한다면 여기서 간단히 출력\n",
        "            if verbose and ((i+1) % verbose_step == 0):\n",
        "                print( f\"Epoch {i+1:3d}: Cost={mean_costs:.5f}, lr={lr:.5f}\" )\n",
        "\n",
        "            # 한 에폭에 발생한 로스를 평균하여 에폭당 로스로 저장\n",
        "            ep_mean_costs.append(mean_costs)\n",
        "\n",
        "        return ep_mean_costs\n",
        "\n",
        "###############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sanity check\n",
        "\n",
        "- 학습에 있어서 정확한 그래디언트가 제일 중요히기 때문에 작성된 `backward()`함수가 정확히 그래디언트를 계산하는지 반드시 체크해야 함\n",
        "\n",
        "- 체크 방법은 수치 미분 함수와 `backward()`가 게산하는 그래디언트가 유사한지 확인하는 것"
      ],
      "metadata": {
        "id": "TcOhPqrgOoQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def numer_deriv(x, fun, args=(), h=None, method=\"central\", dtype='float32'):\n",
        "    \"\"\"\n",
        "    Find the first derivative of a function at a point x.\n",
        "\n",
        "    x     : The point at which derivative is found.\n",
        "    fun   : Input function.\n",
        "    args  : Tuple extra arguments passed to fun.\n",
        "    h     : Step size\n",
        "    method: 'central' or 'forward'\n",
        "    dtype : Data type of gradient, must be set to 'longdouble'\n",
        "            if numerically unstable.\n",
        "    \"\"\"\n",
        "\n",
        "    # [1] 필요변수 초기화\n",
        "    scalar = False\n",
        "    m = 1\n",
        "\n",
        "    # [2] x가 스칼라인지 벡터인지 확인 스칼라면 무조건 벡터로 고치고 시작\n",
        "    if not hasattr(type(x), '__iter__'):\n",
        "        x = np.array([x])\n",
        "        scalar = True\n",
        "\n",
        "    # [3] x 타입을 디폴트로 float32로 변경\n",
        "    x = x.astype(dtype)\n",
        "\n",
        "    # [4] 미분 계수 초기화\n",
        "    g = np.zeros(x.shape[0]).astype(dtype)\n",
        "\n",
        "    # [5] 미분계수를 변수 개수만큼 루프를 돌면서 구하기\n",
        "    for i in range(x.shape[0]) :\n",
        "        # [5-1]변경된 위치를 설정할 변수 두개를 준비\n",
        "        # dx1[i], dx2[i]로 각 변수의 요소를 접근할 수 있음\n",
        "        dx1 = x.copy()\n",
        "        dx2 = x.copy()\n",
        "\n",
        "        # [5-2] h 결정 대충 변수의 1%정도\n",
        "        # https://en.wikipedia.org/wiki/Numerical_differentiation\n",
        "        if h == None:\n",
        "            h = np.sqrt(np.finfo(np.float32).eps) if x[i] == 0.0 else np.sqrt(np.finfo(np.float32).eps) * x[i]\n",
        "\n",
        "        ##########################################\n",
        "        # WRITE YOUR CODE HERE\n",
        "        # [5-3*] dx1[i] 변경\n",
        "        dx1[i] += h\n",
        "\n",
        "        # [5-4*] central이면 dx[2]도 함께 변경, 이 때 m = 2로 설정해서\n",
        "        # [5-5]에서 g[i]를 계산할 때 2h로 나누게 해야함.\n",
        "        if method == \"central\":\n",
        "            dx2[i] -= h\n",
        "            m = 2\n",
        "\n",
        "        # [5-5*] 미분계수 계산\n",
        "        # fun이 스칼라 함수여도 요소 한개짜리 ndarray로 전달되면 문제없이\n",
        "        # 호출되므로 여기거 fun은 fun(dx1, *args) 식으로 호출되면 됨\n",
        "        g[i] = (fun(dx1, *args) - fun(dx2, *args)) / (m*h)\n",
        "        ##########################################\n",
        "\n",
        "    # [6] 결과값 리턴\n",
        "    if scalar:\n",
        "        return g[0]\n",
        "    else:\n",
        "        return g"
      ],
      "metadata": {
        "id": "u4ah1DbwOCAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위 수치 미분 함수를 사용해서 $D=10$인 가상의 데이터 두개에 대해서 유효성 검사를 수행\n",
        "\n",
        "- 아래 셀을 실행했을 때 `numerical ∇J(w)`의 결과와 `∇J(w)` 결과가 거의 유사하게 나와야 함(두 결과는 숫자 열개로 구성된 벡터)"
      ],
      "metadata": {
        "id": "Tb_-4birfRaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가상의 개, 고양이 데이터 X와 정답 레이블 y를 정의\n",
        "X_train_sanity = np.array(\n",
        "    [[0,1,0,0,1,1,1,0,0,0],   # 개     1\n",
        "     [1,0,0,1,1,1,1,0,1,0]])  # 고양이 0\n",
        "y_train_sanity = np.array([1, 0])\n",
        "\n",
        "# 데이터 차원\n",
        "D = 10\n",
        "\n",
        "loss_sanity = Loss(X_train_sanity, y_train_sanity, lamda=0.001)\n",
        "\n",
        "w = np.random.rand(D)\n",
        "print(\"w\")\n",
        "print(w)\n",
        "\n",
        "# forward(self, w, X, y)\n",
        "print(\"\\nL(w)\")\n",
        "print(loss_sanity.forward(w, X_train_sanity, y_train_sanity))\n",
        "\n",
        "print(\"\\nnumerical ∇L(w)\")\n",
        "print(numer_deriv(w, loss_sanity.forward,\n",
        "                  args=(X_train_sanity, y_train_sanity)))\n",
        "\n",
        "print(\"\\n∇L(w)\")\n",
        "print(loss_sanity.backward(w, X_train_sanity, y_train_sanity))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dl-NiGcOR7i",
        "outputId": "4fccd7f3-f2f8-4dfa-a260-fecfe358b00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w\n",
            "[0.80270183 0.65224675 0.92962012 0.26111291 0.98268921 0.8213555\n",
            " 0.36506248 0.68074464 0.32267618 0.75975879]\n",
            "\n",
            "L(w)\n",
            "3.644043248826353\n",
            "\n",
            "numerical ∇L(w)\n",
            "[ 9.7308481e-01 -5.5532090e-02  9.2951319e-04  9.7243911e-01\n",
            "  9.1708082e-01  9.1691911e-01  9.1636425e-01  6.8089744e-04\n",
            "  9.7250062e-01  7.5961143e-04]\n",
            "\n",
            "∇L(w)\n",
            "[ 9.73031676e-01 -5.55288515e-02  9.29620123e-04  9.72490087e-01\n",
            "  9.17030565e-01  9.16869232e-01  9.16412939e-01  6.80744640e-04\n",
            "  9.72551650e-01  7.59758786e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sanity check가 통과 되었으면 아래 셀을 수행하여 학습 진행"
      ],
      "metadata": {
        "id": "bp8CgAyKfxCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 학습"
      ],
      "metadata": {
        "id": "QdNcz5AfsTy0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ0NF5gUWkxt"
      },
      "outputs": [],
      "source": [
        "# 분류기를 만들고\n",
        "loss = Loss(X_train, y_train, lamda=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsQwS8CjWkxt",
        "outputId": "4b8728c0-aa3c-44e6-a2be-b458b9483527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   5: Cost=1723.07667, lr=0.01000\n",
            "Epoch  10: Cost=1349.00455, lr=0.01000\n",
            "Epoch  15: Cost=1109.36634, lr=0.01000\n",
            "Epoch  20: Cost=950.15946, lr=0.01000\n",
            "Epoch  25: Cost=838.55593, lr=0.01000\n",
            "Epoch  30: Cost=753.30507, lr=0.01000\n",
            "Epoch  35: Cost=684.90480, lr=0.01000\n",
            "Epoch  40: Cost=628.48307, lr=0.01000\n",
            "Epoch  45: Cost=581.02396, lr=0.01000\n",
            "Epoch  50: Cost=540.48268, lr=0.01000\n",
            "Epoch  55: Cost=505.40598, lr=0.01000\n",
            "Epoch  60: Cost=474.72834, lr=0.01000\n",
            "Epoch  65: Cost=447.64869, lr=0.01000\n",
            "Epoch  70: Cost=423.55180, lr=0.01000\n",
            "Epoch  75: Cost=401.95653, lr=0.01000\n",
            "Epoch  80: Cost=382.48084, lr=0.01000\n",
            "Epoch  85: Cost=364.81751, lr=0.01000\n",
            "Epoch  90: Cost=348.71682, lr=0.01000\n",
            "Epoch  95: Cost=333.97391, lr=0.01000\n",
            "Epoch 100: Cost=320.41933, lr=0.01000\n",
            "Epoch 105: Cost=307.91178, lr=0.01000\n",
            "Epoch 110: Cost=296.33257, lr=0.01000\n",
            "Epoch 115: Cost=285.58120, lr=0.01000\n",
            "Epoch 120: Cost=275.57191, lr=0.01000\n",
            "Epoch 125: Cost=266.23098, lr=0.01000\n",
            "Epoch 130: Cost=257.49457, lr=0.01000\n",
            "Epoch 135: Cost=249.30702, lr=0.01000\n",
            "Epoch 140: Cost=241.61948, lr=0.01000\n",
            "Epoch 145: Cost=234.38887, lr=0.01000\n",
            "Epoch 150: Cost=227.57695, lr=0.01000\n"
          ]
        }
      ],
      "source": [
        "# 학습시킨다.\n",
        "costs = loss.train(lr=0.01, epoch=150, verbose=True, verbose_step=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "OpVhG7rxWkxt",
        "outputId": "3bd8cdc7-55d6-4e87-844c-6fbda233fd19"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 학습하는 동안 기록한 로스를 시각화\n",
        "plt.plot(costs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 미리 만들어 놓은 사이킷런 `SGDClassifier`와 성능 비교를 통해 코드 유효성 확인\n",
        "\n",
        "- 결과는 아래와 같이 나오는데 `precision`, `recall`이 두 모델에서 비슷하게 나와야 함\n",
        "```\n",
        "              precision    recall  f1-score   support\n",
        "         0.0       0.98      0.99      0.99      2561\n",
        "         1.0       0.97      0.90      0.93       439\n",
        "    \n",
        "      accuracy                         0.98      3000\n",
        "     macro avg     0.97      0.95      0.96      3000\n",
        "weighted avg     0.98      0.98      0.98      3000\n",
        "```"
      ],
      "metadata": {
        "id": "w5kSxSA6hjbV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "javgk6XnWkxt",
        "outputId": "31562e94-bdc3-447e-ef24-383198f1a136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn SGDClassifier\n",
            "-----------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.99      2561\n",
            "         1.0       0.97      0.90      0.94       439\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.98      0.95      0.96      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n",
            "[[2548   13]\n",
            " [  42  397]]\n",
            "\n",
            "Ours\n",
            "-----------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2561\n",
            "         1.0       0.97      0.94      0.96       439\n",
            "\n",
            "    accuracy                           0.99      3000\n",
            "   macro avg       0.98      0.97      0.97      3000\n",
            "weighted avg       0.99      0.99      0.99      3000\n",
            "\n",
            "[[2547   14]\n",
            " [  25  414]]\n"
          ]
        }
      ],
      "source": [
        "print(\"scikit-learn SGDClassifier\")\n",
        "print(\"-----------------------------------------------------\")\n",
        "y_train_pred = logreg.predict(X_train)\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "print(confusion_matrix(y_train, y_train_pred))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Ours\")\n",
        "print(\"-----------------------------------------------------\")\n",
        "y_train_pred = np.array([logistic(np.dot(X, loss.w)) for X in X_train])\n",
        "y_train_pred  = y_train_pred > 0.50\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "print(confusion_matrix(y_train, y_train_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY3dvnakWkxu",
        "outputId": "84d42add-c090-45cf-e036-6465f9185fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn SGDClassifier\n",
            "-----------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.96      0.96       359\n",
            "         1.0       0.76      0.73      0.75        64\n",
            "\n",
            "    accuracy                           0.92       423\n",
            "   macro avg       0.86      0.85      0.85       423\n",
            "weighted avg       0.92      0.92      0.92       423\n",
            "\n",
            "[[344  15]\n",
            " [ 17  47]]\n",
            "\n",
            "Ours\n",
            "-----------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.95      0.95       359\n",
            "         1.0       0.72      0.72      0.72        64\n",
            "\n",
            "    accuracy                           0.91       423\n",
            "   macro avg       0.83      0.83      0.83       423\n",
            "weighted avg       0.91      0.91      0.91       423\n",
            "\n",
            "[[341  18]\n",
            " [ 18  46]]\n"
          ]
        }
      ],
      "source": [
        "print(\"scikit-learn SGDClassifier\")\n",
        "print(\"-----------------------------------------------------\")\n",
        "y_test_pred = logreg.predict(X_test)\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Ours\")\n",
        "print(\"-----------------------------------------------------\")\n",
        "y_test_pred = np.array([logistic(np.dot(X, loss.w)) for X in X_test])\n",
        "y_test_pred  = y_test_pred > 0.50\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(confusion_matrix(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gOQJnGrNbD3y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pd",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}