{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/%EC%9E%A5%EA%B8%B0/poly_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsPUdwzL6k5h"
      },
      "source": [
        "### 5기분들 코드"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG_7aEWnN1bI",
        "outputId": "aabff169-cf34-421e-a747-0461b25a07e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xmu__DU2Tp72"
      },
      "outputs": [],
      "source": [
        "# 5기 분들 git파일 다운로드\n",
        "# !git clone https://github.com/doh0106/Poly-Encoder.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cxfaBBYbqoD",
        "outputId": "94369616-fa58-4779-c7a7-5c6b6a73bb5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구글 공유폴더 이용해서 학습하기\n",
        "- 구글 드라이브에서 공유폴더 바로가기 생성 > 구글 드라이브 마운트 > MyDrive에서 공유 폴더 바로가기 선택 > 현재 경로 공유 폴더 경로로 변경"
      ],
      "metadata": {
        "id": "E_Pe8llmOBxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Poly-Encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4D_W1J6N_q-",
        "outputId": "a98f2e04-e2d8-4180-adf4-5d684a530995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Poly-Encoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WtBhCJASvXI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "817efc24-5898-4f36-8e6e-89ed3ae89ec2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index               q1                 q2                   q3  \\\n",
              "0         0          '가'의 의미            '가'의 뜻?          '가'의 뜻이 뭐야?   \n",
              "1         1        '가계'의 예시?           '가계'의 뜻?     '가계'의 뜻과 예문이 뭐야?   \n",
              "2         2   '가곡'의 예시문을 알려줘      '가곡'의 의미가 뭐야?           '가곡'의 의미는?   \n",
              "3         3   '가공'의 예시문을 알려줘          '가공'의 의미?       '가공'의 뜻을 알려주세요   \n",
              "4         4     '가구'의 뜻이 뭐야?       '가구'의 뜻을 말해봐   '가구'의 뜻과 예시를 알려주세요   \n",
              "...     ...              ...                ...                  ...   \n",
              "4697   4697        '힐끗'의 예시?   '힐끗'의 뜻과 예시가 뭐야?             '힐끗'의 뜻?   \n",
              "4698   4698   '힘겹다'의 예시를 말해줘  '힘겹다'의 뜻과 예문을 알려줘  '힘겹다'의 뜻과 예시를 알려주세요   \n",
              "4699   4699       '힘없다'의 의미?      '힘없다'의 뜻, 예문?          '힘없다'의 의미는?   \n",
              "4700   4700  '힘입다'의 뜻을 알려주세요          '힘입다'의 뜻?       '힘입다'의 예시는 뭐야?   \n",
              "4701   4701       '힘주다'의 예시?         '힘주다'의 의미?        '힘주다'의 뜻을 말해봐   \n",
              "\n",
              "                   q4                                         answer  \n",
              "0       '가'의 뜻을 알려주세요                            어떤 장소나 물건의 둘레나 끝부분.  \n",
              "1          '가계'의 의미는?                                   경제 단위로서의 가정.  \n",
              "2        '가곡'의 뜻을 말해봐  시를 피리, 가야금, 거문고 등 전통 악기에 맞춰서 노래하는 한국의 전통 성악곡.  \n",
              "3            '가공'의 뜻?             기술이나 힘 등을 이용해 원료나 재료를 새로운 제품으로 만듦.  \n",
              "4      '가구'의 예시문을 알려줘                           한 집에서 함께 사는 사람들의 집단.  \n",
              "...               ...                                            ...  \n",
              "4697    '힐끗'의 예시를 말해줘                                슬쩍 한 번 흘겨보는 모양.  \n",
              "4698    '힘겹다'의 뜻을 말해봐                 힘이 모자라거나 부족하여 어떤 일을 당해 내기 어렵다.  \n",
              "4699    '힘없다'의 뜻이 뭐야?                                 기운이나 의욕 등이 없다.  \n",
              "4700    '힘입다'의 뜻과 예시?                                  어떤 힘의 도움을 받다.  \n",
              "4701  '힘주다'의 예시문을 알려줘                               힘이나 기운을 한곳으로 몰다.  \n",
              "\n",
              "[4702 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a9778bc-dc0b-43ab-8002-866efe2881ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>q1</th>\n",
              "      <th>q2</th>\n",
              "      <th>q3</th>\n",
              "      <th>q4</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>'가'의 의미</td>\n",
              "      <td>'가'의 뜻?</td>\n",
              "      <td>'가'의 뜻이 뭐야?</td>\n",
              "      <td>'가'의 뜻을 알려주세요</td>\n",
              "      <td>어떤 장소나 물건의 둘레나 끝부분.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>'가계'의 예시?</td>\n",
              "      <td>'가계'의 뜻?</td>\n",
              "      <td>'가계'의 뜻과 예문이 뭐야?</td>\n",
              "      <td>'가계'의 의미는?</td>\n",
              "      <td>경제 단위로서의 가정.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>'가곡'의 예시문을 알려줘</td>\n",
              "      <td>'가곡'의 의미가 뭐야?</td>\n",
              "      <td>'가곡'의 의미는?</td>\n",
              "      <td>'가곡'의 뜻을 말해봐</td>\n",
              "      <td>시를 피리, 가야금, 거문고 등 전통 악기에 맞춰서 노래하는 한국의 전통 성악곡.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>'가공'의 예시문을 알려줘</td>\n",
              "      <td>'가공'의 의미?</td>\n",
              "      <td>'가공'의 뜻을 알려주세요</td>\n",
              "      <td>'가공'의 뜻?</td>\n",
              "      <td>기술이나 힘 등을 이용해 원료나 재료를 새로운 제품으로 만듦.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>'가구'의 뜻이 뭐야?</td>\n",
              "      <td>'가구'의 뜻을 말해봐</td>\n",
              "      <td>'가구'의 뜻과 예시를 알려주세요</td>\n",
              "      <td>'가구'의 예시문을 알려줘</td>\n",
              "      <td>한 집에서 함께 사는 사람들의 집단.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4697</th>\n",
              "      <td>4697</td>\n",
              "      <td>'힐끗'의 예시?</td>\n",
              "      <td>'힐끗'의 뜻과 예시가 뭐야?</td>\n",
              "      <td>'힐끗'의 뜻?</td>\n",
              "      <td>'힐끗'의 예시를 말해줘</td>\n",
              "      <td>슬쩍 한 번 흘겨보는 모양.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4698</th>\n",
              "      <td>4698</td>\n",
              "      <td>'힘겹다'의 예시를 말해줘</td>\n",
              "      <td>'힘겹다'의 뜻과 예문을 알려줘</td>\n",
              "      <td>'힘겹다'의 뜻과 예시를 알려주세요</td>\n",
              "      <td>'힘겹다'의 뜻을 말해봐</td>\n",
              "      <td>힘이 모자라거나 부족하여 어떤 일을 당해 내기 어렵다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4699</th>\n",
              "      <td>4699</td>\n",
              "      <td>'힘없다'의 의미?</td>\n",
              "      <td>'힘없다'의 뜻, 예문?</td>\n",
              "      <td>'힘없다'의 의미는?</td>\n",
              "      <td>'힘없다'의 뜻이 뭐야?</td>\n",
              "      <td>기운이나 의욕 등이 없다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4700</th>\n",
              "      <td>4700</td>\n",
              "      <td>'힘입다'의 뜻을 알려주세요</td>\n",
              "      <td>'힘입다'의 뜻?</td>\n",
              "      <td>'힘입다'의 예시는 뭐야?</td>\n",
              "      <td>'힘입다'의 뜻과 예시?</td>\n",
              "      <td>어떤 힘의 도움을 받다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4701</th>\n",
              "      <td>4701</td>\n",
              "      <td>'힘주다'의 예시?</td>\n",
              "      <td>'힘주다'의 의미?</td>\n",
              "      <td>'힘주다'의 뜻을 말해봐</td>\n",
              "      <td>'힘주다'의 예시문을 알려줘</td>\n",
              "      <td>힘이나 기운을 한곳으로 몰다.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4702 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a9778bc-dc0b-43ab-8002-866efe2881ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0a9778bc-dc0b-43ab-8002-866efe2881ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0a9778bc-dc0b-43ab-8002-866efe2881ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-16ae299a-ef1c-48a3-adb3-b7383f9bb391\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16ae299a-ef1c-48a3-adb3-b7383f9bb391')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-16ae299a-ef1c-48a3-adb3-b7383f9bb391 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/Poly-Encoder/datasets/train.pickle', 'rb') as f:\n",
        "    corona = pickle.load(f)\n",
        "corona"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQT9pKy_YUtO",
        "outputId": "e9f38a87-d1cb-4b0b-854f-3347d0ad1c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-02 04:50:13.501396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(bert_model='models/bert/', eval=False, model_type='bert', output_dir='result/train1', train_dir='datasets/', train_file='train.pickle', valid_file='train.pickle', test_file='test.pickle', neg_size=15, use_pretrain=True, architecture='poly', max_contexts_length=256, max_response_length=64, train_batch_size=2, eval_batch_size=2, print_freq=100, poly_m=16, learning_rate=5e-05, weight_decay=0.01, warmup_steps=100, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, seed=12345, gradient_accumulation_steps=1, fp16=False, fp16_opt_level='O1', gpu=0)\n",
            "================================================================================\n",
            "Train dir: datasets/\n",
            "Output dir: result/train1\n",
            "================================================================================\n",
            "100% 4702/4702 [00:11<00:00, 398.67it/s]\n",
            "100% 4702/4702 [00:14<00:00, 324.83it/s]\n",
            "Loading parameters from models/bert/pytorch_model.bin\n",
            "Some weights of BertModel were not initialized from the model checkpoint at models/bert/ and are newly initialized: ['encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 42001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "모델 투 디바이스  cuda\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Print freq: 100 Eval freq: 1000\n",
            "  4% 100/2351 [00:18<06:54,  5.43it/s]100 4.620238346285187\n",
            "  9% 200/2351 [00:33<05:59,  5.98it/s]200 3.3967899790476075\n",
            " 13% 300/2351 [00:49<05:32,  6.16it/s]300 2.955061507949916\n",
            " 17% 400/2351 [01:05<05:12,  6.25it/s]400 2.7640878928487655\n",
            " 21% 500/2351 [01:20<04:54,  6.29it/s]500 2.6271977207986636\n",
            " 26% 600/2351 [01:36<04:37,  6.30it/s]600 2.596692080259478\n",
            " 30% 700/2351 [01:52<04:23,  6.26it/s]700 2.5839482028576146\n",
            " 34% 800/2351 [02:08<04:08,  6.25it/s]800 2.5173484516941245\n",
            " 38% 900/2351 [02:25<03:52,  6.24it/s]900 2.4647538730802223\n",
            " 43% 1000/2351 [02:41<03:36,  6.23it/s]1000 2.4459635414602237\n",
            "Global Step 1000 VAL res:\n",
            " {'train_loss': 2.4459635414602237, 'eval_loss': 2.7725865938266963, 'R1': 0.07422373458102935, 'R2': 0.13845172267120373, 'R5': 0.33836665248830283, 'R10': 0.6448319863887707, 'MRR': 0.2026627951659853, 'epoch': 1, 'global_step': 1000}\n",
            "[Saving at] result/train1/poly_16_pytorch_model.bin\n",
            " 47% 1100/2351 [08:52<25:59,  1.25s/it]1100 2.4045378548135474\n",
            " 51% 1200/2351 [09:08<17:35,  1.09it/s]1200 2.3870227152256605\n",
            " 55% 1300/2351 [09:25<12:04,  1.45it/s]1300 2.3551146130743796\n",
            " 60% 1400/2351 [09:41<08:24,  1.88it/s]1400 2.324932594338565\n",
            " 64% 1500/2351 [09:58<05:57,  2.38it/s]1500 2.3052254900739837\n",
            " 68% 1600/2351 [10:14<04:18,  2.91it/s]1600 2.267568603298278\n",
            " 72% 1700/2351 [10:31<03:08,  3.45it/s]1700 2.238574479731238\n",
            " 77% 1800/2351 [10:47<02:19,  3.96it/s]1800 2.215352350991323\n",
            " 81% 1900/2351 [11:04<01:42,  4.42it/s]1900 2.183675581280044\n",
            " 85% 2000/2351 [11:20<01:13,  4.81it/s]2000 2.151754005186725\n",
            "Global Step 2000 VAL res:\n",
            " {'train_loss': 2.151754005186725, 'eval_loss': 2.7725885578643914, 'R1': 0.13845172267120373, 'R2': 0.226286686516376, 'R5': 0.4410888983411314, 'R10': 0.7216078264568269, 'MRR': 0.1562358369807328, 'epoch': 1, 'global_step': 2000}\n",
            " 89% 2100/2351 [17:32<05:16,  1.26s/it]2100 2.1275001559446434\n",
            " 94% 2200/2351 [17:49<02:20,  1.07it/s]2200 2.101921889003451\n",
            " 98% 2300/2351 [18:05<00:35,  1.42it/s]2300 2.0847474738538425\n",
            "[Saving at] result/train1/poly_16_pytorch_model_train.bin\n",
            "Epoch 1, Global Step 2351 VAL res:\n",
            " {'train_loss': 2.072546678977123, 'eval_loss': 2.772589014622061, 'R1': 0.13568694172692472, 'R2': 0.21565291365376435, 'R5': 0.4287537218205019, 'R10': 0.7216078264568269, 'MRR': 0.16083228323498422, 'epoch': 1, 'global_step': 2351}\n",
            " 98% 2300/2351 [24:11<00:32,  1.58it/s]\n"
          ]
        }
      ],
      "source": [
        "# train poly_encoder\n",
        "!python utils/run.py \\\n",
        "--model_type bert \\\n",
        "--bert_model models/bert/ \\\n",
        "--output_dir result/train1 \\\n",
        "--train_dir datasets/ \\\n",
        "--train_file train.pickle \\\n",
        "--valid_file train.pickle \\\n",
        "--use_pretrain \\\n",
        "--architecture poly \\\n",
        "--poly_m 16 \\\n",
        "--train_batch_size 2 \\\n",
        "--eval_batch_size 2 \\\n",
        "--max_contexts_length 256 \\\n",
        "--max_response_length 64 \\\n",
        "--num_train_epochs 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLQF_xyvXD9s"
      },
      "outputs": [],
      "source": [
        "# !python3 /content/Poly-Encoder/utils/train.ipynb -bert_model /your/pretrained/model/dir/content/Poly-Encoder/models/bert/pytorch_model.bin --output_dir /your/ckpt/dir --train_dir /your/data/dir --use_pretrain --architecture poly --poly_m 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9A2NNPEcKqD",
        "outputId": "2ff99f3e-b7e8-4805-d538-a01dc8e1eabe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-02 09:57:27.541340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(bert_model='models/bert/', eval=False, model_type='bert', output_dir='result/train2', train_dir='datasets/', train_file='train.pickle', valid_file='train.pickle', test_file='test.pickle', neg_size=15, use_pretrain=True, architecture='cross', max_contexts_length=256, max_response_length=64, train_batch_size=2, eval_batch_size=2, print_freq=100, poly_m=0, learning_rate=5e-05, weight_decay=0.01, warmup_steps=100, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, seed=12345, gradient_accumulation_steps=1, fp16=False, fp16_opt_level='O1', gpu=0)\n",
            "================================================================================\n",
            "Train dir: datasets/\n",
            "Output dir: result/train2\n",
            "================================================================================\n",
            "100% 4702/4702 [00:11<00:00, 407.29it/s]\n",
            "100% 4702/4702 [00:11<00:00, 410.04it/s]\n",
            "Loading parameters from models/bert/pytorch_model.bin\n",
            "Some weights of BertModel were not initialized from the model checkpoint at models/bert/ and are newly initialized: ['encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 42001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "모델 투 디바이스  cuda\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Print freq: 100 Eval freq: 1000\n",
            "  4% 100/2351 [02:35<58:29,  1.56s/it]100 2.8207827019691467\n",
            "  9% 200/2351 [05:11<55:44,  1.55s/it]200 2.802168763875961\n",
            " 13% 300/2351 [07:46<53:04,  1.55s/it]300 2.8039517307281496\n",
            " 17% 400/2351 [10:21<50:27,  1.55s/it]400 2.8048128193616866\n",
            " 21% 500/2351 [12:56<47:52,  1.55s/it]500 2.804119679927826\n",
            " 26% 600/2351 [15:31<45:16,  1.55s/it]600 2.8005900716781618\n",
            " 30% 700/2351 [18:06<42:42,  1.55s/it]700 2.7994172617367337\n",
            " 34% 800/2351 [20:41<40:07,  1.55s/it]800 2.797754172086716\n",
            " 38% 900/2351 [23:17<37:31,  1.55s/it]900 2.793265232510037\n",
            " 43% 1000/2351 [25:52<34:55,  1.55s/it]1000 2.7955605659484863\n",
            "Global Step 1000 VAL res:\n",
            " {'train_loss': 2.7955605659484863, 'eval_loss': 2.7725858220847197, 'R1': 0.0635899617184177, 'R2': 0.12824330072309656, 'R5': 0.3194385367928541, 'R10': 0.6282433007230965, 'MRR': 0.2141307027605411, 'epoch': 1, 'global_step': 1000}\n",
            "[Saving at] result/train2/cross_0_pytorch_model.bin\n",
            " 47% 1100/2351 [49:59<1:54:48,  5.51s/it]1100 2.794742460901087\n",
            " 51% 1200/2351 [52:34<1:22:33,  4.30s/it]1200 2.7939337120453516\n",
            " 55% 1300/2351 [55:09<1:00:46,  3.47s/it]1300 2.794628192828252\n",
            " 60% 1400/2351 [57:44<45:47,  2.89s/it]  1400 2.79530410698482\n",
            " 64% 1500/2351 [1:00:19<35:15,  2.49s/it]1500 2.7944648237228393\n",
            " 68% 1600/2351 [1:02:54<27:35,  2.20s/it]1600 2.793758424371481\n",
            " 72% 1700/2351 [1:05:29<21:46,  2.01s/it]1700 2.79318101644516\n",
            " 77% 1800/2351 [1:08:04<17:10,  1.87s/it]1800 2.79367295689053\n"
          ]
        }
      ],
      "source": [
        "# train cross_encoder\n",
        "!python utils/run.py \\\n",
        "--model_type bert \\\n",
        "--bert_model models/bert/ \\\n",
        "--output_dir result/train2 \\\n",
        "--train_dir datasets/ \\\n",
        "--train_file train.pickle \\\n",
        "--valid_file train.pickle \\\n",
        "--use_pretrain \\\n",
        "--architecture cross \\\n",
        "--train_batch_size 2 \\\n",
        "--eval_batch_size 2 \\\n",
        "--max_contexts_length 256 \\\n",
        "--max_response_length 64 \\\n",
        "--num_train_epochs 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "4cflSu3RcG2P",
        "outputId": "a1df3613-a205-4f1d-c294-b63650b65f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Poly-Encoder/result/train2/pytorch_model.bin\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0b73b5839f61>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0membedding_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcross_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoad_Model_Tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cross'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mpoly_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoad_Model_Tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'poly'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mcross_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Poly-Encoder/utils/model_for_inference.py\u001b[0m in \u001b[0;36mLoad_Model_Tokenizer\u001b[0;34m(model_path, model_type, bert_type)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_model_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizerClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Poly-Encoder/result/train2/pytorch_model.bin'"
          ]
        }
      ],
      "source": [
        "from utils.model_for_inference import Load_Model_Tokenizer\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "\n",
        "CATEGORY = 'corona' # normal, water, corona\n",
        "\n",
        "poly_dir = '/content/Poly-Encoder/result/train1'\n",
        "cross_dir = '/content/Poly-Encoder/result/train2'\n",
        "emb_dir = '/content/Poly-Encoder/datasets'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# q1, q2, q3, q4, text, embedding(text에 대한) 저장 pickle / 하지만 현재는 inference에 text와 embedding만 사용\n",
        "# with open(os.path.join(emb_dir, f'{CATEGORY}_with_text.pickle'), 'rb') as f:\n",
        "with open(os.path.join(emb_dir, f'{CATEGORY}_with_text.pickle'), 'rb') as f:\n",
        "    embedding_df = pickle.load(f)\n",
        "\n",
        "cross_encoder, _ = Load_Model_Tokenizer(cross_dir, model_type='cross') # train폴더에서 pytorch_model.bin으로 이름 변경\n",
        "poly_encoder, tokenizer = Load_Model_Tokenizer(poly_dir, model_type='poly')# train폴더에서 pytorch_model.bin으로 이름 변경\n",
        "cross_encoder.to(device)\n",
        "poly_encoder.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6BbwqCaq5QC"
      },
      "outputs": [],
      "source": [
        "# # 코드 셀 <undefined>\n",
        "# # # %% [code]\n",
        "from utils.inference import Callcenter\n",
        "import numpy as np\n",
        "\n",
        "call_center = Callcenter(poly_encoder=poly_encoder, cross_encoder=cross_encoder,\n",
        "                        tokenizer=tokenizer, emb_df=embedding_df, device=device, topk=5)\n",
        "\n",
        "query = '집에 가고 싶다.'\n",
        "top_k_cross_scores, top_k_indices= call_center.inference(query)\n",
        "# poly score가 가장 높은 k개의 답변 값들의 cross score 값과 index들 반환\n",
        "\n",
        "top_cross_idx = top_k_indices[np.argmax(top_k_cross_scores)]\n",
        "# k개의 답변들 중 cross score가 가장 높은 idx이용하여 최종 답변 산출\n",
        "answer = embedding_df['text'].iloc[top_cross_idx]\n",
        "\n",
        "print(f'질문 : {query}')\n",
        "print(f'답변 : {answer}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ludNeKZGrwS8",
        "outputId": "a479342a-c52b-41f6-df87-c21008b8a6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "질문 : 코로나19.\n",
            "답변 :   네, 코로나십구 장기화로 매출 타격을 받고 있는 소상공인과 생계에 어려움을 겪는 취약계층 가구를 대상으로 도시가스 요금 납부 부담을 완화해드립니다.\n"
          ]
        }
      ],
      "source": [
        "# # 코드 셀 <undefined>\n",
        "# # # %% [code]\n",
        "from utils.inference import Callcenter\n",
        "import numpy as np\n",
        "\n",
        "call_center = Callcenter(poly_encoder=poly_encoder, cross_encoder=cross_encoder,\n",
        "                        tokenizer=tokenizer, emb_df=embedding_df, device=device, topk=5)\n",
        "\n",
        "query = '코로나19.'\n",
        "top_k_cross_scores, top_k_indices= call_center.inference(query)\n",
        "# poly score가 가장 높은 k개의 답변 값들의 cross score 값과 index들 반환\n",
        "\n",
        "top_cross_idx = top_k_indices[np.argmax(top_k_cross_scores)]\n",
        "# k개의 답변들 중 cross score가 가장 높은 idx이용하여 최종 답변 산출\n",
        "answer = embedding_df['text'].iloc[top_cross_idx]\n",
        "\n",
        "print(f'질문 : {query}')\n",
        "print(f'답변 : {answer}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IRnirFkca7r",
        "outputId": "d157ed1a-9442-4ef3-c6cc-7ba1cf6b8e60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(bert_model='models/bert', text_path='/path/to/카테고리별답변들.txt', max_response_length=128, output_dir='/path/to/카테고리별embedding.pickle', model_type='bert', gpu=1)\n",
            "Loading parameters from models/bert/pytorch_model.bin\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 42001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Poly-Encoder/utils/text_2_emb.py\", line 84, in <module>\n",
            "    model.load_state_dict(model_state_dict)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2041, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for PolyEncoder:\n",
            "\tMissing key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\", \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\", \"poly_code_embeddings.weight\". \n",
            "\tUnexpected key(s) in state_dict: \"encoder.embeddings.position_ids\", \"encoder.embeddings.word_embeddings.weight\", \"encoder.embeddings.position_embeddings.weight\", \"encoder.embeddings.token_type_embeddings.weight\", \"encoder.embeddings.LayerNorm.weight\", \"encoder.embeddings.LayerNorm.bias\", \"encoder.encoder.layer.0.attention.self.query.weight\", \"encoder.encoder.layer.0.attention.self.query.bias\", \"encoder.encoder.layer.0.attention.self.key.weight\", \"encoder.encoder.layer.0.attention.self.key.bias\", \"encoder.encoder.layer.0.attention.self.value.weight\", \"encoder.encoder.layer.0.attention.self.value.bias\", \"encoder.encoder.layer.0.attention.output.dense.weight\", \"encoder.encoder.layer.0.attention.output.dense.bias\", \"encoder.encoder.layer.0.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.0.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.0.intermediate.dense.weight\", \"encoder.encoder.layer.0.intermediate.dense.bias\", \"encoder.encoder.layer.0.output.dense.weight\", \"encoder.encoder.layer.0.output.dense.bias\", \"encoder.encoder.layer.0.output.LayerNorm.weight\", \"encoder.encoder.layer.0.output.LayerNorm.bias\", \"encoder.encoder.layer.1.attention.self.query.weight\", \"encoder.encoder.layer.1.attention.self.query.bias\", \"encoder.encoder.layer.1.attention.self.key.weight\", \"encoder.encoder.layer.1.attention.self.key.bias\", \"encoder.encoder.layer.1.attention.self.value.weight\", \"encoder.encoder.layer.1.attention.self.value.bias\", \"encoder.encoder.layer.1.attention.output.dense.weight\", \"encoder.encoder.layer.1.attention.output.dense.bias\", \"encoder.encoder.layer.1.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.1.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.1.intermediate.dense.weight\", \"encoder.encoder.layer.1.intermediate.dense.bias\", \"encoder.encoder.layer.1.output.dense.weight\", \"encoder.encoder.layer.1.output.dense.bias\", \"encoder.encoder.layer.1.output.LayerNorm.weight\", \"encoder.encoder.layer.1.output.LayerNorm.bias\", \"encoder.encoder.layer.2.attention.self.query.weight\", \"encoder.encoder.layer.2.attention.self.query.bias\", \"encoder.encoder.layer.2.attention.self.key.weight\", \"encoder.encoder.layer.2.attention.self.key.bias\", \"encoder.encoder.layer.2.attention.self.value.weight\", \"encoder.encoder.layer.2.attention.self.value.bias\", \"encoder.encoder.layer.2.attention.output.dense.weight\", \"encoder.encoder.layer.2.attention.output.dense.bias\", \"encoder.encoder.layer.2.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.2.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.2.intermediate.dense.weight\", \"encoder.encoder.layer.2.intermediate.dense.bias\", \"encoder.encoder.layer.2.output.dense.weight\", \"encoder.encoder.layer.2.output.dense.bias\", \"encoder.encoder.layer.2.output.LayerNorm.weight\", \"encoder.encoder.layer.2.output.LayerNorm.bias\", \"encoder.encoder.layer.3.attention.self.query.weight\", \"encoder.encoder.layer.3.attention.self.query.bias\", \"encoder.encoder.layer.3.attention.self.key.weight\", \"encoder.encoder.layer.3.attention.self.key.bias\", \"encoder.encoder.layer.3.attention.self.value.weight\", \"encoder.encoder.layer.3.attention.self.value.bias\", \"encoder.encoder.layer.3.attention.output.dense.weight\", \"encoder.encoder.layer.3.attention.output.dense.bias\", \"encoder.encoder.layer.3.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.3.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.3.intermediate.dense.weight\", \"encoder.encoder.layer.3.intermediate.dense.bias\", \"encoder.encoder.layer.3.output.dense.weight\", \"encoder.encoder.layer.3.output.dense.bias\", \"encoder.encoder.layer.3.output.LayerNorm.weight\", \"encoder.encoder.layer.3.output.LayerNorm.bias\", \"encoder.encoder.layer.4.attention.self.query.weight\", \"encoder.encoder.layer.4.attention.self.query.bias\", \"encoder.encoder.layer.4.attention.self.key.weight\", \"encoder.encoder.layer.4.attention.self.key.bias\", \"encoder.encoder.layer.4.attention.self.value.weight\", \"encoder.encoder.layer.4.attention.self.value.bias\", \"encoder.encoder.layer.4.attention.output.dense.weight\", \"encoder.encoder.layer.4.attention.output.dense.bias\", \"encoder.encoder.layer.4.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.4.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.4.intermediate.dense.weight\", \"encoder.encoder.layer.4.intermediate.dense.bias\", \"encoder.encoder.layer.4.output.dense.weight\", \"encoder.encoder.layer.4.output.dense.bias\", \"encoder.encoder.layer.4.output.LayerNorm.weight\", \"encoder.encoder.layer.4.output.LayerNorm.bias\", \"encoder.encoder.layer.5.attention.self.query.weight\", \"encoder.encoder.layer.5.attention.self.query.bias\", \"encoder.encoder.layer.5.attention.self.key.weight\", \"encoder.encoder.layer.5.attention.self.key.bias\", \"encoder.encoder.layer.5.attention.self.value.weight\", \"encoder.encoder.layer.5.attention.self.value.bias\", \"encoder.encoder.layer.5.attention.output.dense.weight\", \"encoder.encoder.layer.5.attention.output.dense.bias\", \"encoder.encoder.layer.5.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.5.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.5.intermediate.dense.weight\", \"encoder.encoder.layer.5.intermediate.dense.bias\", \"encoder.encoder.layer.5.output.dense.weight\", \"encoder.encoder.layer.5.output.dense.bias\", \"encoder.encoder.layer.5.output.LayerNorm.weight\", \"encoder.encoder.layer.5.output.LayerNorm.bias\", \"encoder.encoder.layer.6.attention.self.query.weight\", \"encoder.encoder.layer.6.attention.self.query.bias\", \"encoder.encoder.layer.6.attention.self.key.weight\", \"encoder.encoder.layer.6.attention.self.key.bias\", \"encoder.encoder.layer.6.attention.self.value.weight\", \"encoder.encoder.layer.6.attention.self.value.bias\", \"encoder.encoder.layer.6.attention.output.dense.weight\", \"encoder.encoder.layer.6.attention.output.dense.bias\", \"encoder.encoder.layer.6.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.6.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.6.intermediate.dense.weight\", \"encoder.encoder.layer.6.intermediate.dense.bias\", \"encoder.encoder.layer.6.output.dense.weight\", \"encoder.encoder.layer.6.output.dense.bias\", \"encoder.encoder.layer.6.output.LayerNorm.weight\", \"encoder.encoder.layer.6.output.LayerNorm.bias\", \"encoder.encoder.layer.7.attention.self.query.weight\", \"encoder.encoder.layer.7.attention.self.query.bias\", \"encoder.encoder.layer.7.attention.self.key.weight\", \"encoder.encoder.layer.7.attention.self.key.bias\", \"encoder.encoder.layer.7.attention.self.value.weight\", \"encoder.encoder.layer.7.attention.self.value.bias\", \"encoder.encoder.layer.7.attention.output.dense.weight\", \"encoder.encoder.layer.7.attention.output.dense.bias\", \"encoder.encoder.layer.7.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.7.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.7.intermediate.dense.weight\", \"encoder.encoder.layer.7.intermediate.dense.bias\", \"encoder.encoder.layer.7.output.dense.weight\", \"encoder.encoder.layer.7.output.dense.bias\", \"encoder.encoder.layer.7.output.LayerNorm.weight\", \"encoder.encoder.layer.7.output.LayerNorm.bias\", \"encoder.encoder.layer.8.attention.self.query.weight\", \"encoder.encoder.layer.8.attention.self.query.bias\", \"encoder.encoder.layer.8.attention.self.key.weight\", \"encoder.encoder.layer.8.attention.self.key.bias\", \"encoder.encoder.layer.8.attention.self.value.weight\", \"encoder.encoder.layer.8.attention.self.value.bias\", \"encoder.encoder.layer.8.attention.output.dense.weight\", \"encoder.encoder.layer.8.attention.output.dense.bias\", \"encoder.encoder.layer.8.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.8.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.8.intermediate.dense.weight\", \"encoder.encoder.layer.8.intermediate.dense.bias\", \"encoder.encoder.layer.8.output.dense.weight\", \"encoder.encoder.layer.8.output.dense.bias\", \"encoder.encoder.layer.8.output.LayerNorm.weight\", \"encoder.encoder.layer.8.output.LayerNorm.bias\", \"encoder.encoder.layer.9.attention.self.query.weight\", \"encoder.encoder.layer.9.attention.self.query.bias\", \"encoder.encoder.layer.9.attention.self.key.weight\", \"encoder.encoder.layer.9.attention.self.key.bias\", \"encoder.encoder.layer.9.attention.self.value.weight\", \"encoder.encoder.layer.9.attention.self.value.bias\", \"encoder.encoder.layer.9.attention.output.dense.weight\", \"encoder.encoder.layer.9.attention.output.dense.bias\", \"encoder.encoder.layer.9.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.9.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.9.intermediate.dense.weight\", \"encoder.encoder.layer.9.intermediate.dense.bias\", \"encoder.encoder.layer.9.output.dense.weight\", \"encoder.encoder.layer.9.output.dense.bias\", \"encoder.encoder.layer.9.output.LayerNorm.weight\", \"encoder.encoder.layer.9.output.LayerNorm.bias\", \"encoder.encoder.layer.10.attention.self.query.weight\", \"encoder.encoder.layer.10.attention.self.query.bias\", \"encoder.encoder.layer.10.attention.self.key.weight\", \"encoder.encoder.layer.10.attention.self.key.bias\", \"encoder.encoder.layer.10.attention.self.value.weight\", \"encoder.encoder.layer.10.attention.self.value.bias\", \"encoder.encoder.layer.10.attention.output.dense.weight\", \"encoder.encoder.layer.10.attention.output.dense.bias\", \"encoder.encoder.layer.10.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.10.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.10.intermediate.dense.weight\", \"encoder.encoder.layer.10.intermediate.dense.bias\", \"encoder.encoder.layer.10.output.dense.weight\", \"encoder.encoder.layer.10.output.dense.bias\", \"encoder.encoder.layer.10.output.LayerNorm.weight\", \"encoder.encoder.layer.10.output.LayerNorm.bias\", \"encoder.encoder.layer.11.attention.self.query.weight\", \"encoder.encoder.layer.11.attention.self.query.bias\", \"encoder.encoder.layer.11.attention.self.key.weight\", \"encoder.encoder.layer.11.attention.self.key.bias\", \"encoder.encoder.layer.11.attention.self.value.weight\", \"encoder.encoder.layer.11.attention.self.value.bias\", \"encoder.encoder.layer.11.attention.output.dense.weight\", \"encoder.encoder.layer.11.attention.output.dense.bias\", \"encoder.encoder.layer.11.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.11.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.11.intermediate.dense.weight\", \"encoder.encoder.layer.11.intermediate.dense.bias\", \"encoder.encoder.layer.11.output.dense.weight\", \"encoder.encoder.layer.11.output.dense.bias\", \"encoder.encoder.layer.11.output.LayerNorm.weight\", \"encoder.encoder.layer.11.output.LayerNorm.bias\", \"encoder.pooler.dense.weight\", \"encoder.pooler.dense.bias\", \"decoder.bert.embeddings.position_ids\", \"decoder.bert.embeddings.word_embeddings.weight\", \"decoder.bert.embeddings.position_embeddings.weight\", \"decoder.bert.embeddings.token_type_embeddings.weight\", \"decoder.bert.embeddings.LayerNorm.weight\", \"decoder.bert.embeddings.LayerNorm.bias\", \"decoder.bert.encoder.layer.0.attention.self.query.weight\", \"decoder.bert.encoder.layer.0.attention.self.query.bias\", \"decoder.bert.encoder.layer.0.attention.self.key.weight\", \"decoder.bert.encoder.layer.0.attention.self.key.bias\", \"decoder.bert.encoder.layer.0.attention.self.value.weight\", \"decoder.bert.encoder.layer.0.attention.self.value.bias\", \"decoder.bert.encoder.layer.0.attention.output.dense.weight\", \"decoder.bert.encoder.layer.0.attention.output.dense.bias\", \"decoder.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.0.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.0.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.0.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.0.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.0.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.0.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.0.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.0.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.0.intermediate.dense.weight\", \"decoder.bert.encoder.layer.0.intermediate.dense.bias\", \"decoder.bert.encoder.layer.0.output.dense.weight\", \"decoder.bert.encoder.layer.0.output.dense.bias\", \"decoder.bert.encoder.layer.0.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.0.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.1.attention.self.query.weight\", \"decoder.bert.encoder.layer.1.attention.self.query.bias\", \"decoder.bert.encoder.layer.1.attention.self.key.weight\", \"decoder.bert.encoder.layer.1.attention.self.key.bias\", \"decoder.bert.encoder.layer.1.attention.self.value.weight\", \"decoder.bert.encoder.layer.1.attention.self.value.bias\", \"decoder.bert.encoder.layer.1.attention.output.dense.weight\", \"decoder.bert.encoder.layer.1.attention.output.dense.bias\", \"decoder.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.1.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.1.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.1.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.1.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.1.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.1.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.1.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.1.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.1.intermediate.dense.weight\", \"decoder.bert.encoder.layer.1.intermediate.dense.bias\", \"decoder.bert.encoder.layer.1.output.dense.weight\", \"decoder.bert.encoder.layer.1.output.dense.bias\", \"decoder.bert.encoder.layer.1.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.1.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.2.attention.self.query.weight\", \"decoder.bert.encoder.layer.2.attention.self.query.bias\", \"decoder.bert.encoder.layer.2.attention.self.key.weight\", \"decoder.bert.encoder.layer.2.attention.self.key.bias\", \"decoder.bert.encoder.layer.2.attention.self.value.weight\", \"decoder.bert.encoder.layer.2.attention.self.value.bias\", \"decoder.bert.encoder.layer.2.attention.output.dense.weight\", \"decoder.bert.encoder.layer.2.attention.output.dense.bias\", \"decoder.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.2.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.2.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.2.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.2.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.2.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.2.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.2.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.2.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.2.intermediate.dense.weight\", \"decoder.bert.encoder.layer.2.intermediate.dense.bias\", \"decoder.bert.encoder.layer.2.output.dense.weight\", \"decoder.bert.encoder.layer.2.output.dense.bias\", \"decoder.bert.encoder.layer.2.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.2.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.3.attention.self.query.weight\", \"decoder.bert.encoder.layer.3.attention.self.query.bias\", \"decoder.bert.encoder.layer.3.attention.self.key.weight\", \"decoder.bert.encoder.layer.3.attention.self.key.bias\", \"decoder.bert.encoder.layer.3.attention.self.value.weight\", \"decoder.bert.encoder.layer.3.attention.self.value.bias\", \"decoder.bert.encoder.layer.3.attention.output.dense.weight\", \"decoder.bert.encoder.layer.3.attention.output.dense.bias\", \"decoder.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.3.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.3.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.3.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.3.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.3.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.3.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.3.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.3.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.3.intermediate.dense.weight\", \"decoder.bert.encoder.layer.3.intermediate.dense.bias\", \"decoder.bert.encoder.layer.3.output.dense.weight\", \"decoder.bert.encoder.layer.3.output.dense.bias\", \"decoder.bert.encoder.layer.3.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.3.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.4.attention.self.query.weight\", \"decoder.bert.encoder.layer.4.attention.self.query.bias\", \"decoder.bert.encoder.layer.4.attention.self.key.weight\", \"decoder.bert.encoder.layer.4.attention.self.key.bias\", \"decoder.bert.encoder.layer.4.attention.self.value.weight\", \"decoder.bert.encoder.layer.4.attention.self.value.bias\", \"decoder.bert.encoder.layer.4.attention.output.dense.weight\", \"decoder.bert.encoder.layer.4.attention.output.dense.bias\", \"decoder.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.4.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.4.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.4.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.4.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.4.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.4.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.4.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.4.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.4.intermediate.dense.weight\", \"decoder.bert.encoder.layer.4.intermediate.dense.bias\", \"decoder.bert.encoder.layer.4.output.dense.weight\", \"decoder.bert.encoder.layer.4.output.dense.bias\", \"decoder.bert.encoder.layer.4.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.4.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.5.attention.self.query.weight\", \"decoder.bert.encoder.layer.5.attention.self.query.bias\", \"decoder.bert.encoder.layer.5.attention.self.key.weight\", \"decoder.bert.encoder.layer.5.attention.self.key.bias\", \"decoder.bert.encoder.layer.5.attention.self.value.weight\", \"decoder.bert.encoder.layer.5.attention.self.value.bias\", \"decoder.bert.encoder.layer.5.attention.output.dense.weight\", \"decoder.bert.encoder.layer.5.attention.output.dense.bias\", \"decoder.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.5.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.5.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.5.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.5.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.5.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.5.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.5.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.5.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.5.intermediate.dense.weight\", \"decoder.bert.encoder.layer.5.intermediate.dense.bias\", \"decoder.bert.encoder.layer.5.output.dense.weight\", \"decoder.bert.encoder.layer.5.output.dense.bias\", \"decoder.bert.encoder.layer.5.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.5.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.6.attention.self.query.weight\", \"decoder.bert.encoder.layer.6.attention.self.query.bias\", \"decoder.bert.encoder.layer.6.attention.self.key.weight\", \"decoder.bert.encoder.layer.6.attention.self.key.bias\", \"decoder.bert.encoder.layer.6.attention.self.value.weight\", \"decoder.bert.encoder.layer.6.attention.self.value.bias\", \"decoder.bert.encoder.layer.6.attention.output.dense.weight\", \"decoder.bert.encoder.layer.6.attention.output.dense.bias\", \"decoder.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.6.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.6.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.6.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.6.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.6.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.6.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.6.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.6.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.6.intermediate.dense.weight\", \"decoder.bert.encoder.layer.6.intermediate.dense.bias\", \"decoder.bert.encoder.layer.6.output.dense.weight\", \"decoder.bert.encoder.layer.6.output.dense.bias\", \"decoder.bert.encoder.layer.6.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.6.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.7.attention.self.query.weight\", \"decoder.bert.encoder.layer.7.attention.self.query.bias\", \"decoder.bert.encoder.layer.7.attention.self.key.weight\", \"decoder.bert.encoder.layer.7.attention.self.key.bias\", \"decoder.bert.encoder.layer.7.attention.self.value.weight\", \"decoder.bert.encoder.layer.7.attention.self.value.bias\", \"decoder.bert.encoder.layer.7.attention.output.dense.weight\", \"decoder.bert.encoder.layer.7.attention.output.dense.bias\", \"decoder.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.7.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.7.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.7.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.7.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.7.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.7.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.7.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.7.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.7.intermediate.dense.weight\", \"decoder.bert.encoder.layer.7.intermediate.dense.bias\", \"decoder.bert.encoder.layer.7.output.dense.weight\", \"decoder.bert.encoder.layer.7.output.dense.bias\", \"decoder.bert.encoder.layer.7.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.7.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.8.attention.self.query.weight\", \"decoder.bert.encoder.layer.8.attention.self.query.bias\", \"decoder.bert.encoder.layer.8.attention.self.key.weight\", \"decoder.bert.encoder.layer.8.attention.self.key.bias\", \"decoder.bert.encoder.layer.8.attention.self.value.weight\", \"decoder.bert.encoder.layer.8.attention.self.value.bias\", \"decoder.bert.encoder.layer.8.attention.output.dense.weight\", \"decoder.bert.encoder.layer.8.attention.output.dense.bias\", \"decoder.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.8.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.8.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.8.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.8.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.8.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.8.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.8.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.8.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.8.intermediate.dense.weight\", \"decoder.bert.encoder.layer.8.intermediate.dense.bias\", \"decoder.bert.encoder.layer.8.output.dense.weight\", \"decoder.bert.encoder.layer.8.output.dense.bias\", \"decoder.bert.encoder.layer.8.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.8.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.9.attention.self.query.weight\", \"decoder.bert.encoder.layer.9.attention.self.query.bias\", \"decoder.bert.encoder.layer.9.attention.self.key.weight\", \"decoder.bert.encoder.layer.9.attention.self.key.bias\", \"decoder.bert.encoder.layer.9.attention.self.value.weight\", \"decoder.bert.encoder.layer.9.attention.self.value.bias\", \"decoder.bert.encoder.layer.9.attention.output.dense.weight\", \"decoder.bert.encoder.layer.9.attention.output.dense.bias\", \"decoder.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.9.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.9.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.9.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.9.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.9.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.9.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.9.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.9.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.9.intermediate.dense.weight\", \"decoder.bert.encoder.layer.9.intermediate.dense.bias\", \"decoder.bert.encoder.layer.9.output.dense.weight\", \"decoder.bert.encoder.layer.9.output.dense.bias\", \"decoder.bert.encoder.layer.9.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.9.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.10.attention.self.query.weight\", \"decoder.bert.encoder.layer.10.attention.self.query.bias\", \"decoder.bert.encoder.layer.10.attention.self.key.weight\", \"decoder.bert.encoder.layer.10.attention.self.key.bias\", \"decoder.bert.encoder.layer.10.attention.self.value.weight\", \"decoder.bert.encoder.layer.10.attention.self.value.bias\", \"decoder.bert.encoder.layer.10.attention.output.dense.weight\", \"decoder.bert.encoder.layer.10.attention.output.dense.bias\", \"decoder.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.10.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.10.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.10.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.10.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.10.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.10.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.10.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.10.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.10.intermediate.dense.weight\", \"decoder.bert.encoder.layer.10.intermediate.dense.bias\", \"decoder.bert.encoder.layer.10.output.dense.weight\", \"decoder.bert.encoder.layer.10.output.dense.bias\", \"decoder.bert.encoder.layer.10.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.10.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.11.attention.self.query.weight\", \"decoder.bert.encoder.layer.11.attention.self.query.bias\", \"decoder.bert.encoder.layer.11.attention.self.key.weight\", \"decoder.bert.encoder.layer.11.attention.self.key.bias\", \"decoder.bert.encoder.layer.11.attention.self.value.weight\", \"decoder.bert.encoder.layer.11.attention.self.value.bias\", \"decoder.bert.encoder.layer.11.attention.output.dense.weight\", \"decoder.bert.encoder.layer.11.attention.output.dense.bias\", \"decoder.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.11.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.11.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.11.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.11.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.11.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.11.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.11.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.11.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.11.intermediate.dense.weight\", \"decoder.bert.encoder.layer.11.intermediate.dense.bias\", \"decoder.bert.encoder.layer.11.output.dense.weight\", \"decoder.bert.encoder.layer.11.output.dense.bias\", \"decoder.bert.encoder.layer.11.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.11.output.LayerNorm.bias\", \"decoder.cls.predictions.bias\", \"decoder.cls.predictions.transform.dense.weight\", \"decoder.cls.predictions.transform.dense.bias\", \"decoder.cls.predictions.transform.LayerNorm.weight\", \"decoder.cls.predictions.transform.LayerNorm.bias\", \"decoder.cls.predictions.decoder.weight\", \"decoder.cls.predictions.decoder.bias\". \n"
          ]
        }
      ],
      "source": [
        "# infrence\n",
        "!python utils/text_2_emb.py \\\n",
        "--model_type bert \\\n",
        "--bert_model models/bert \\\n",
        "--text_path /path/to/카테고리별답변들.txt \\\n",
        "--output_dir /path/to/카테고리별embedding.pickle \\\n",
        "--gpu 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXvT31FJ6pt1"
      },
      "source": [
        "### 원본 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0jlAQDWUcRx"
      },
      "outputs": [],
      "source": [
        "parlai interactive -m transformer/polyencoder \\\n",
        "    -mf zoo:pretrained_transformers/model_poly/model \\\n",
        "    --encode-candidate-vecs true \\\n",
        "    --eval-candidates fixed  \\\n",
        "    --fixed-candidates-path data/models/pretrained_transformers/convai_trainset_cands.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4rhBueuqhW4"
      },
      "source": [
        "### 다른 git코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubdinMpPqlWU",
        "outputId": "bb54ed92-b536-459d-d907-5a8e149fa488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: You must specify a repository to clone.\n",
            "\n",
            "usage: git clone [<options>] [--] <repo> [<dir>]\n",
            "\n",
            "    -v, --verbose         be more verbose\n",
            "    -q, --quiet           be more quiet\n",
            "    --progress            force progress reporting\n",
            "    --reject-shallow      don't clone shallow repository\n",
            "    -n, --no-checkout     don't create a checkout\n",
            "    --bare                create a bare repository\n",
            "    --mirror              create a mirror repository (implies bare)\n",
            "    -l, --local           to clone from a local repository\n",
            "    --no-hardlinks        don't use local hardlinks, always copy\n",
            "    -s, --shared          setup as shared repository\n",
            "    --recurse-submodules[=<pathspec>]\n",
            "                          initialize submodules in the clone\n",
            "    --recursive ...       alias of --recurse-submodules\n",
            "    -j, --jobs <n>        number of submodules cloned in parallel\n",
            "    --template <template-directory>\n",
            "                          directory from which templates will be used\n",
            "    --reference <repo>    reference repository\n",
            "    --reference-if-able <repo>\n",
            "                          reference repository\n",
            "    --dissociate          use --reference only while cloning\n",
            "    -o, --origin <name>   use <name> instead of 'origin' to track upstream\n",
            "    -b, --branch <branch>\n",
            "                          checkout <branch> instead of the remote's HEAD\n",
            "    -u, --upload-pack <path>\n",
            "                          path to git-upload-pack on the remote\n",
            "    --depth <depth>       create a shallow clone of that depth\n",
            "    --shallow-since <time>\n",
            "                          create a shallow clone since a specific time\n",
            "    --shallow-exclude <revision>\n",
            "                          deepen history of shallow clone, excluding rev\n",
            "    --single-branch       clone only one branch, HEAD or --branch\n",
            "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
            "    --shallow-submodules  any cloned submodules will be shallow\n",
            "    --separate-git-dir <gitdir>\n",
            "                          separate git dir from working tree\n",
            "    -c, --config <key=value>\n",
            "                          set config inside the new repository\n",
            "    --server-option <server-specific>\n",
            "                          option to transmit\n",
            "    -4, --ipv4            use IPv4 addresses only\n",
            "    -6, --ipv6            use IPv6 addresses only\n",
            "    --filter <args>       object filtering\n",
            "    --remote-submodules   any cloned submodules will use their remote-tracking branch\n",
            "    --sparse              initialize sparse-checkout file to include only files at root\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JehVX2Mcq9tw"
      },
      "outputs": [],
      "source": [
        "python3 run.py --bert_model bert_model/ --output_dir output_dstc7/ --train_dir dstc7/ --use_pretrain --architecture poly --poly_m 16 --eval"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBmX/utYX84+X09R9hSCmb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}