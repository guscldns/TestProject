{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMXD8C+lgO+ur09dtK/MvL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/%EA%B3%BC%EC%A0%9C%20/%EC%9D%B4%EB%AF%B8%EC%A7%80_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6yZiy7Lnzyv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from PIL import Image\n",
        "#dir(tf.keras.applications)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 불러오기"
      ],
      "metadata": {
        "id": "SEjcw2_i541G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.resnet50.ResNet50(include_top=True, input_shape = (224, 224 ,3), weights = 'imagenet')"
      ],
      "metadata": {
        "id": "eUk89dzaNh02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a282a8-0d73-4540-f172-714d5b662304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102967424/102967424 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "CnOe1JBjD42i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 윈도우 생성"
      ],
      "metadata": {
        "id": "xWwqW0tTcvpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class percents:\n",
        "    def __init__(self):\n",
        "        self.model = tf.keras.applications.resnet50.ResNet50(include_top=True, input_shape=(224, 224, 3), weights='imagenet')\n",
        "\n",
        "    def test(self, image_path, window_div_list = [1,2,4,8]):\n",
        "        self.image_path = image_path\n",
        "\n",
        "        image = PIL.Image.open(self.image_path)\n",
        "        Xdim, Ydim = image.size\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for window_div in window_div_list:\n",
        "            stride = max(Xdim // window_div, 1)\n",
        "            x_size = int(Xdim / window_div)\n",
        "            y_size = int(Ydim / window_div)\n",
        "\n",
        "            result = {}\n",
        "\n",
        "            for h in range(0, Xdim, stride):\n",
        "                for w in range(0, Ydim, stride):\n",
        "                    img_cropped = image.crop((w, h, y_size + w, x_size + h))\n",
        "                    win_img = np.array(img_cropped.resize((int(224), int(224))))\n",
        "                    input_img = np.expand_dims(win_img, axis=0)\n",
        "                    predictions = self.model.predict(input_img)\n",
        "                    predicted_class = tf.keras.applications.resnet50.decode_predictions(predictions, top=3)\n",
        "\n",
        "                    for i in range(3):\n",
        "                        if predicted_class[0][i][1] in result:\n",
        "                            result[predicted_class[0][i][1]] += predicted_class[0][i][2] / (window_div ** 2)\n",
        "                        else:\n",
        "                            result[predicted_class[0][i][1]] = predicted_class[0][i][2]\n",
        "\n",
        "            results[window_div] = dict(sorted(result.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "BL8oWLq6Lkvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확률\n",
        "class percents:\n",
        "    def __init__(self):\n",
        "        self.model = tf.keras.applications.resnet50.ResNet50(include_top=True, input_shape = (224, 224 ,3), weights = 'imagenet')\n",
        "\n",
        "    def test(self, image_path, window_div, stride ):\n",
        "        super().__init__()\n",
        "        self.image_path = image_path\n",
        "        self.window_div = window_div\n",
        "        self.stride = stride\n",
        "\n",
        "        image = PIL.Image.open(self.image_path)\n",
        "        Xdim, Ydim = image.size\n",
        "        x_size = int(Xdim/self.window_div) # 세로\n",
        "        y_size = int(Ydim/self.window_div) # 가로\n",
        "\n",
        "        result= {}\n",
        "        for h in range(0, Xdim, self.stride): # 세로\n",
        "            for w in range(0, Ydim, self.stride): # 가로\n",
        "                img_cropped = image.crop((w, h, y_size+w, x_size+h,))\n",
        "                win_img = np.array(img_cropped.resize((int(224), int(224))))\n",
        "                input_img = np.expand_dims(win_img, axis=0)\n",
        "                predictions = model.predict(input_img)\n",
        "                predicted_class = tf.keras.applications.resnet50.decode_predictions(predictions, top=3)\n",
        "                for i in range(3):\n",
        "                    if predicted_class[0][i][1] in result:\n",
        "                        result[predicted_class[0][i][1]] += predicted_class[0][i][2]/(window_div**2)\n",
        "                    else:\n",
        "                        result[predicted_class[0][i][1]] = predicted_class[0][i][2]\n",
        "\n",
        "        result = dict(sorted(result.items(), key=lambda x:x[1], reverse=True))\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "f__2oCR81PAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈도\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "class num_img:\n",
        "    def __init__(self):\n",
        "        self.model = tf.keras.applications.resnet50.ResNet50(include_top=True, input_shape=(224, 224, 3), weights='imagenet')\n",
        "\n",
        "    def num(self, image_path, window_div, stride):\n",
        "        self.image_path = image_path\n",
        "        self.window_div = window_div\n",
        "        self.stride = stride\n",
        "        image = PIL.Image.open(self.image_path)\n",
        "        Xdim, Ydim = image.size\n",
        "        x_size = int(Xdim / self.window_div)  # 세로\n",
        "        y_size = int(Ydim / self.window_div)  # 가로\n",
        "\n",
        "        result = defaultdict(int)\n",
        "        for h in range(0, Xdim, self.stride):  # 세로\n",
        "            for w in range(0, Ydim, self.stride):  # 가로\n",
        "                img_cropped = image.crop((w, h, y_size + w, x_size + h,))\n",
        "                win_img = np.array(img_cropped.resize((int(224), int(224))))\n",
        "                input_img = np.expand_dims(win_img, axis=0)\n",
        "                predictions = self.model.predict(input_img)\n",
        "                predicted_class = tf.keras.applications.resnet50.decode_predictions(predictions, top=3)\n",
        "                for i in range(3):\n",
        "                    result[predicted_class[0][i][1]] += 1\n",
        "\n",
        "        result = dict(sorted(result.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "owBoRgpj49Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트"
      ],
      "metadata": {
        "id": "p8GgBaH1exGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결과"
      ],
      "metadata": {
        "id": "h76FryvloKXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/1591569183791.jpg'\n",
        "\n",
        "a = []\n",
        "model = percents()\n",
        "b = model.test(image_path, window_div_list = [1,2,4,8])\n"
      ],
      "metadata": {
        "id": "4GDkXaH9POQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "id": "43ex7RggGSir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img"
      ],
      "metadata": {
        "id": "QEQmDvy9BoNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = {}\n",
        "\n",
        "for a in range(len(windows)):\n",
        "    input_img = np.expand_dims(windows[a], axis=0)\n",
        "    predictions = model.predict(input_img)\n",
        "    predicted_class = tf.keras.applications.resnet50.decode_predictions(predictions, top=1)[0][0]\n",
        "    result[predicted_class[1]] = predicted_class[2]\n",
        "\n",
        "len(result)"
      ],
      "metadata": {
        "id": "Zcl9-aK0z6Gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caaec2b2-bd96-458e-aeb3-2ea43e4c06ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n",
            "1/1 [==============================] - 0s 178ms/step\n",
            "1/1 [==============================] - 0s 174ms/step\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "1/1 [==============================] - 0s 264ms/step\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "1/1 [==============================] - 0s 167ms/step\n",
            "1/1 [==============================] - 0s 186ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = dict(sorted(result.items(), key=lambda x:x[1], reverse=True))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0-cv_fggmgo",
        "outputId": "70ea1fd0-0c84-4f9a-ca46-c375d51a2e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nematode': 0.14914486, 'dishwasher': 0.05083472}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVLnsG94s40s",
        "outputId": "a63af205-a0d8-4d05-ad5f-2d1a2733e62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4864, 3648)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = image.resize((int(224), int(224)), resample= Image.BILINEAR) # 기본 : Image.BICUBIC"
      ],
      "metadata": {
        "id": "wPwfE4bB9AuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT 코드"
      ],
      "metadata": {
        "id": "bin1RB2_6k7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "\n",
        "# 모델 지정\n",
        "class ObjectRecognizer:\n",
        "    def __init__(self):\n",
        "        self.model = ResNet50(include_top=True, weights='imagenet')\n",
        "\n",
        "    # 윈도우 크기 설정\n",
        "    def sliding_window(self, image, window_size, stride):\n",
        "        window_width, window_height = window_size\n",
        "        stride_x, stride_y = stride\n",
        "\n",
        "        for y in range(0, image.shape[0] - window_height + 1, stride_y):\n",
        "            for x in range(0, image.shape[1] - window_width + 1, stride_x):\n",
        "                yield (x, y, image[y:y + window_height, x:x + window_width])\n",
        "\n",
        "    # 실제 데이터로 실험\n",
        "    def recognize_objects(self, image, window_sizes, stride=(100, 100)):\n",
        "        results = []\n",
        "        for size in window_sizes:\n",
        "            window_width = int(image.shape[1] * size)\n",
        "            window_height = int(image.shape[0] * size)\n",
        "\n",
        "            for (x, y, window) in self.sliding_window(image, (window_width, window_height), stride):\n",
        "                resized_window = cv2.resize(window, (224, 224))\n",
        "                preprocessed_window = preprocess_input(np.expand_dims(resized_window, axis=0))\n",
        "\n",
        "                preds = self.model.predict(preprocessed_window)\n",
        "                decoded_preds = decode_predictions(preds, top=5)[0]\n",
        "\n",
        "                results.extend(decoded_preds)\n",
        "\n",
        "        # 확률에 따라 내림차순으로 결과 정렬\n",
        "        results.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # 중복된 결과를 필터링하고 각 고유한 결과에 대한 확률 합계를 계산\n",
        "        unique_results = {}\n",
        "        for result in results:\n",
        "            label = result[1]\n",
        "            prob = result[2]\n",
        "\n",
        "            if label not in unique_results:\n",
        "                unique_results[label] = prob\n",
        "            else:\n",
        "                unique_results[label] += prob\n",
        "\n",
        "        # 합계 확률에 따라 내림차순으로 고유 결과 정렬\n",
        "        sorted_results = sorted(unique_results.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # 확률과 함께 상위 5개의 고유 결과 출력\n",
        "        top_5_results = sorted_results[:5]\n",
        "\n",
        "        return top_5_results"
      ],
      "metadata": {
        "id": "uoepGCc47Hdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Object Recognizer 클래스의 인스턴스 생성\n",
        "recognizer = ObjectRecognizer()\n",
        "\n",
        "# 이미지 로드\n",
        "image = cv2.imread('/content/20230706_173238.jpg')\n",
        "# 색 변경(삭제 가능)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 윈도우 크기 = 백분율(원래 이미지 크기의 0.1 = 10%)\n",
        "window_sizes = [1.0, 0.5, 0.4]\n",
        "\n",
        "# recognit_objects 메서드를 호출\n",
        "results = recognizer.recognize_objects(image, window_sizes)\n",
        "\n",
        "# 결과 출력\n",
        "for label, prob in results:\n",
        "    print(f\"{label}: {prob}\")"
      ],
      "metadata": {
        "id": "h08-TNSQ7idk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eIe-pqhh4vm",
        "outputId": "cc1f730f-35db-4c42-87c7-f43e22d01540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('water_bottle', 0.60631716),\n",
              " ('beer_bottle', 0.044199806),\n",
              " ('bucket', 0.028730191),\n",
              " ('vacuum', 0.028223686),\n",
              " ('ashcan', 0.027989872)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "\n",
        "class ObjectRecognizer:\n",
        "    def __init__(self):\n",
        "        self.model = ResNet50(include_top=True, weights='imagenet')\n",
        "        self.window_sizes = [0.5, 0.75, 1.0]  # List of window sizes to use\n",
        "        self.stride = (100, 100)  # Stride for sliding windows\n",
        "\n",
        "    def recognize_objects(self, image):\n",
        "        results = []\n",
        "\n",
        "        for size in self.window_sizes:\n",
        "            window_width = int(image.shape[1] * size)\n",
        "            window_height = int(image.shape[0] * size)\n",
        "\n",
        "            for (x, y, window) in self.sliding_window(image, (window_width, window_height), self.stride):\n",
        "                resized_window = cv2.resize(window, (224, 224))\n",
        "                preprocessed_window = preprocess_input(np.expand_dims(resized_window, axis=0))\n",
        "\n",
        "                preds = self.model.predict(preprocessed_window)\n",
        "                decoded_preds = decode_predictions(preds, top=5)[0]\n",
        "\n",
        "                results.extend(decoded_preds)\n",
        "\n",
        "        unique_results = {}\n",
        "        for result in results:\n",
        "            label = result[1]\n",
        "            prob = result[2]\n",
        "\n",
        "            if label not in unique_results:\n",
        "                unique_results[label] = prob\n",
        "            else:\n",
        "                unique_results[label] += prob\n",
        "\n",
        "        sorted_results = sorted(unique_results.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_5_results = sorted_results[:5]\n",
        "\n",
        "        return top_5_results\n",
        "\n",
        "    def sliding_window(self, image, window_size, stride):\n",
        "        window_width, window_height = window_size\n",
        "        stride_x, stride_y = stride\n",
        "\n",
        "        for y in range(0, image.shape[0] - window_height + 1, stride_y):\n",
        "            for x in range(0, image.shape[1] - window_width + 1, stride_x):\n",
        "                yield (x, y, image[y:y + window_height, x:x + window_width])"
      ],
      "metadata": {
        "id": "FRhA5jV_aiid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == '__main__':\n",
        "    # Load the image\n",
        "    image_path = 'path/to/your/image.jpg'\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Create an instance of ObjectRecognizer\n",
        "    recognizer = ObjectRecognizer()\n",
        "\n",
        "    # Recognize objects in the image\n",
        "    object_predictions = recognizer.recognize_objects(image)\n",
        "\n",
        "    # Print the top 5 object predictions\n",
        "    for prediction in object_predictions:\n",
        "        label = prediction[0]\n",
        "        probability = prediction[1]\n",
        "        print(f\"Label: {label}, Probability: {probability}\")"
      ],
      "metadata": {
        "id": "PW5Z1K-lajld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzAAuLMygAr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문장 모델 추가"
      ],
      "metadata": {
        "id": "Ipb1uB-Pgp_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "# !pip install fastai"
      ],
      "metadata": {
        "id": "OY7VwrsGlCQ3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions"
      ],
      "metadata": {
        "id": "TiFnvyvLzWv6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "\n",
        "# 모델 지정\n",
        "class ObjectRecognizer:\n",
        "    def __init__(self):\n",
        "        self.model = ResNet50(include_top=True, weights='imagenet')\n",
        "\n",
        "    # 윈도우 크기 설정\n",
        "    def sliding_window(self, image, window_size, stride):\n",
        "        window_width, window_height = window_size\n",
        "        stride_x, stride_y = stride\n",
        "\n",
        "        for y in range(0, image.shape[0] - window_height + 1, stride_y):\n",
        "            for x in range(0, image.shape[1] - window_width + 1, stride_x):\n",
        "                yield (x, y, image[y:y + window_height, x:x + window_width])\n",
        "\n",
        "    # 실제 데이터로 실험\n",
        "    def recognize_objects(self, image, window_sizes, stride=(700, 700)):\n",
        "        results = []\n",
        "        for size in window_sizes:\n",
        "            window_width = int(image.shape[1] * size)\n",
        "            window_height = int(image.shape[0] * size)\n",
        "\n",
        "            for (x, y, window) in self.sliding_window(image, (window_width, window_height), stride):\n",
        "                resized_window = cv2.resize(window, (224, 224))\n",
        "                preprocessed_window = preprocess_input(np.expand_dims(resized_window, axis=0))\n",
        "\n",
        "                preds = self.model.predict(preprocessed_window)\n",
        "                decoded_preds = decode_predictions(preds, top=5)[0]\n",
        "\n",
        "                results.extend(decoded_preds)\n",
        "\n",
        "        # 확률에 따라 내림차순으로 결과 정렬\n",
        "        results.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # 각 고유한 결과에 대한 확률 합계를 계산\n",
        "        unique_results = {}\n",
        "        for result in results:\n",
        "            label = result[1]\n",
        "            prob = result[2]\n",
        "\n",
        "            if label not in unique_results:\n",
        "                unique_results[label] = prob\n",
        "            else:\n",
        "                unique_results[label] += prob\n",
        "\n",
        "        # 합계 확률에 따라 내림차순으로 고유 결과 정렬\n",
        "        sorted_results = sorted(unique_results.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # 확률과 함께 상위 5개의 고유 결과 출력\n",
        "        top_5_results = sorted_results[:]\n",
        "\n",
        "        return top_5_results"
      ],
      "metadata": {
        "id": "kKhTBQL_gEig"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Object Recognizer 클래스의 인스턴스 생성\n",
        "recognizer = ObjectRecognizer()\n",
        "\n",
        "# 이미지 로드\n",
        "image = cv2.imread('/content/20230706_171846.jpg')\n",
        "# 색 변경(삭제 가능)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 윈도우 크기 = 백분율(원래 이미지 크기의 0.1 = 10%)\n",
        "window_sizes = [0.2]\n",
        "\n",
        "# recognit_objects 메서드를 호출\n",
        "results = recognizer.recognize_objects(image, window_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS-RG6nsjyr9",
        "outputId": "924f9413-6264-4605-9525-b98b9b6b3e5e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 0s 240ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 0s 223ms/step\n",
            "1/1 [==============================] - 0s 223ms/step\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 226ms/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 0s 214ms/step\n",
            "1/1 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 0s 225ms/step\n",
            "1/1 [==============================] - 0s 220ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exaurt7knGDg",
        "outputId": "8df1032a-3d74-48d6-da0d-f94083634a7e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('desk', 1.0479332),\n",
              " ('backpack', 0.9761256),\n",
              " ('notebook', 0.534201),\n",
              " ('laptop', 0.39107385),\n",
              " ('knot', 0.3856863),\n",
              " ('washbasin', 0.32401416),\n",
              " ('power_drill', 0.30189845),\n",
              " ('carton', 0.28301734),\n",
              " ('tray', 0.27632982),\n",
              " ('file', 0.27142048),\n",
              " ('running_shoe', 0.21345618),\n",
              " ('hook', 0.20815359),\n",
              " ('scabbard', 0.20685166),\n",
              " ('turnstile', 0.20141438),\n",
              " ('window_screen', 0.18897614),\n",
              " ('folding_chair', 0.1760108),\n",
              " ('pedestal', 0.13187757),\n",
              " ('tripod', 0.12888479),\n",
              " ('stretcher', 0.12325156),\n",
              " ('monitor', 0.11323958),\n",
              " ('jean', 0.112737216),\n",
              " ('purse', 0.11183865),\n",
              " ('projector', 0.110645674),\n",
              " ('barbell', 0.10852295),\n",
              " ('lab_coat', 0.107868545),\n",
              " ('shower_curtain', 0.106051564),\n",
              " ('screen', 0.102258176),\n",
              " ('vacuum', 0.1010514),\n",
              " ('studio_couch', 0.10017837),\n",
              " ('medicine_chest', 0.093604654),\n",
              " ('remote_control', 0.09049801),\n",
              " ('barrel', 0.07288482),\n",
              " ('safe', 0.07232691),\n",
              " ('buckle', 0.069643505),\n",
              " ('toilet_seat', 0.06862195),\n",
              " ('wok', 0.06806636),\n",
              " ('punching_bag', 0.06718),\n",
              " ('mailbag', 0.066383146),\n",
              " ('letter_opener', 0.06489002),\n",
              " ('bathtub', 0.060906682),\n",
              " ('velvet', 0.058592394),\n",
              " ('loudspeaker', 0.05435398),\n",
              " ('mouse', 0.05405795),\n",
              " ('dining_table', 0.051547144),\n",
              " ('desktop_computer', 0.047074143),\n",
              " ('dishwasher', 0.046844155),\n",
              " ('suit', 0.046743028),\n",
              " ('toaster', 0.045662384),\n",
              " ('sleeping_bag', 0.04484154),\n",
              " ('iron', 0.036099315),\n",
              " ('wardrobe', 0.030873137),\n",
              " ('pitcher', 0.030288795),\n",
              " ('tub', 0.029717932),\n",
              " ('mortarboard', 0.028195068),\n",
              " ('safety_pin', 0.027315067),\n",
              " ('cup', 0.023893312),\n",
              " ('entertainment_center', 0.022362262)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Rt4kQ0F_Ha6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### dylanmengzhou/kobart-trans-en-ko-v2"
      ],
      "metadata": {
        "id": "nKckkcy_u4Dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dylanmengzhou/kobart-trans-en-ko-v2\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"dylanmengzhou/kobart-trans-en-ko-v2\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "5Ahp-q05qPZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = list(results)\n",
        "text = key[3][0]\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yBx3VWYeqyw4",
        "outputId": "96a35c87-dfc5-4d06-c17f-d1f6d3baed87"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'seat_belt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = key[3][0]\n",
        "\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
        "gen_ids = model.generate(input_ids)\n",
        "generated = tokenizer.decode(gen_ids[0].tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "6h9jtcNAswV1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A28kfk9tL_B",
        "outputId": "0cedc23d-6051-4720-eb1d-c62ba3495f03"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안전벨트하고 앉으세요 안전벨트하고 안전벨트하고 안전벨트하고 안전벨트하고\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NHNDQ/nllb-finetuned-en2ko\n"
      ],
      "metadata": {
        "id": "pRkNMqDPu79F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_name_or_path = \"NHNDQ/nllb-finetuned-en2ko\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "2dzxslQgu2qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = list(results)\n",
        "text = key[3][0]\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "629fbc10-5a21-44a6-da4b-84d41a381bee",
        "id": "bNciM5Zxu2qO"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'seat_belt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = key[3][0]\n",
        "\n",
        "model_inputs = tokenizer(text, return_tensors= \"pt\" )\n",
        "\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "gen_tokens = model.generate(input_ids, max_length=64, num_beams=100, no_repeat_ngram_size=2)\n",
        "print (tokenizer.batch_decode(gen_tokens, skip_special_tokens= True ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjK34qB1u2qP",
        "outputId": "7af1333a-b84a-4b5a-9ad0-b986d4c7f0b2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['중. (, ), ( )) (() ) ) ( ())']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-uXV8RhwVgn",
        "outputId": "105a43f8-8717-40e5-fefe-ae49f03c20ec"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### facebook/nllb-200-distilled-600M"
      ],
      "metadata": {
        "id": "wCsHehTMykkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_name_or_path = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "trans_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
        "\n",
        "trans_model.to(device)"
      ],
      "metadata": {
        "id": "eLGVHzDsyjh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = list(results)[3][0]\n",
        "input_ids = tokenizer.encode(inputs, return_tensors=\"pt\").to(device)\n",
        "gen_ids = trans_model.generate(input_ids, forced_bos_token_id=tokenizer.lang_code_to_id[\"kor_Hang\"])\n",
        "translation = tokenizer.decode(gen_ids[0, :].tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "CEFtS4P-3SBx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs, translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa7EsbUQ74yy",
        "outputId": "78e108c6-ad23-4219-f087-c4dc4e44b499"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sleeping_bag 잠자리\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시 모델"
      ],
      "metadata": {
        "id": "tTJzTZi56CHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# device setting\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# load model and tokenizer\n",
        "model_name_or_path = \"ddobokki/gpt2_poem\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "poem_model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
        "poem_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTPnb0kP0f_m",
        "outputId": "6777fcfb-6cbe-4776-8322-c1437bede540"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51202, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51202, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_start_token = \"<k>\"\n",
        "keyword_end_token = \"</k>\"\n",
        "text = translation\n",
        "\n",
        "input_text = keyword_start_token + text + keyword_end_token\n",
        "\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "gen_ids = poem_model.generate(\n",
        "    input_ids, max_length=64, num_beams=100, no_repeat_ngram_size=2\n",
        ")\n",
        "generated = tokenizer.decode(gen_ids[0, :].tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "KuzPt0iGx6XN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l40uRJ-E4MNt",
        "outputId": "d59b744f-307e-47d8-d8a1-d88f1829718e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "잠자리 어디선가 날아온\n",
            "잠자리 한 마리\n",
            "오늘도 어김없이 날아와\n",
            "밤하늘을 날아다닌다\n",
            "어디서 날아왔는지\n",
            "아무도 모르게\n",
            "떠다니던 잠자리는\n",
            "어느새\n",
            "사라져버렸다\n",
            "무엇이 그리 슬펐을까\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# # device setting\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# # load model and tokenizer\n",
        "# model_name_or_path = \"facebook/nllb-200-distilled-600M\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
        "# model.to(device)\n",
        "\n",
        "# keyword_start_token = \"<k>\"\n",
        "# keyword_end_token = \"</k>\"\n",
        "# text = \"산 꼭대기가 보이는 경치\"\n",
        "# input_text = keyword_start_token + text + keyword_end_token\n",
        "\n",
        "# input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "# gen_ids = model.generate(\n",
        "#     input_ids, max_length=64, num_beams=100, no_repeat_ngram_size=2\n",
        "# )\n",
        "# generated = tokenizer.decode(gen_ids[0, :].tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "fp3dbuc-lxg9"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}