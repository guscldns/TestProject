{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/0716/05_learning_rate_scheduling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Schedule Learning Rate for More Improving\n",
        "Callbacks API 활용  \n",
        "1) ReduceLROnPlateau  \n",
        "2) LearningRateScheduler"
      ],
      "metadata": {
        "id": "n1AlKJy6cNnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q. 모델의 성능이 더이상 개선되지 않을 때, 왜 Learning Rate을 감소시키는 전략을 쓸까?\n",
        "이는 얼핏 생각해보면, 반 직관적(counter-intuitive)이지 않은가?  "
      ],
      "metadata": {
        "id": "JI492nThpLVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Rate이 무엇이었는지 다시 한번 상기해보자.  \n",
        "        \n",
        "    W ← W - lr * Gradient"
      ],
      "metadata": {
        "id": "c0PBOyocppgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ReduceLROnPlateau\n",
        "모델이 일정기간(patience)동안 개선되지 않으면(monitor)  \n",
        "Learning rate을 일정비율(factor)로 감소시킴으로 loss를 낮춤"
      ],
      "metadata": {
        "id": "xLXoawlKh2qM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.1, # new_lr = lr * factor.\n",
        "        patience=10,\n",
        "        min_delta=0.0001, # threshold for measuring the new optimum, to only focus on significant changes.  \n",
        "        cooldown=0, # number of epochs to wait before resuming normal operation after lr has been reduced.  \n",
        "        min_lr=0\n",
        "    )"
      ],
      "metadata": {
        "id": "YpDPK3wqd11s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Id7TU7pfME67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset download\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xf3LULIMEta",
        "outputId": "2f084873-c792-421c-fa29-8f43af25a5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modeling\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(10)\n",
        "            ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "6sjiiptqL9qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "e2fT3ctfNnra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=1, min_lr=0)\n",
        "model.fit(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBLS4__iRme",
        "outputId": "1670be2d-3ace-41bb-ccd6-0ee242c37d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3089 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1064 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3064 - accuracy: 0.0953 - val_loss: 2.3026 - val_accuracy: 0.1064 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3108 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.0958 - lr: 2.0000e-04\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3060 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.0958 - lr: 4.0000e-05\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3054 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.0958 - lr: 8.0000e-06\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3062 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.6000e-06\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3046 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 3.2000e-07\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3080 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 6.4000e-08\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3057 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.2800e-08\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3054 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 2.5600e-09\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3046 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 5.1200e-10\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3060 - accuracy: 0.1013 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.0240e-10\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3063 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 2.0480e-11\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3063 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 4.0960e-12\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 2.3068 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 8.1920e-13\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3048 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.6384e-13\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 2.3057 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 3.2768e-14\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3040 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 6.5536e-15\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 2.3066 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.3107e-15\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3054 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 2.6214e-16\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3053 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 5.2429e-17\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3054 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.0486e-17\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3054 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 2.0972e-18\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3066 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 4.1943e-19\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3046 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 8.3886e-20\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3046 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.6777e-20\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3060 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 3.3554e-21\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3063 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 6.7109e-22\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3069 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.3422e-22\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3059 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 2.6844e-23\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3066 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 5.3687e-24\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3051 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.0737e-24\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3049 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 2.1475e-25\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3054 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 4.2950e-26\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3066 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 8.5899e-27\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3057 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.7180e-27\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3051 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 3.4360e-28\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3060 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 6.8719e-29\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3071 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.3744e-29\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3075 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 2.7488e-30\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3068 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 5.4976e-31\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3066 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.0995e-31\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3054 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 2.1990e-32\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3063 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 4.3980e-33\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3066 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 8.7961e-34\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3049 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.7592e-34\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3072 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 3.5184e-35\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 2.3069 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 7.0369e-36\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3051 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 1.4074e-36\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3060 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.0957 - lr: 2.8148e-37\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7aef2ad1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LearningRateScheduler\n",
        "scheduler함수 설정을 바탕으로, epoch마다 learning rate을 변환"
      ],
      "metadata": {
        "id": "JXY1ifIRhb_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "   if epoch < 2:\n",
        "     return lr\n",
        "   else:\n",
        "     return lr * 0.1"
      ],
      "metadata": {
        "id": "QfSfY2Modnz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(lr=0.001), loss='mse')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mN7qKC9emkC",
        "outputId": "72fa18a9-66d8-4cc4-c49f-229a75d7dd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_13 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0)"
      ],
      "metadata": {
        "id": "nKFA4igncK9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=x_train,\n",
        "          y=y_train,\n",
        "          epochs=5,\n",
        "          validation_data=(x_test, y_test),\n",
        "          batch_size = 10000,\n",
        "          callbacks=[lr_schedule])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlAfNhivdZXB",
        "outputId": "9ed3d9d5-d250-4812-d9ab-79ce8897fd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "6/6 [==============================] - 3s 419ms/step - loss: 6269.2886 - val_loss: 2499.5623 - lr: 0.0010\n",
            "Epoch 2/5\n",
            "6/6 [==============================] - 2s 412ms/step - loss: 2393.6536 - val_loss: 1165.3063 - lr: 0.0010\n",
            "Epoch 3/5\n",
            "6/6 [==============================] - 2s 405ms/step - loss: 1735.0145 - val_loss: 918.4071 - lr: 1.0000e-04\n",
            "Epoch 4/5\n",
            "6/6 [==============================] - 2s 400ms/step - loss: 1533.6758 - val_loss: 882.3265 - lr: 1.0000e-05\n",
            "Epoch 5/5\n",
            "6/6 [==============================] - 2s 407ms/step - loss: 1509.8970 - val_loss: 878.1278 - lr: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a66978f90>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}
