{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20/%EB%AA%A8%EB%8D%B8%EB%A7%81_%EC%98%88%EC%A0%9C(commit_no).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Gg0h4P99LaP"
      },
      "outputs": [],
      "source": [
        "# core\n",
        "import os, shutil, unicodedata\n",
        "import pickle, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# visualize\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm  # 폰트\n",
        "from matplotlib import rc # 폰트\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "## keras\n",
        "from tensorflow.keras import layers, models, metrics, callbacks\n",
        "## layers & models\n",
        "from tensorflow.keras.layers import Layer, Input, Embedding, Concatenate, Flatten, Normalization\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, Attention\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "## optimizers & callbacks\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "## preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "## utils\n",
        "from tensorflow.keras.utils import plot_model\n",
        "## saving\n",
        "from tensorflow.keras.saving import save_model\n",
        "\n",
        "# Huggingface\n",
        "from transformers import TFBertModel, BertForMaskedLM, FillMaskPipeline, TFBertForNextSentencePrediction, TFRobertaModel, AutoModel, TFBertForSequenceClassification\n",
        "\n",
        "from transformers import TFBertTokenizer, AutoTokenizer, AutoConfig\n",
        "from transformers import TFGPT2LMHeadModel\n",
        "# scikit-learn\n",
        "## models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "# Time Check\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# customization\n",
        "## font\n",
        "# plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EQLBL7M9LaR"
      },
      "source": [
        "## preprocessed Data 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSa-b--g9LaS",
        "outputId": "2b3df362-491e-4f5d-865a-f660de7189ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>facts</th>\n",
              "      <th>first_party_winner</th>\n",
              "      <th>facts_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>TRAIN_0000</td>\n",
              "      <td>Phil A. St. Amant</td>\n",
              "      <td>Herman A. Thompson</td>\n",
              "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['On', 'June', '27,', '1962,', 'Phil', 'St.', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TRAIN_0001</td>\n",
              "      <td>Stephen Duncan</td>\n",
              "      <td>Lawrence Owens</td>\n",
              "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
              "      <td>0</td>\n",
              "      <td>['Ramon', 'Nelson', 'was', 'riding', 'his', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>TRAIN_0002</td>\n",
              "      <td>Billy Joe Magwood</td>\n",
              "      <td>Tony Patterson, Warden, et al.</td>\n",
              "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
              "      <td>1</td>\n",
              "      <td>['An', 'Alabama', 'state', 'court', 'convicted...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>TRAIN_0003</td>\n",
              "      <td>Linkletter</td>\n",
              "      <td>Walker</td>\n",
              "      <td>Victor Linkletter was convicted in state court...</td>\n",
              "      <td>0</td>\n",
              "      <td>['Victor', 'Linkletter', 'was', 'convicted', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>TRAIN_0004</td>\n",
              "      <td>William Earl Fikes</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
              "      <td>1</td>\n",
              "      <td>['On', 'April', '24,', '1953', 'in', 'Selma,',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>2473</td>\n",
              "      <td>TRAIN_2473</td>\n",
              "      <td>HollyFrontier Cheyenne Refining, LLC, et al.</td>\n",
              "      <td>Renewable Fuels Association, et al.</td>\n",
              "      <td>Congress amended the Clean Air Act through the...</td>\n",
              "      <td>1</td>\n",
              "      <td>['Congress', 'amended', 'the', 'Clean', 'Air',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>2474</td>\n",
              "      <td>TRAIN_2474</td>\n",
              "      <td>Grupo Mexicano de Desarrollo, S. A.</td>\n",
              "      <td>Alliance Bond Fund, Inc.</td>\n",
              "      <td>Alliance Bond Fund, Inc., an investment fund, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['Alliance', 'Bond', 'Fund,', 'Inc.,', 'an', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>2475</td>\n",
              "      <td>TRAIN_2475</td>\n",
              "      <td>Peguero</td>\n",
              "      <td>United States</td>\n",
              "      <td>In 1992, the District Court sentenced Manuel D...</td>\n",
              "      <td>0</td>\n",
              "      <td>['In', '1992,', 'the', 'District', 'Court', 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>2476</td>\n",
              "      <td>TRAIN_2476</td>\n",
              "      <td>Immigration and Naturalization Service</td>\n",
              "      <td>St. Cyr</td>\n",
              "      <td>On March 8, 1996, Enrico St. Cyr, a lawful per...</td>\n",
              "      <td>0</td>\n",
              "      <td>['On', 'March', '8,', '1996,', 'Enrico', 'St.'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>2477</td>\n",
              "      <td>TRAIN_2477</td>\n",
              "      <td>Markman</td>\n",
              "      <td>Westview Instruments, Inc.</td>\n",
              "      <td>Herbert Markman owns the patent to a system th...</td>\n",
              "      <td>0</td>\n",
              "      <td>['Herbert', 'Markman', 'owns', 'the', 'patent'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2478 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0          ID                                   first_party  \\\n",
              "0              0  TRAIN_0000                             Phil A. St. Amant   \n",
              "1              1  TRAIN_0001                                Stephen Duncan   \n",
              "2              2  TRAIN_0002                             Billy Joe Magwood   \n",
              "3              3  TRAIN_0003                                    Linkletter   \n",
              "4              4  TRAIN_0004                            William Earl Fikes   \n",
              "...          ...         ...                                           ...   \n",
              "2473        2473  TRAIN_2473  HollyFrontier Cheyenne Refining, LLC, et al.   \n",
              "2474        2474  TRAIN_2474           Grupo Mexicano de Desarrollo, S. A.   \n",
              "2475        2475  TRAIN_2475                                       Peguero   \n",
              "2476        2476  TRAIN_2476        Immigration and Naturalization Service   \n",
              "2477        2477  TRAIN_2477                                       Markman   \n",
              "\n",
              "                             second_party  \\\n",
              "0                      Herman A. Thompson   \n",
              "1                          Lawrence Owens   \n",
              "2          Tony Patterson, Warden, et al.   \n",
              "3                                  Walker   \n",
              "4                                 Alabama   \n",
              "...                                   ...   \n",
              "2473  Renewable Fuels Association, et al.   \n",
              "2474             Alliance Bond Fund, Inc.   \n",
              "2475                        United States   \n",
              "2476                              St. Cyr   \n",
              "2477           Westview Instruments, Inc.   \n",
              "\n",
              "                                                  facts  first_party_winner  \\\n",
              "0     On June 27, 1962, Phil St. Amant, a candidate ...                   1   \n",
              "1     Ramon Nelson was riding his bike when he suffe...                   0   \n",
              "2     An Alabama state court convicted Billy Joe Mag...                   1   \n",
              "3     Victor Linkletter was convicted in state court...                   0   \n",
              "4     On April 24, 1953 in Selma, Alabama, an intrud...                   1   \n",
              "...                                                 ...                 ...   \n",
              "2473  Congress amended the Clean Air Act through the...                   1   \n",
              "2474  Alliance Bond Fund, Inc., an investment fund, ...                   1   \n",
              "2475  In 1992, the District Court sentenced Manuel D...                   0   \n",
              "2476  On March 8, 1996, Enrico St. Cyr, a lawful per...                   0   \n",
              "2477  Herbert Markman owns the patent to a system th...                   0   \n",
              "\n",
              "                                            facts_split  \n",
              "0     ['On', 'June', '27,', '1962,', 'Phil', 'St.', ...  \n",
              "1     ['Ramon', 'Nelson', 'was', 'riding', 'his', 'b...  \n",
              "2     ['An', 'Alabama', 'state', 'court', 'convicted...  \n",
              "3     ['Victor', 'Linkletter', 'was', 'convicted', '...  \n",
              "4     ['On', 'April', '24,', '1953', 'in', 'Selma,',...  \n",
              "...                                                 ...  \n",
              "2473  ['Congress', 'amended', 'the', 'Clean', 'Air',...  \n",
              "2474  ['Alliance', 'Bond', 'Fund,', 'Inc.,', 'an', '...  \n",
              "2475  ['In', '1992,', 'the', 'District', 'Court', 's...  \n",
              "2476  ['On', 'March', '8,', '1996,', 'Enrico', 'St.'...  \n",
              "2477  ['Herbert', 'Markman', 'owns', 'the', 'patent'...  \n",
              "\n",
              "[2478 rows x 7 columns]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../../data/preprocessed/preprocessed_1.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYASyRwX9LaS"
      },
      "source": [
        "## 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy1gVIgb9LaT",
        "outputId": "c5673c19-aa28-42a1-be2e-c79064d4f78d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at nlpaueb/legal-bert-small-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"nlpaueb/legal-bert-small-uncased\",\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_ids\": 0,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 512,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 2048,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 8,\n",
              "  \"num_hidden_layers\": 6,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.30.2\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# nlpaueb/legal-bert-small-uncased\n",
        "tokenizer_3 = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-small-uncased\")\n",
        "model_3 = TFBertModel.from_pretrained(\"nlpaueb/legal-bert-small-uncased\")\n",
        "config_3 = AutoConfig.from_pretrained(\"nlpaueb/legal-bert-small-uncased\") # 모델 구조 파악(레이어는 몰라도 속성 알기 좋아서 썼습니다)\n",
        "\n",
        "config_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlZCSx0Y9LaT",
        "outputId": "1a284ab5-bf07-46ab-922d-dc796b5f871f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "token_3의 0번 문장:\n",
            "['[CLS]', 'on', 'june', '27', ',', '1962', ',', 'phil', 'st', '.', 'am', '##ant', ',', 'a', 'candidate', 'for', 'public', 'office', ',', 'made', 'a', 'television', 'speech', 'in', 'baton', 'roug', '##e', ',', 'louisiana', '.', 'during', 'this', 'speech', ',', 'st', '.', 'am', '##ant', 'accused', 'his', 'political', 'opponent', 'of', 'being', 'a', 'communist', 'and', 'of', 'being', 'involved', 'in', 'criminal', 'activities', 'with', 'the', 'head', 'of', 'the', 'local', 'teamster', '##s', 'union', '.', 'finally', ',', 'st', '.', 'am', '##ant', 'implicated', 'herman', 'thompson', ',', 'an', 'east', 'baton', 'roug', '##e', 'deputy', 'sheriff', ',', 'in', 'a', 'scheme', 'to', 'move', 'money', 'between', 'the', 'teamster', '##s', 'union', 'and', 'st', '.', 'am', '##ant', 's', 'political', 'opponent', '.', 'thompson', 'successfully', 'sued', 'st', '.', 'am', '##ant', 'for', 'defam', '##ation', '.', 'louisiana', 's', 'first', 'circuit', 'court', 'of', 'appeals', 'reversed', ',', 'holding', 'that', 'thompson', 'did', 'not', 'show', 'st', '.', 'am', '##ant', 'acted', 'with', 'malic', '##e', '.', 'thompson', 'the', '##n', 'appealed', 'to', 'the', 'supreme', 'court', 'of', 'louisiana', '.', 'that', 'court', 'held', 'that', ',', 'although', 'public', 'figures', 'forfeit', 'some', 'of', 'their', 'first', 'amendment', 'protection', 'from', 'defam', '##ation', ',', 'st', '.', 'am', '##ant', 'accused', 'thompson', 'of', 'a', 'crime', 'with', 'utter', 'disregard', 'of', 'whether', 'the', 'remarks', 'were', 'true', '.', 'finally', ',', 'that', 'court', 'held', 'that', 'the', 'first', 'amendment', 'protect', '##s', 'uni', '##n', '##hibited', ',', 'robust', 'debate', ',', 'rather', 'than', 'an', 'open', 'season', 'to', 'shoot', 'down', 'the', 'good', 'name', 'of', 'anyone', 'who', 'happens', 'to', 'be', 'a', 'public', 'servant', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "# 토큰화\n",
        "token_3 = tokenizer_3(df['facts'].tolist(), truncation=True, padding=True, return_tensors = 'tf')\n",
        "\n",
        "# 토큰화 결과 체크([PAD] 토큰 제외)\n",
        "print(f'''token_3의 0번 문장:\\n{[token for token in token_3[0].tokens if not token == '[PAD]']}''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cge6xsGV9LaT"
      },
      "outputs": [],
      "source": [
        "# X, y 지정\n",
        "X_data = token_3\n",
        "y_data = df['first_party_winner'].astype(np.int32) # 그냥 astype() 좋아해서 쓴것입니다. int()써도 문제 없을거에요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDGC56189LaT"
      },
      "outputs": [],
      "source": [
        "# Dataset 타입으로 변환\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(X_data),\n",
        "    y_data\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhuxkAX_9LaT",
        "outputId": "69ad8485-bfb8-4cfd-8e39-7dbdfed6896f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "155/155 [==============================] - 88s 510ms/step - loss: 0.6589 - accuracy: 0.6461\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x69e7dcac0>"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 수정\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        self.bert = TFBertModel.from_pretrained(model_name, from_pt = True) ## from_tf -> from_pt ##\n",
        "        self.classifier = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')\n",
        "\n",
        "    def call(self, input_ids = None, attention_mask=None, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        cls_token = outputs[1]\n",
        "        prediction = self.classifier(cls_token)\n",
        "\n",
        "        return prediction\n",
        "\n",
        "\n",
        "# 모델 인스턴스\n",
        "model_name = \"nlpaueb/legal-bert-small-uncased\"\n",
        "model = MyModel(model_name)\n",
        "\n",
        "\n",
        "# 컴파일\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=5e-5)\n",
        "loss = tf.keras.losses.BinaryCrossentropy() ## SparseCategoricalCrossenctropy -> Binary ##\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])\n",
        "\n",
        "num_train = 1000\n",
        "\n",
        "# 학습\n",
        "model.fit(\n",
        "    train_dataset.shuffle(num_train).batch(16),\n",
        "    epochs=1, batch_size=16,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}