{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz6pKdI2nvK8nX734wv0c4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/%EC%88%98%EC%97%85/pytorch_CustomDataset_%ED%81%B4%EB%9E%98%EC%8A%A4_%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip install pillow\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "PEnoraSeTsFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "6AuHzmImSA3c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToPILImage\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# ZIP 파일 열기\n",
        "with zipfile.ZipFile(\"/content/training_set (2).zip\", \"r\") as zip_ref:\n",
        "    # 파일 목록 가져오기\n",
        "    file_list = zip_ref.namelist()\n",
        "\n",
        "    # 파일 목록 출력\n",
        "    for file in file_list:\n",
        "        print(file)\n",
        "\n",
        "        # 파일 압축해제\n",
        "        zip_ref.extract(file)"
      ],
      "metadata": {
        "id": "zlTnSzh8U9e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.remove('/content/test_set/cats/.ipynb_checkpoints')\n",
        "# os.remove('/content/test_set/dogs/.ipynb_checkpoints')\n",
        "# os.rmdir('/content/test_set/cats/.ipynb_checkpoints')\n",
        "# os.rmdir('/content/test_set/dogs/.ipynb_checkpoints')"
      ],
      "metadata": {
        "id": "mD6TlBf-qQxt"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CustomDataset 클래스에서 이미지를 읽을 때 이미지를 PIL 이미지로 변환 후 텐서로 변환\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None): # root_dir = 폴더 경로, transform = 이미지 변환\n",
        "        self.root_dir = root_dir # 폴더 경로 변수화\n",
        "        self.transform = transform # 함수 변수화\n",
        "        self.classes = os.listdir(root_dir) # 폴더 내 파일 리스트 변수화\n",
        "        self.data = [] # 폴더 안의 파일 전체 경로, 이미지경로, 라벨 저장할 리스트\n",
        "        for label in range(len(self.classes)): # 리스트 변수에서 개수로 라벨설정\n",
        "            class_folder = os.path.join(root_dir, self.classes[label]) # 리스트변수[0], [1]의 폴더 명에 따라 이미지 폴더 전체 경로 생성\n",
        "            for filename in os.listdir(class_folder): # 이미지 폴더 내 파일 리스트 가져와서 for문 돌면서 1개씩 가져옴\n",
        "                img_path = os.path.join(class_folder, filename) # 이미지 파일 경로 설정\n",
        "                self.data.append((img_path, label)) # data 리스트에 이미지 경로, 라벨 저장\n",
        "    def __len__(self):\n",
        "        return len(self.data) # data 리스트에서 개수 세기\n",
        "    def __getitem__(self, idx): # 인덱스값 넣어주면 이미지와 라벨 가져오는 함수\n",
        "        img_path, label = self.data[idx] # 이미지 경로와 라벨을 data 리스트에서 가져옴\n",
        "        image = Image.open(img_path) # 이미지 경로에서 이미지 불러오기\n",
        "        if self.transform:\n",
        "            image = self.transform(image) # 이미지를 transform에 설정된 기준으로 가져오기\n",
        "        return image, label # 이미지 라벨 출력"
      ],
      "metadata": {
        "id": "DfDGM8yJSYWp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content\"  # 현재 작업 디렉토리로 설정\n",
        "batch_size = 32\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = CustomDataset(os.path.join(data_dir, 'training_set'), transform=transform)\n",
        "test_dataset = CustomDataset(os.path.join(data_dir, 'test_set'), transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "ioUgz-2IZa7e"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 CNN"
      ],
      "metadata": {
        "id": "m6OJ9Tk6b9V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# CNN 모델 정의\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 * 56 * 56, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "kPagGmPpcm8w"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 초기화 및 손실 함수, 최적화 함수 설정\n",
        "num_classes = len(train_dataset.classes)\n",
        "model = SimpleCNN(num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 모델 학습\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwpMgdVZn5nO",
        "outputId": "05ca477d-1aa4-4f19-87ad-575cc7cae676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7060408336775643\n",
            "Epoch 2, Loss: 0.651059091091156\n",
            "Epoch 3, Loss: 0.6024794152804783\n",
            "Epoch 4, Loss: 0.5607253057616097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on test set: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "id": "llPRStbErcDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}