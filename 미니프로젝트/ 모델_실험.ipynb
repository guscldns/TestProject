{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%20%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF_%EC%8B%A4%ED%97%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXZ1-pQdaY46"
      },
      "source": [
        "<!-- !pip install transformers -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctPVatyHaY49",
        "outputId": "7e072770-6c63-4ab0-e899-d83b96f1bc19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.0.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pymysql"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSiRQd-aa4ak",
        "outputId": "35106f04-daf3-4a13-b63b-8675f5ebfa99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "av44cG2fajvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfX42omOaY4-"
      },
      "outputs": [],
      "source": [
        "# core\n",
        "import os, pymysql, shutil, unicodedata, pickle, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# visualize\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm  # 폰트\n",
        "from matplotlib import rc # 폰트\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "## layers & models\n",
        "from tensorflow.keras.layers import Layer, Input, Embedding, Concatenate, Flatten, Normalization\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, Attention\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "## optimizers & callbacks\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "## preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "## utils\n",
        "from tensorflow.keras.utils import plot_model\n",
        "## saving\n",
        "from tensorflow.keras.saving import save_model\n",
        "# Huggingface\n",
        "from transformers import TFBertModel, FillMaskPipeline, TFRobertaModel, AutoModel, TFBertForSequenceClassification, TFGPT2LMHeadModel\n",
        "\n",
        "from transformers import TFBertTokenizer, AutoTokenizer, AutoConfig\n",
        "from transformers import logging\n",
        "# scikit-learn\n",
        "## models\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "# Time Check\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# customization\n",
        "# from knockknock import desktop_sender\n",
        "## font\n",
        "# plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = True\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "logging.set_verbosity_error() #  fine-tuning할 때 warning 메시지 끄기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGfOVIASaY4_"
      },
      "source": [
        "## preprocessed Data 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0LAr7uk-aY4_",
        "outputId": "6c0be895-ead0-4d66-9034-ac4cffdeb24d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0          ID         first_party                    second_party  \\\n",
              "0           0  TRAIN_0000   Phil A. St. Amant              Herman A. Thompson   \n",
              "1           1  TRAIN_0001      Stephen Duncan                  Lawrence Owens   \n",
              "2           2  TRAIN_0002   Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
              "3           3  TRAIN_0003          Linkletter                          Walker   \n",
              "4           4  TRAIN_0004  William Earl Fikes                         Alabama   \n",
              "\n",
              "                                               facts  first_party_winner  \\\n",
              "0  On June 27, 1962, Phil St. Amant, a candidate ...                   1   \n",
              "1  Ramon Nelson was riding his bike when he suffe...                   0   \n",
              "2  An Alabama state court convicted Billy Joe Mag...                   1   \n",
              "3  Victor Linkletter was convicted in state court...                   0   \n",
              "4  On April 24, 1953 in Selma, Alabama, an intrud...                   1   \n",
              "\n",
              "                                         facts_split  \n",
              "0  ['On', 'June', '27,', '1962,', 'Phil', 'St.', ...  \n",
              "1  ['Ramon', 'Nelson', 'was', 'riding', 'his', 'b...  \n",
              "2  ['An', 'Alabama', 'state', 'court', 'convicted...  \n",
              "3  ['Victor', 'Linkletter', 'was', 'convicted', '...  \n",
              "4  ['On', 'April', '24,', '1953', 'in', 'Selma,',...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5371558-6bd7-438a-b38a-d2080cbc63a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>facts</th>\n",
              "      <th>first_party_winner</th>\n",
              "      <th>facts_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>TRAIN_0000</td>\n",
              "      <td>Phil A. St. Amant</td>\n",
              "      <td>Herman A. Thompson</td>\n",
              "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['On', 'June', '27,', '1962,', 'Phil', 'St.', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TRAIN_0001</td>\n",
              "      <td>Stephen Duncan</td>\n",
              "      <td>Lawrence Owens</td>\n",
              "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
              "      <td>0</td>\n",
              "      <td>['Ramon', 'Nelson', 'was', 'riding', 'his', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>TRAIN_0002</td>\n",
              "      <td>Billy Joe Magwood</td>\n",
              "      <td>Tony Patterson, Warden, et al.</td>\n",
              "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
              "      <td>1</td>\n",
              "      <td>['An', 'Alabama', 'state', 'court', 'convicted...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>TRAIN_0003</td>\n",
              "      <td>Linkletter</td>\n",
              "      <td>Walker</td>\n",
              "      <td>Victor Linkletter was convicted in state court...</td>\n",
              "      <td>0</td>\n",
              "      <td>['Victor', 'Linkletter', 'was', 'convicted', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>TRAIN_0004</td>\n",
              "      <td>William Earl Fikes</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
              "      <td>1</td>\n",
              "      <td>['On', 'April', '24,', '1953', 'in', 'Selma,',...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5371558-6bd7-438a-b38a-d2080cbc63a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5371558-6bd7-438a-b38a-d2080cbc63a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5371558-6bd7-438a-b38a-d2080cbc63a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_csv('/content/preprocessed_1.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHTtj-XbaY5A"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXOjpOshaY5A"
      },
      "outputs": [],
      "source": [
        "# 사전학습 모델 아카이브 (RoBERTa 아키텍쳐는 반영되지 않았습니다)\n",
        "model_names = {0: 'nlpaueb/legal-bert-base-uncased', # BERT based\n",
        "               1: 'saibo/legal-roberta-base', #RoBERTa based\n",
        "               2: 'casehold/custom-legalbert', # BERT based\n",
        "               3: 'nlpaueb/legal-bert-small-uncased' # BERT based\n",
        "               }\n",
        "\n",
        "# 사용할 모델 지정하기\n",
        "MODEL_NAME = model_names[3]\n",
        "\n",
        "\n",
        "# Hyper-Parameter\n",
        "LEARNING_RATE = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oS2Z7siaY5A"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model): # Fine-Tune\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        self.bert = TFBertModel.from_pretrained(model_name, from_pt = True)\n",
        "        self.classifier = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')\n",
        "\n",
        "    def call(self, input_ids = None, attention_mask=None, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        cls_token = outputs[1]\n",
        "        prediction = self.classifier(cls_token)\n",
        "\n",
        "        return prediction\n",
        "\n",
        "\n",
        "class WorkFlow(MyModel):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__(model_name)\n",
        "        self.model_name = model_name\n",
        "        self.config = AutoConfig.from_pretrained(self.model_name)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "\n",
        "\n",
        "    def call(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
        "        super().call(input_ids = None, attention_mask=None, token_type_ids=None)\n",
        "\n",
        "\n",
        "\n",
        "    def get_dataset(self, X_data, y_data, test_split=0.2, shuffle=True, shuffle_size=3000):\n",
        "\n",
        "        tokens = self.tokenizer(X_data.tolist(), truncation=True, padding=True, return_tensors = 'tf')\n",
        "\n",
        "        X_data = tokens\n",
        "        y_data = y_data\n",
        "\n",
        "        # dataset 타입으로 변환\n",
        "        ds = tf.data.Dataset.from_tensor_slices((\n",
        "            dict(X_data),\n",
        "            y_data\n",
        "        ))\n",
        "\n",
        "        if shuffle:\n",
        "            ds = ds.shuffle(shuffle_size, seed=777)\n",
        "\n",
        "        test_size = int(test_split * len(ds))\n",
        "        train_size = len(ds) - test_size\n",
        "\n",
        "        self.train_ds = ds.take(train_size)\n",
        "        self.test_ds = ds.take(test_size)\n",
        "\n",
        "        return self.train_ds, self.test_ds\n",
        "\n",
        "\n",
        "    def model_compile(self, learning_rate=LEARNING_RATE):\n",
        "        self.model = MyModel(self.model_name)\n",
        "        # 컴파일\n",
        "        self.optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
        "        self.loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "        self.model.compile(optimizer=self.optimizer,\n",
        "                           loss=self.loss,\n",
        "                           metrics = ['binary_accuracy']\n",
        "                           )\n",
        "\n",
        "\n",
        "\n",
        "    def run_model(self, filepath, patience=3, batch_size=32, epochs=5):\n",
        "\n",
        "        # 콜백함수\n",
        "        # chk = tf.keras.callbacks.ModelCheckpoint(filepath=filepath+'_{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss') # SubClass에서는 체크포인트 저장 불가\n",
        "        es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                              patience=patience,\n",
        "                                              restore_best_weights=True,\n",
        "                                              verbose=1,\n",
        "                                              start_from_epoch=4) # epoch 4부터 모니터링 시작\n",
        "\n",
        "        # 학습\n",
        "        self.history = self.model.fit(\n",
        "                        self.train_ds.batch(batch_size),\n",
        "                        validation_data = [self.test_ds.batch(batch_size)],\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        # callbacks=[es, chk]\n",
        "                        callbacks=[es]\n",
        "                        )\n",
        "\n",
        "        self.model.save_weights(filepath=filepath + '.h5',\n",
        "                                overwrite=True,\n",
        "                                save_format='h5'\n",
        "                                )\n",
        "\n",
        "        return self.history\n",
        "\n",
        "    def visualizer(self):\n",
        "\n",
        "        fig = make_subplots(rows=1, cols=2,\n",
        "                            subplot_titles=('Loss', 'Accuracy'))\n",
        "\n",
        "        # loss\n",
        "        fig.add_trace(go.Scatter(x=self.history.epoch,\n",
        "                                 y=self.history.history['loss'],\n",
        "                                 name='loss',\n",
        "                                 mode='lines+markers'),\n",
        "                      row=1, col=1)\n",
        "\n",
        "        # val loss\n",
        "        fig.add_trace(go.Scatter(x=self.history.epoch,\n",
        "                                 y=self.history.history['val_loss'],\n",
        "                                 name='val_loss',\n",
        "                                 mode='lines+markers'),\n",
        "                      row=1, col=1)\n",
        "\n",
        "        # binary accuracy\n",
        "        fig.add_trace(go.Scatter(x=self.history.epoch,\n",
        "                                 y=self.history.history['binary_accuracy'],\n",
        "                                 name='binary_accuracy',\n",
        "                                 mode='lines+markers'),\n",
        "                      row=1, col=2)\n",
        "\n",
        "        # val binary accuracy\n",
        "        fig.add_trace(go.Scatter(x=self.history.epoch,\n",
        "                                 y=self.history.history['val_binary_accuracy'],\n",
        "                                 name='val_binary_accuracy',\n",
        "                                 mode='lines+markers'),\n",
        "                      row=1, col=2)\n",
        "\n",
        "\n",
        "        fig.update_layout(showlegend=True)\n",
        "\n",
        "        fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf2bKqebaY5B"
      },
      "source": [
        "## 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjqPLvIBaY5B",
        "outputId": "809b814b-5bf2-4d90-a6bb-889333f42c2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"nlpaueb/legal-bert-small-uncased\",\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_ids\": 0,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 512,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 2048,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 8,\n",
              "  \"num_hidden_layers\": 6,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.30.2\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ],
      "source": [
        "wf = WorkFlow(MODEL_NAME)\n",
        "\n",
        "wf.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GuGq-cUaY5C"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 지정\n",
        "X_data = df['facts']\n",
        "y_data = df['first_party_winner'].astype(np.int32)\n",
        "\n",
        "train_ds, test_ds = wf.get_dataset(X_data, y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGCcyzq9aY5C",
        "outputId": "168b5701-81c9-420a-c75f-a60f79198e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.6659 - binary_accuracy: 0.6455"
          ]
        }
      ],
      "source": [
        "save_name = MODEL_NAME.split('/')[1]\n",
        "\n",
        "# compile 및 fit\n",
        "wf.model_compile()\n",
        "history = wf.run_model(filepath= save_name, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymysql\n",
        "import pandas as pd\n",
        "\n",
        "class DbHelper():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_TrainData(self, config):\n",
        "        db_connection = pymysql.connect(\n",
        "           **config\n",
        "        )\n",
        "        cursor = db_connection.cursor()\n",
        "\n",
        "        # Execute the SQL query to fetch the data\n",
        "        sql = \"SELECT * FROM devcon\"\n",
        "        cursor.execute(sql)\n",
        "\n",
        "        # Fetch all the rows returned by the query\n",
        "        rows = cursor.fetchall()\n",
        "\n",
        "        data = []\n",
        "\n",
        "        # Iterate over the rows and append data to the list as dictionaries\n",
        "        for row in rows:\n",
        "            raw_id = row[1]\n",
        "            raw_first_party = row[2]\n",
        "            raw_second_party = row[3]\n",
        "            raw_facts = row[4]\n",
        "            raw_winner = row[5]\n",
        "            facts_split = row[6]\n",
        "\n",
        "            # Create a dictionary for the row\n",
        "            row_dict = {\n",
        "                '_id': raw_id,\n",
        "                'raw_first_party': raw_first_party,\n",
        "                'raw_second_party': raw_second_party,\n",
        "                'raw_facts': raw_facts,\n",
        "                'raw_winner': raw_winner,\n",
        "                'facts_split':facts_split\n",
        "            }\n",
        "\n",
        "            # Append the dictionary to the data list\n",
        "            data.append(row_dict)\n",
        "\n",
        "        # Create a DataFrame from the data list\n",
        "        df = pd.DataFrame(data)\n",
        "        # Close the cursor and connection\n",
        "        cursor.close()\n",
        "        db_connection.close()\n",
        "\n",
        "        # Print the DataFrame\n",
        "        return df\n",
        "\n",
        "    def get_TestData(self, config):\n",
        "\n",
        "\n",
        "        db_connection = pymysql.connect(\n",
        "           **config\n",
        "        )\n",
        "        cursor = db_connection.cursor()\n",
        "\n",
        "        # Execute the SQL query to fetch the data\n",
        "        sql = \"SELECT * FROM devcon_test\"\n",
        "        cursor.execute(sql)\n",
        "\n",
        "        # Fetch all the rows returned by the query\n",
        "        rows = cursor.fetchall()\n",
        "\n",
        "        data = []\n",
        "\n",
        "        # Iterate over the rows and append data to the list as dictionaries\n",
        "        for row in rows:\n",
        "            raw_id = row[1]\n",
        "            raw_first_party = row[2]\n",
        "            raw_second_party = row[3]\n",
        "            raw_facts = row[4]\n",
        "\n",
        "            # Create a dictionary for the row\n",
        "            row_dict = {\n",
        "                '_id': raw_id,\n",
        "                'raw_first_party': raw_first_party,\n",
        "                'raw_second_party': raw_second_party,\n",
        "                'raw_facts': raw_facts,\n",
        "            }\n",
        "\n",
        "            # Append the dictionary to the data list\n",
        "            data.append(row_dict)\n",
        "\n",
        "        # Create a DataFrame from the data list\n",
        "        df = pd.DataFrame(data)\n",
        "        # Close the cursor and connection\n",
        "        cursor.close()\n",
        "        db_connection.close()\n",
        "\n",
        "        # Print the DataFrame\n",
        "        return df\n",
        "\n",
        "    def update_TrainData(self, config, dataFrame):\n",
        "        db_connection = pymysql.connect(\n",
        "           **config\n",
        "        )\n",
        "        cursor = db_connection.cursor()\n",
        "        sql = \"update devcon set raw_facts ='%s' where raw_ID = '%s'\"\n",
        "\n",
        "        for index, row in enumerate(dataFrame):\n",
        "             row['']\n",
        "             cursor.execute(sql.format())\n",
        "\n",
        "        cursor.execute(sql)\n",
        "        cursor.close()\n",
        "        db_connection.close()"
      ],
      "metadata": {
        "id": "O3gs5db9X0EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connectionInfo = {\n",
        "    'host':'private.dotge.site',\n",
        "    'user':'ade345',\n",
        "    'password':'dbslwms123',\n",
        "    'database':'books'\n",
        "}\n",
        "alpha = DbHelper()\n",
        "test_df=alpha.get_TestData(connectionInfo)\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "78tghQwcXvnx",
        "outputId": "93e1fef8-814d-47db-e7a7-31281950ef07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            _id                                    raw_first_party  \\\n",
              "0     TEST_0000                                            Salerno   \n",
              "1     TEST_0001             Milberg Weiss Bershad Hynes and Lerach   \n",
              "2     TEST_0002  No. 07-582\\t Title: \\t Federal Communications ...   \n",
              "3     TEST_0003                                    Harold Kaufman    \n",
              "4     TEST_0004                                             Berger   \n",
              "...         ...                                                ...   \n",
              "1235  TEST_1235              Haitian Centers Council, Inc., et al.   \n",
              "1236  TEST_1236                                            Whitman   \n",
              "1237  TEST_1237                Linda A. Matteo and John J. Madigan   \n",
              "1238  TEST_1238      Washington State Apple Advertising Commission   \n",
              "1239  TEST_1239                                   Theodore Stovall   \n",
              "\n",
              "                                       raw_second_party  \\\n",
              "0                                         United States   \n",
              "1                                         Lexecon, Inc.   \n",
              "2                 Fox Television Stations, Inc., et al.   \n",
              "3                                         United States   \n",
              "4                                                Hanlon   \n",
              "...                                                 ...   \n",
              "1235  Chris Sale, Acting Commissioner, Immigration A...   \n",
              "1236               American Trucking Associations, Inc.   \n",
              "1237                                    William G. Barr   \n",
              "1238                                               Hunt   \n",
              "1239                              Wilfred Denno, Warden   \n",
              "\n",
              "                                              raw_facts  \n",
              "0     The 1984 Bail Reform Act allowed the federal c...  \n",
              "1     Lexecon Inc. was a defendant in a class action...  \n",
              "2     In 2002 and 2003, Fox Television Stations broa...  \n",
              "3     During his trial for armed robbery of a federa...  \n",
              "4     In 1993, a magistrate judge issued a warrant a...  \n",
              "...                                                 ...  \n",
              "1235  According to Executive Order No. 12807 signed ...  \n",
              "1236  Section 109(a) of the Clean Air Act (CAA) requ...  \n",
              "1237  Linda Matteo and John Madigan created a plan f...  \n",
              "1238  In 1972, the North Carolina Board of Agricultu...  \n",
              "1239  On August 23, 1961, Dr. Paul Berheldt was stab...  \n",
              "\n",
              "[1240 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a39f921-404c-490b-b2fd-436917f748b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>raw_first_party</th>\n",
              "      <th>raw_second_party</th>\n",
              "      <th>raw_facts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_0000</td>\n",
              "      <td>Salerno</td>\n",
              "      <td>United States</td>\n",
              "      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_0001</td>\n",
              "      <td>Milberg Weiss Bershad Hynes and Lerach</td>\n",
              "      <td>Lexecon, Inc.</td>\n",
              "      <td>Lexecon Inc. was a defendant in a class action...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_0002</td>\n",
              "      <td>No. 07-582\\t Title: \\t Federal Communications ...</td>\n",
              "      <td>Fox Television Stations, Inc., et al.</td>\n",
              "      <td>In 2002 and 2003, Fox Television Stations broa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_0003</td>\n",
              "      <td>Harold Kaufman</td>\n",
              "      <td>United States</td>\n",
              "      <td>During his trial for armed robbery of a federa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_0004</td>\n",
              "      <td>Berger</td>\n",
              "      <td>Hanlon</td>\n",
              "      <td>In 1993, a magistrate judge issued a warrant a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>TEST_1235</td>\n",
              "      <td>Haitian Centers Council, Inc., et al.</td>\n",
              "      <td>Chris Sale, Acting Commissioner, Immigration A...</td>\n",
              "      <td>According to Executive Order No. 12807 signed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1236</th>\n",
              "      <td>TEST_1236</td>\n",
              "      <td>Whitman</td>\n",
              "      <td>American Trucking Associations, Inc.</td>\n",
              "      <td>Section 109(a) of the Clean Air Act (CAA) requ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>TEST_1237</td>\n",
              "      <td>Linda A. Matteo and John J. Madigan</td>\n",
              "      <td>William G. Barr</td>\n",
              "      <td>Linda Matteo and John Madigan created a plan f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>TEST_1238</td>\n",
              "      <td>Washington State Apple Advertising Commission</td>\n",
              "      <td>Hunt</td>\n",
              "      <td>In 1972, the North Carolina Board of Agricultu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>TEST_1239</td>\n",
              "      <td>Theodore Stovall</td>\n",
              "      <td>Wilfred Denno, Warden</td>\n",
              "      <td>On August 23, 1961, Dr. Paul Berheldt was stab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1240 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a39f921-404c-490b-b2fd-436917f748b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a39f921-404c-490b-b2fd-436917f748b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a39f921-404c-490b-b2fd-436917f748b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_facts_test  = list(map(lambda x: x.split(), test_df['raw_facts']))\n",
        "raw_facts_test[:5]\n",
        "raw_id_test = test_df['_id']"
      ],
      "metadata": {
        "id": "vLG1SdpTYk9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = test_df['raw_facts'].tolist()"
      ],
      "metadata": {
        "id": "d6i6rYpYZ409"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Haz8vcMaY5C"
      },
      "outputs": [],
      "source": [
        "# 레이어 구조 확인\n",
        "display(plot_model(wf.model, show_shapes=True))\n",
        "wf.model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5wH-uoGaY5C"
      },
      "outputs": [],
      "source": [
        "# 시각화\n",
        "wf.visualizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe_wBYM8aY5C"
      },
      "outputs": [],
      "source": [
        "# 저장된 weight 불러오기\n",
        "f  = wf.model.load_weights(f\"{save_name}.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_5fXbsDaY5C"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}