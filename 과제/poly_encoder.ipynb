{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjN15V5lBHU6PuQtrgJ8UA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/%EA%B3%BC%EC%A0%9C/poly_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5기분들 코드"
      ],
      "metadata": {
        "id": "UsPUdwzL6k5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "3cxfaBBYbqoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da69401-199a-424e-f7ce-a49a478878f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmu__DU2Tp72",
        "outputId": "4b06aa9c-b8d8-488f-d3dd-8c2e88eb60e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Poly-Encoder'...\n",
            "remote: Enumerating objects: 368, done.\u001b[K\n",
            "remote: Counting objects: 100% (360/360), done.\u001b[K\n",
            "remote: Compressing objects: 100% (217/217), done.\u001b[K\n",
            "remote: Total 368 (delta 197), reused 291 (delta 138), pack-reused 8\u001b[K\n",
            "Receiving objects: 100% (368/368), 83.34 MiB | 13.64 MiB/s, done.\n",
            "Resolving deltas: 100% (199/199), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/doh0106/Poly-Encoder.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Poly-Encoder/models/bert\n",
        "# kobert 모델\n",
        "!gdown 1R3QB2KADpICk0csnS_nEH5tAEl4FkaCP\n",
        "\n",
        "# # !mkdir /content/Poly-Encoder/models/roberta\n",
        "# %cd /content/Poly-Encoder/models/roberta\n",
        "# # robert 모델\n",
        "# !gdown 1QUk_Q6gGSRebFVWfjuPrsy6RAn4OZwv-"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IpuUGWuX9I_",
        "outputId": "26b6871e-c5ce-4343-c017-7d1b2a1989ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder/models/bert\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1R3QB2KADpICk0csnS_nEH5tAEl4FkaCP\n",
            "To: /content/Poly-Encoder/models/bert/pytorch_model.bin\n",
            "100% 589M/589M [00:07<00:00, 74.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Poly-Encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCklj2KiYFlm",
        "outputId": "c01f1994-f501-4efa-d631-0bee3e1f196f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train poly_encoder\n",
        "!python utils/run.py \\\n",
        "--model_type bert \\\n",
        "--bert_model models/bert/ \\\n",
        "--output_dir result/train1 \\\n",
        "--train_dir datasets/ \\\n",
        "--train_file dasan_train_data.pickle \\\n",
        "--valid_file dasan_train_data.pickle \\\n",
        "--use_pretrain \\\n",
        "--architecture poly \\\n",
        "--poly_m 16 \\\n",
        "--train_batch_size 2 \\\n",
        "--eval_batch_size 2 \\\n",
        "--max_contexts_length 256 \\\n",
        "--max_response_length 64 \\\n",
        "--num_train_epochs 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQT9pKy_YUtO",
        "outputId": "e0a90cce-3ec3-4fb8-a885-0533cd1b9624"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-30 12:57:27.176070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(bert_model='models/bert/', eval=False, model_type='bert', output_dir='result/train1', train_dir='datasets/', train_file='dasan_train_data.pickle', valid_file='dasan_train_data.pickle', test_file='test.pickle', neg_size=15, use_pretrain=True, architecture='poly', max_contexts_length=256, max_response_length=64, train_batch_size=2, eval_batch_size=2, print_freq=100, poly_m=16, learning_rate=5e-05, weight_decay=0.01, warmup_steps=100, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, seed=12345, gradient_accumulation_steps=1, fp16=False, fp16_opt_level='O1', gpu=0)\n",
            "================================================================================\n",
            "Train dir: datasets/\n",
            "Output dir: result/train1\n",
            "================================================================================\n",
            "100% 884/884 [00:01<00:00, 571.23it/s]\n",
            "100% 884/884 [00:02<00:00, 355.11it/s]\n",
            "Loading parameters from models/bert/pytorch_model.bin\n",
            "Some weights of BertModel were not initialized from the model checkpoint at models/bert/ and are newly initialized: ['encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.attention.self.key.bias', 'pooler.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 42001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "모델 투 디바이스  cuda\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Print freq: 100 Eval freq: 221\n",
            " 23% 100/442 [00:16<00:55,  6.18it/s]100 3.5295294746987746\n",
            " 45% 200/442 [00:32<00:38,  6.22it/s]200 2.838690649403643\n",
            "Global Step 221 VAL res:\n",
            " {'train_loss': 2.7357834815426214, 'eval_loss': 2.77212627279273, 'R1': 0.0916289592760181, 'R2': 0.16968325791855204, 'R5': 0.38122171945701355, 'R10': 0.6798642533936652, 'MRR': 0.2435205066426786, 'epoch': 1, 'global_step': 221}\n",
            "[Saving at] result/train1/poly_16_pytorch_model.bin\n",
            " 68% 300/442 [01:52<01:04,  2.19it/s]300 2.584766810773817\n",
            " 90% 400/442 [02:09<00:14,  2.93it/s]400 2.4313813798420187\n",
            "Global Step 442 VAL res:\n",
            " {'train_loss': 2.355970745772398, 'eval_loss': 2.772261884956878, 'R1': 0.07692307692307693, 'R2': 0.1595022624434389, 'R5': 0.3744343891402715, 'R10': 0.6776018099547512, 'MRR': 0.2308618433477031, 'epoch': 1, 'global_step': 442}\n",
            "[Saving at] result/train1/poly_16_pytorch_model_train.bin\n",
            "Epoch 1, Global Step 442 VAL res:\n",
            " {'train_loss': 2.355970745772398, 'eval_loss': 2.772261884956878, 'R1': 0.07692307692307693, 'R2': 0.1595022624434389, 'R5': 0.3744343891402715, 'R10': 0.6776018099547512, 'MRR': 0.2308618433477031, 'epoch': 1, 'global_step': 442}\n",
            " 90% 400/442 [04:40<00:29,  1.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 /content/Poly-Encoder/utils/train.ipynb -bert_model /your/pretrained/model/dir/content/Poly-Encoder/models/bert/pytorch_model.bin --output_dir /your/ckpt/dir --train_dir /your/data/dir --use_pretrain --architecture poly --poly_m 16"
      ],
      "metadata": {
        "id": "BLQF_xyvXD9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train cross_encoder\n",
        "!python utils/run.py \\\n",
        "--model_type bert \\\n",
        "--bert_model models/bert/ \\\n",
        "--output_dir result/train2 \\\n",
        "--train_dir datasets/ \\\n",
        "--train_file dasan_train_data.pickle \\\n",
        "--valid_file dasan_train_data.pickle \\\n",
        "--use_pretrain \\\n",
        "--architecture cross \\\n",
        "--train_batch_size 2 \\\n",
        "--eval_batch_size 2 \\\n",
        "--max_contexts_length 256 \\\n",
        "--max_response_length 64 \\\n",
        "--num_train_epochs 1"
      ],
      "metadata": {
        "id": "z9A2NNPEcKqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e50e56-6e0a-4482-e74c-729dde9b8453"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-30 13:02:24.746225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(bert_model='models/bert/', eval=False, model_type='bert', output_dir='result/train2', train_dir='datasets/', train_file='dasan_train_data.pickle', valid_file='dasan_train_data.pickle', test_file='test.pickle', neg_size=15, use_pretrain=True, architecture='cross', max_contexts_length=256, max_response_length=64, train_batch_size=2, eval_batch_size=2, print_freq=100, poly_m=0, learning_rate=5e-05, weight_decay=0.01, warmup_steps=100, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, seed=12345, gradient_accumulation_steps=1, fp16=False, fp16_opt_level='O1', gpu=0)\n",
            "================================================================================\n",
            "Train dir: datasets/\n",
            "Output dir: result/train2\n",
            "================================================================================\n",
            "100% 884/884 [00:01<00:00, 558.21it/s]\n",
            "100% 884/884 [00:01<00:00, 578.37it/s]\n",
            "Loading parameters from models/bert/pytorch_model.bin\n",
            "Some weights of BertModel were not initialized from the model checkpoint at models/bert/ and are newly initialized: ['encoder.layer.11.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 42001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "모델 투 디바이스  cuda\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Print freq: 100 Eval freq: 221\n",
            " 23% 100/442 [02:45<09:24,  1.65s/it]100 2.820994520187378\n",
            " 45% 200/442 [05:28<06:37,  1.64s/it]200 2.8014587366580965\n",
            "Global Step 221 VAL res:\n",
            " {'train_loss': 2.800697115212005, 'eval_loss': 2.7725023085175597, 'R1': 0.06447963800904978, 'R2': 0.13009049773755657, 'R5': 0.3076923076923077, 'R10': 0.6255656108597285, 'MRR': 0.2122837601061583, 'epoch': 1, 'global_step': 221}\n",
            "[Saving at] result/train2/cross_0_pytorch_model.bin\n",
            " 68% 300/442 [12:40<06:46,  2.86s/it]300 2.8026535518964133\n",
            " 90% 400/442 [15:23<01:39,  2.38s/it]400 2.808316477537155\n",
            "Global Step 442 VAL res:\n",
            " {'train_loss': 2.806202758491309, 'eval_loss': 2.772539251530332, 'R1': 0.0746606334841629, 'R2': 0.12669683257918551, 'R5': 0.333710407239819, 'R10': 0.6527149321266968, 'MRR': 0.2236346656736928, 'epoch': 1, 'global_step': 442}\n",
            "[Saving at] result/train2/cross_0_pytorch_model_train.bin\n",
            "Epoch 1, Global Step 442 VAL res:\n",
            " {'train_loss': 2.806202758491309, 'eval_loss': 2.772539251530332, 'R1': 0.0746606334841629, 'R2': 0.12669683257918551, 'R5': 0.333710407239819, 'R10': 0.6527149321266968, 'MRR': 0.2236346656736928, 'epoch': 1, 'global_step': 442}\n",
            " 90% 400/442 [25:22<02:39,  3.81s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9jsetx-FfyA0",
        "outputId": "797cd6c6-8899-4dbb-8bca-5c9f0708aea0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Poly-Encoder'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.model_for_inference import Load_Model_Tokenizer\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "\n",
        "CATEGORY = 'corona' # normal, water, corona\n",
        "\n",
        "poly_dir = '/content/Poly-Encoder/result/train1'\n",
        "cross_dir = '/content/Poly-Encoder/result/train2'\n",
        "emb_dir = '/content/Poly-Encoder/datasets'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# q1, q2, q3, q4, text, embedding(text에 대한) 저장 pickle / 하지만 현재는 inference에 text와 embedding만 사용\n",
        "# with open(os.path.join(emb_dir, f'{CATEGORY}_with_text.pickle'), 'rb') as f:\n",
        "with open(os.path.join(emb_dir, f'{CATEGORY}_with_text.pickle'), 'rb') as f:\n",
        "    embedding_df = pickle.load(f)\n",
        "\n",
        "cross_encoder, _ = Load_Model_Tokenizer(cross_dir, model_type='cross')\n",
        "poly_encoder, tokenizer = Load_Model_Tokenizer(poly_dir, model_type='poly')\n",
        "cross_encoder.to(device)\n",
        "poly_encoder.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cflSu3RcG2P",
        "outputId": "3046cf1c-bca4-4f44-eb4d-5fbf4b693073"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder/result/train2/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 42001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 준비 끝\n",
            "/content/Poly-Encoder/result/train1/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 42001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 준비 끝\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PolyEncoder(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(42001, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (poly_code_embeddings): Embedding(16, 768)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 코드 셀 <undefined>\n",
        "# # # %% [code]\n",
        "from utils.inference import Callcenter\n",
        "import numpy as np\n",
        "\n",
        "call_center = Callcenter(poly_encoder=poly_encoder, cross_encoder=cross_encoder,\n",
        "                        tokenizer=tokenizer, emb_df=embedding_df, device=device, topk=5)\n",
        "\n",
        "query = '집에 가고 싶다.'\n",
        "top_k_cross_scores, top_k_indices= call_center.inference(query)\n",
        "# poly score가 가장 높은 k개의 답변 값들의 cross score 값과 index들 반환\n",
        "\n",
        "top_cross_idx = top_k_indices[np.argmax(top_k_cross_scores)]\n",
        "# k개의 답변들 중 cross score가 가장 높은 idx이용하여 최종 답변 산출\n",
        "answer = embedding_df['text'].iloc[top_cross_idx]\n",
        "\n",
        "print(f'질문 : {query}')\n",
        "print(f'답변 : {answer}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6BbwqCaq5QC",
        "outputId": "d33c6146-45b1-45f7-ea3a-4918913de895"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문 : 집에 가고 싶다.\n",
            "답변 :   네, 코로나십구 장기화로 매출 타격을 받고 있는 소상공인과 생계에 어려움을 겪는 취약계층 가구를 대상으로 도시가스 요금 납부 부담을 완화해드립니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 코드 셀 <undefined>\n",
        "# # # %% [code]\n",
        "from utils.inference import Callcenter\n",
        "import numpy as np\n",
        "\n",
        "call_center = Callcenter(poly_encoder=poly_encoder, cross_encoder=cross_encoder,\n",
        "                        tokenizer=tokenizer, emb_df=embedding_df, device=device, topk=5)\n",
        "\n",
        "query = '코로나19.'\n",
        "top_k_cross_scores, top_k_indices= call_center.inference(query)\n",
        "# poly score가 가장 높은 k개의 답변 값들의 cross score 값과 index들 반환\n",
        "\n",
        "top_cross_idx = top_k_indices[np.argmax(top_k_cross_scores)]\n",
        "# k개의 답변들 중 cross score가 가장 높은 idx이용하여 최종 답변 산출\n",
        "answer = embedding_df['text'].iloc[top_cross_idx]\n",
        "\n",
        "print(f'질문 : {query}')\n",
        "print(f'답변 : {answer}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ludNeKZGrwS8",
        "outputId": "a479342a-c52b-41f6-df87-c21008b8a6dc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문 : 코로나19.\n",
            "답변 :   네, 코로나십구 장기화로 매출 타격을 받고 있는 소상공인과 생계에 어려움을 겪는 취약계층 가구를 대상으로 도시가스 요금 납부 부담을 완화해드립니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# infrence\n",
        "!python utils/text_2_emb.py \\\n",
        "--model_type bert \\\n",
        "--bert_model models/bert \\\n",
        "--text_path /path/to/카테고리별답변들.txt \\\n",
        "--output_dir /path/to/카테고리별embedding.pickle \\\n",
        "--gpu 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IRnirFkca7r",
        "outputId": "d157ed1a-9442-4ef3-c6cc-7ba1cf6b8e60"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(bert_model='models/bert', text_path='/path/to/카테고리별답변들.txt', max_response_length=128, output_dir='/path/to/카테고리별embedding.pickle', model_type='bert', gpu=1)\n",
            "Loading parameters from models/bert/pytorch_model.bin\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 42001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Poly-Encoder/utils/text_2_emb.py\", line 84, in <module>\n",
            "    model.load_state_dict(model_state_dict)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2041, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for PolyEncoder:\n",
            "\tMissing key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\", \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\", \"poly_code_embeddings.weight\". \n",
            "\tUnexpected key(s) in state_dict: \"encoder.embeddings.position_ids\", \"encoder.embeddings.word_embeddings.weight\", \"encoder.embeddings.position_embeddings.weight\", \"encoder.embeddings.token_type_embeddings.weight\", \"encoder.embeddings.LayerNorm.weight\", \"encoder.embeddings.LayerNorm.bias\", \"encoder.encoder.layer.0.attention.self.query.weight\", \"encoder.encoder.layer.0.attention.self.query.bias\", \"encoder.encoder.layer.0.attention.self.key.weight\", \"encoder.encoder.layer.0.attention.self.key.bias\", \"encoder.encoder.layer.0.attention.self.value.weight\", \"encoder.encoder.layer.0.attention.self.value.bias\", \"encoder.encoder.layer.0.attention.output.dense.weight\", \"encoder.encoder.layer.0.attention.output.dense.bias\", \"encoder.encoder.layer.0.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.0.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.0.intermediate.dense.weight\", \"encoder.encoder.layer.0.intermediate.dense.bias\", \"encoder.encoder.layer.0.output.dense.weight\", \"encoder.encoder.layer.0.output.dense.bias\", \"encoder.encoder.layer.0.output.LayerNorm.weight\", \"encoder.encoder.layer.0.output.LayerNorm.bias\", \"encoder.encoder.layer.1.attention.self.query.weight\", \"encoder.encoder.layer.1.attention.self.query.bias\", \"encoder.encoder.layer.1.attention.self.key.weight\", \"encoder.encoder.layer.1.attention.self.key.bias\", \"encoder.encoder.layer.1.attention.self.value.weight\", \"encoder.encoder.layer.1.attention.self.value.bias\", \"encoder.encoder.layer.1.attention.output.dense.weight\", \"encoder.encoder.layer.1.attention.output.dense.bias\", \"encoder.encoder.layer.1.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.1.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.1.intermediate.dense.weight\", \"encoder.encoder.layer.1.intermediate.dense.bias\", \"encoder.encoder.layer.1.output.dense.weight\", \"encoder.encoder.layer.1.output.dense.bias\", \"encoder.encoder.layer.1.output.LayerNorm.weight\", \"encoder.encoder.layer.1.output.LayerNorm.bias\", \"encoder.encoder.layer.2.attention.self.query.weight\", \"encoder.encoder.layer.2.attention.self.query.bias\", \"encoder.encoder.layer.2.attention.self.key.weight\", \"encoder.encoder.layer.2.attention.self.key.bias\", \"encoder.encoder.layer.2.attention.self.value.weight\", \"encoder.encoder.layer.2.attention.self.value.bias\", \"encoder.encoder.layer.2.attention.output.dense.weight\", \"encoder.encoder.layer.2.attention.output.dense.bias\", \"encoder.encoder.layer.2.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.2.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.2.intermediate.dense.weight\", \"encoder.encoder.layer.2.intermediate.dense.bias\", \"encoder.encoder.layer.2.output.dense.weight\", \"encoder.encoder.layer.2.output.dense.bias\", \"encoder.encoder.layer.2.output.LayerNorm.weight\", \"encoder.encoder.layer.2.output.LayerNorm.bias\", \"encoder.encoder.layer.3.attention.self.query.weight\", \"encoder.encoder.layer.3.attention.self.query.bias\", \"encoder.encoder.layer.3.attention.self.key.weight\", \"encoder.encoder.layer.3.attention.self.key.bias\", \"encoder.encoder.layer.3.attention.self.value.weight\", \"encoder.encoder.layer.3.attention.self.value.bias\", \"encoder.encoder.layer.3.attention.output.dense.weight\", \"encoder.encoder.layer.3.attention.output.dense.bias\", \"encoder.encoder.layer.3.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.3.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.3.intermediate.dense.weight\", \"encoder.encoder.layer.3.intermediate.dense.bias\", \"encoder.encoder.layer.3.output.dense.weight\", \"encoder.encoder.layer.3.output.dense.bias\", \"encoder.encoder.layer.3.output.LayerNorm.weight\", \"encoder.encoder.layer.3.output.LayerNorm.bias\", \"encoder.encoder.layer.4.attention.self.query.weight\", \"encoder.encoder.layer.4.attention.self.query.bias\", \"encoder.encoder.layer.4.attention.self.key.weight\", \"encoder.encoder.layer.4.attention.self.key.bias\", \"encoder.encoder.layer.4.attention.self.value.weight\", \"encoder.encoder.layer.4.attention.self.value.bias\", \"encoder.encoder.layer.4.attention.output.dense.weight\", \"encoder.encoder.layer.4.attention.output.dense.bias\", \"encoder.encoder.layer.4.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.4.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.4.intermediate.dense.weight\", \"encoder.encoder.layer.4.intermediate.dense.bias\", \"encoder.encoder.layer.4.output.dense.weight\", \"encoder.encoder.layer.4.output.dense.bias\", \"encoder.encoder.layer.4.output.LayerNorm.weight\", \"encoder.encoder.layer.4.output.LayerNorm.bias\", \"encoder.encoder.layer.5.attention.self.query.weight\", \"encoder.encoder.layer.5.attention.self.query.bias\", \"encoder.encoder.layer.5.attention.self.key.weight\", \"encoder.encoder.layer.5.attention.self.key.bias\", \"encoder.encoder.layer.5.attention.self.value.weight\", \"encoder.encoder.layer.5.attention.self.value.bias\", \"encoder.encoder.layer.5.attention.output.dense.weight\", \"encoder.encoder.layer.5.attention.output.dense.bias\", \"encoder.encoder.layer.5.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.5.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.5.intermediate.dense.weight\", \"encoder.encoder.layer.5.intermediate.dense.bias\", \"encoder.encoder.layer.5.output.dense.weight\", \"encoder.encoder.layer.5.output.dense.bias\", \"encoder.encoder.layer.5.output.LayerNorm.weight\", \"encoder.encoder.layer.5.output.LayerNorm.bias\", \"encoder.encoder.layer.6.attention.self.query.weight\", \"encoder.encoder.layer.6.attention.self.query.bias\", \"encoder.encoder.layer.6.attention.self.key.weight\", \"encoder.encoder.layer.6.attention.self.key.bias\", \"encoder.encoder.layer.6.attention.self.value.weight\", \"encoder.encoder.layer.6.attention.self.value.bias\", \"encoder.encoder.layer.6.attention.output.dense.weight\", \"encoder.encoder.layer.6.attention.output.dense.bias\", \"encoder.encoder.layer.6.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.6.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.6.intermediate.dense.weight\", \"encoder.encoder.layer.6.intermediate.dense.bias\", \"encoder.encoder.layer.6.output.dense.weight\", \"encoder.encoder.layer.6.output.dense.bias\", \"encoder.encoder.layer.6.output.LayerNorm.weight\", \"encoder.encoder.layer.6.output.LayerNorm.bias\", \"encoder.encoder.layer.7.attention.self.query.weight\", \"encoder.encoder.layer.7.attention.self.query.bias\", \"encoder.encoder.layer.7.attention.self.key.weight\", \"encoder.encoder.layer.7.attention.self.key.bias\", \"encoder.encoder.layer.7.attention.self.value.weight\", \"encoder.encoder.layer.7.attention.self.value.bias\", \"encoder.encoder.layer.7.attention.output.dense.weight\", \"encoder.encoder.layer.7.attention.output.dense.bias\", \"encoder.encoder.layer.7.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.7.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.7.intermediate.dense.weight\", \"encoder.encoder.layer.7.intermediate.dense.bias\", \"encoder.encoder.layer.7.output.dense.weight\", \"encoder.encoder.layer.7.output.dense.bias\", \"encoder.encoder.layer.7.output.LayerNorm.weight\", \"encoder.encoder.layer.7.output.LayerNorm.bias\", \"encoder.encoder.layer.8.attention.self.query.weight\", \"encoder.encoder.layer.8.attention.self.query.bias\", \"encoder.encoder.layer.8.attention.self.key.weight\", \"encoder.encoder.layer.8.attention.self.key.bias\", \"encoder.encoder.layer.8.attention.self.value.weight\", \"encoder.encoder.layer.8.attention.self.value.bias\", \"encoder.encoder.layer.8.attention.output.dense.weight\", \"encoder.encoder.layer.8.attention.output.dense.bias\", \"encoder.encoder.layer.8.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.8.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.8.intermediate.dense.weight\", \"encoder.encoder.layer.8.intermediate.dense.bias\", \"encoder.encoder.layer.8.output.dense.weight\", \"encoder.encoder.layer.8.output.dense.bias\", \"encoder.encoder.layer.8.output.LayerNorm.weight\", \"encoder.encoder.layer.8.output.LayerNorm.bias\", \"encoder.encoder.layer.9.attention.self.query.weight\", \"encoder.encoder.layer.9.attention.self.query.bias\", \"encoder.encoder.layer.9.attention.self.key.weight\", \"encoder.encoder.layer.9.attention.self.key.bias\", \"encoder.encoder.layer.9.attention.self.value.weight\", \"encoder.encoder.layer.9.attention.self.value.bias\", \"encoder.encoder.layer.9.attention.output.dense.weight\", \"encoder.encoder.layer.9.attention.output.dense.bias\", \"encoder.encoder.layer.9.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.9.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.9.intermediate.dense.weight\", \"encoder.encoder.layer.9.intermediate.dense.bias\", \"encoder.encoder.layer.9.output.dense.weight\", \"encoder.encoder.layer.9.output.dense.bias\", \"encoder.encoder.layer.9.output.LayerNorm.weight\", \"encoder.encoder.layer.9.output.LayerNorm.bias\", \"encoder.encoder.layer.10.attention.self.query.weight\", \"encoder.encoder.layer.10.attention.self.query.bias\", \"encoder.encoder.layer.10.attention.self.key.weight\", \"encoder.encoder.layer.10.attention.self.key.bias\", \"encoder.encoder.layer.10.attention.self.value.weight\", \"encoder.encoder.layer.10.attention.self.value.bias\", \"encoder.encoder.layer.10.attention.output.dense.weight\", \"encoder.encoder.layer.10.attention.output.dense.bias\", \"encoder.encoder.layer.10.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.10.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.10.intermediate.dense.weight\", \"encoder.encoder.layer.10.intermediate.dense.bias\", \"encoder.encoder.layer.10.output.dense.weight\", \"encoder.encoder.layer.10.output.dense.bias\", \"encoder.encoder.layer.10.output.LayerNorm.weight\", \"encoder.encoder.layer.10.output.LayerNorm.bias\", \"encoder.encoder.layer.11.attention.self.query.weight\", \"encoder.encoder.layer.11.attention.self.query.bias\", \"encoder.encoder.layer.11.attention.self.key.weight\", \"encoder.encoder.layer.11.attention.self.key.bias\", \"encoder.encoder.layer.11.attention.self.value.weight\", \"encoder.encoder.layer.11.attention.self.value.bias\", \"encoder.encoder.layer.11.attention.output.dense.weight\", \"encoder.encoder.layer.11.attention.output.dense.bias\", \"encoder.encoder.layer.11.attention.output.LayerNorm.weight\", \"encoder.encoder.layer.11.attention.output.LayerNorm.bias\", \"encoder.encoder.layer.11.intermediate.dense.weight\", \"encoder.encoder.layer.11.intermediate.dense.bias\", \"encoder.encoder.layer.11.output.dense.weight\", \"encoder.encoder.layer.11.output.dense.bias\", \"encoder.encoder.layer.11.output.LayerNorm.weight\", \"encoder.encoder.layer.11.output.LayerNorm.bias\", \"encoder.pooler.dense.weight\", \"encoder.pooler.dense.bias\", \"decoder.bert.embeddings.position_ids\", \"decoder.bert.embeddings.word_embeddings.weight\", \"decoder.bert.embeddings.position_embeddings.weight\", \"decoder.bert.embeddings.token_type_embeddings.weight\", \"decoder.bert.embeddings.LayerNorm.weight\", \"decoder.bert.embeddings.LayerNorm.bias\", \"decoder.bert.encoder.layer.0.attention.self.query.weight\", \"decoder.bert.encoder.layer.0.attention.self.query.bias\", \"decoder.bert.encoder.layer.0.attention.self.key.weight\", \"decoder.bert.encoder.layer.0.attention.self.key.bias\", \"decoder.bert.encoder.layer.0.attention.self.value.weight\", \"decoder.bert.encoder.layer.0.attention.self.value.bias\", \"decoder.bert.encoder.layer.0.attention.output.dense.weight\", \"decoder.bert.encoder.layer.0.attention.output.dense.bias\", \"decoder.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.0.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.0.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.0.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.0.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.0.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.0.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.0.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.0.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.0.intermediate.dense.weight\", \"decoder.bert.encoder.layer.0.intermediate.dense.bias\", \"decoder.bert.encoder.layer.0.output.dense.weight\", \"decoder.bert.encoder.layer.0.output.dense.bias\", \"decoder.bert.encoder.layer.0.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.0.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.1.attention.self.query.weight\", \"decoder.bert.encoder.layer.1.attention.self.query.bias\", \"decoder.bert.encoder.layer.1.attention.self.key.weight\", \"decoder.bert.encoder.layer.1.attention.self.key.bias\", \"decoder.bert.encoder.layer.1.attention.self.value.weight\", \"decoder.bert.encoder.layer.1.attention.self.value.bias\", \"decoder.bert.encoder.layer.1.attention.output.dense.weight\", \"decoder.bert.encoder.layer.1.attention.output.dense.bias\", \"decoder.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.1.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.1.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.1.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.1.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.1.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.1.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.1.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.1.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.1.intermediate.dense.weight\", \"decoder.bert.encoder.layer.1.intermediate.dense.bias\", \"decoder.bert.encoder.layer.1.output.dense.weight\", \"decoder.bert.encoder.layer.1.output.dense.bias\", \"decoder.bert.encoder.layer.1.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.1.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.2.attention.self.query.weight\", \"decoder.bert.encoder.layer.2.attention.self.query.bias\", \"decoder.bert.encoder.layer.2.attention.self.key.weight\", \"decoder.bert.encoder.layer.2.attention.self.key.bias\", \"decoder.bert.encoder.layer.2.attention.self.value.weight\", \"decoder.bert.encoder.layer.2.attention.self.value.bias\", \"decoder.bert.encoder.layer.2.attention.output.dense.weight\", \"decoder.bert.encoder.layer.2.attention.output.dense.bias\", \"decoder.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.2.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.2.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.2.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.2.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.2.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.2.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.2.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.2.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.2.intermediate.dense.weight\", \"decoder.bert.encoder.layer.2.intermediate.dense.bias\", \"decoder.bert.encoder.layer.2.output.dense.weight\", \"decoder.bert.encoder.layer.2.output.dense.bias\", \"decoder.bert.encoder.layer.2.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.2.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.3.attention.self.query.weight\", \"decoder.bert.encoder.layer.3.attention.self.query.bias\", \"decoder.bert.encoder.layer.3.attention.self.key.weight\", \"decoder.bert.encoder.layer.3.attention.self.key.bias\", \"decoder.bert.encoder.layer.3.attention.self.value.weight\", \"decoder.bert.encoder.layer.3.attention.self.value.bias\", \"decoder.bert.encoder.layer.3.attention.output.dense.weight\", \"decoder.bert.encoder.layer.3.attention.output.dense.bias\", \"decoder.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.3.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.3.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.3.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.3.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.3.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.3.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.3.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.3.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.3.intermediate.dense.weight\", \"decoder.bert.encoder.layer.3.intermediate.dense.bias\", \"decoder.bert.encoder.layer.3.output.dense.weight\", \"decoder.bert.encoder.layer.3.output.dense.bias\", \"decoder.bert.encoder.layer.3.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.3.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.4.attention.self.query.weight\", \"decoder.bert.encoder.layer.4.attention.self.query.bias\", \"decoder.bert.encoder.layer.4.attention.self.key.weight\", \"decoder.bert.encoder.layer.4.attention.self.key.bias\", \"decoder.bert.encoder.layer.4.attention.self.value.weight\", \"decoder.bert.encoder.layer.4.attention.self.value.bias\", \"decoder.bert.encoder.layer.4.attention.output.dense.weight\", \"decoder.bert.encoder.layer.4.attention.output.dense.bias\", \"decoder.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.4.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.4.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.4.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.4.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.4.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.4.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.4.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.4.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.4.intermediate.dense.weight\", \"decoder.bert.encoder.layer.4.intermediate.dense.bias\", \"decoder.bert.encoder.layer.4.output.dense.weight\", \"decoder.bert.encoder.layer.4.output.dense.bias\", \"decoder.bert.encoder.layer.4.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.4.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.5.attention.self.query.weight\", \"decoder.bert.encoder.layer.5.attention.self.query.bias\", \"decoder.bert.encoder.layer.5.attention.self.key.weight\", \"decoder.bert.encoder.layer.5.attention.self.key.bias\", \"decoder.bert.encoder.layer.5.attention.self.value.weight\", \"decoder.bert.encoder.layer.5.attention.self.value.bias\", \"decoder.bert.encoder.layer.5.attention.output.dense.weight\", \"decoder.bert.encoder.layer.5.attention.output.dense.bias\", \"decoder.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.5.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.5.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.5.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.5.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.5.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.5.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.5.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.5.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.5.intermediate.dense.weight\", \"decoder.bert.encoder.layer.5.intermediate.dense.bias\", \"decoder.bert.encoder.layer.5.output.dense.weight\", \"decoder.bert.encoder.layer.5.output.dense.bias\", \"decoder.bert.encoder.layer.5.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.5.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.6.attention.self.query.weight\", \"decoder.bert.encoder.layer.6.attention.self.query.bias\", \"decoder.bert.encoder.layer.6.attention.self.key.weight\", \"decoder.bert.encoder.layer.6.attention.self.key.bias\", \"decoder.bert.encoder.layer.6.attention.self.value.weight\", \"decoder.bert.encoder.layer.6.attention.self.value.bias\", \"decoder.bert.encoder.layer.6.attention.output.dense.weight\", \"decoder.bert.encoder.layer.6.attention.output.dense.bias\", \"decoder.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.6.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.6.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.6.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.6.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.6.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.6.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.6.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.6.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.6.intermediate.dense.weight\", \"decoder.bert.encoder.layer.6.intermediate.dense.bias\", \"decoder.bert.encoder.layer.6.output.dense.weight\", \"decoder.bert.encoder.layer.6.output.dense.bias\", \"decoder.bert.encoder.layer.6.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.6.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.7.attention.self.query.weight\", \"decoder.bert.encoder.layer.7.attention.self.query.bias\", \"decoder.bert.encoder.layer.7.attention.self.key.weight\", \"decoder.bert.encoder.layer.7.attention.self.key.bias\", \"decoder.bert.encoder.layer.7.attention.self.value.weight\", \"decoder.bert.encoder.layer.7.attention.self.value.bias\", \"decoder.bert.encoder.layer.7.attention.output.dense.weight\", \"decoder.bert.encoder.layer.7.attention.output.dense.bias\", \"decoder.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.7.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.7.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.7.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.7.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.7.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.7.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.7.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.7.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.7.intermediate.dense.weight\", \"decoder.bert.encoder.layer.7.intermediate.dense.bias\", \"decoder.bert.encoder.layer.7.output.dense.weight\", \"decoder.bert.encoder.layer.7.output.dense.bias\", \"decoder.bert.encoder.layer.7.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.7.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.8.attention.self.query.weight\", \"decoder.bert.encoder.layer.8.attention.self.query.bias\", \"decoder.bert.encoder.layer.8.attention.self.key.weight\", \"decoder.bert.encoder.layer.8.attention.self.key.bias\", \"decoder.bert.encoder.layer.8.attention.self.value.weight\", \"decoder.bert.encoder.layer.8.attention.self.value.bias\", \"decoder.bert.encoder.layer.8.attention.output.dense.weight\", \"decoder.bert.encoder.layer.8.attention.output.dense.bias\", \"decoder.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.8.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.8.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.8.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.8.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.8.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.8.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.8.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.8.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.8.intermediate.dense.weight\", \"decoder.bert.encoder.layer.8.intermediate.dense.bias\", \"decoder.bert.encoder.layer.8.output.dense.weight\", \"decoder.bert.encoder.layer.8.output.dense.bias\", \"decoder.bert.encoder.layer.8.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.8.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.9.attention.self.query.weight\", \"decoder.bert.encoder.layer.9.attention.self.query.bias\", \"decoder.bert.encoder.layer.9.attention.self.key.weight\", \"decoder.bert.encoder.layer.9.attention.self.key.bias\", \"decoder.bert.encoder.layer.9.attention.self.value.weight\", \"decoder.bert.encoder.layer.9.attention.self.value.bias\", \"decoder.bert.encoder.layer.9.attention.output.dense.weight\", \"decoder.bert.encoder.layer.9.attention.output.dense.bias\", \"decoder.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.9.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.9.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.9.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.9.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.9.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.9.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.9.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.9.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.9.intermediate.dense.weight\", \"decoder.bert.encoder.layer.9.intermediate.dense.bias\", \"decoder.bert.encoder.layer.9.output.dense.weight\", \"decoder.bert.encoder.layer.9.output.dense.bias\", \"decoder.bert.encoder.layer.9.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.9.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.10.attention.self.query.weight\", \"decoder.bert.encoder.layer.10.attention.self.query.bias\", \"decoder.bert.encoder.layer.10.attention.self.key.weight\", \"decoder.bert.encoder.layer.10.attention.self.key.bias\", \"decoder.bert.encoder.layer.10.attention.self.value.weight\", \"decoder.bert.encoder.layer.10.attention.self.value.bias\", \"decoder.bert.encoder.layer.10.attention.output.dense.weight\", \"decoder.bert.encoder.layer.10.attention.output.dense.bias\", \"decoder.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.10.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.10.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.10.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.10.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.10.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.10.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.10.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.10.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.10.intermediate.dense.weight\", \"decoder.bert.encoder.layer.10.intermediate.dense.bias\", \"decoder.bert.encoder.layer.10.output.dense.weight\", \"decoder.bert.encoder.layer.10.output.dense.bias\", \"decoder.bert.encoder.layer.10.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.10.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.11.attention.self.query.weight\", \"decoder.bert.encoder.layer.11.attention.self.query.bias\", \"decoder.bert.encoder.layer.11.attention.self.key.weight\", \"decoder.bert.encoder.layer.11.attention.self.key.bias\", \"decoder.bert.encoder.layer.11.attention.self.value.weight\", \"decoder.bert.encoder.layer.11.attention.self.value.bias\", \"decoder.bert.encoder.layer.11.attention.output.dense.weight\", \"decoder.bert.encoder.layer.11.attention.output.dense.bias\", \"decoder.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.11.crossattention.self.query.weight\", \"decoder.bert.encoder.layer.11.crossattention.self.query.bias\", \"decoder.bert.encoder.layer.11.crossattention.self.key.weight\", \"decoder.bert.encoder.layer.11.crossattention.self.key.bias\", \"decoder.bert.encoder.layer.11.crossattention.self.value.weight\", \"decoder.bert.encoder.layer.11.crossattention.self.value.bias\", \"decoder.bert.encoder.layer.11.crossattention.output.dense.weight\", \"decoder.bert.encoder.layer.11.crossattention.output.dense.bias\", \"decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias\", \"decoder.bert.encoder.layer.11.intermediate.dense.weight\", \"decoder.bert.encoder.layer.11.intermediate.dense.bias\", \"decoder.bert.encoder.layer.11.output.dense.weight\", \"decoder.bert.encoder.layer.11.output.dense.bias\", \"decoder.bert.encoder.layer.11.output.LayerNorm.weight\", \"decoder.bert.encoder.layer.11.output.LayerNorm.bias\", \"decoder.cls.predictions.bias\", \"decoder.cls.predictions.transform.dense.weight\", \"decoder.cls.predictions.transform.dense.bias\", \"decoder.cls.predictions.transform.LayerNorm.weight\", \"decoder.cls.predictions.transform.LayerNorm.bias\", \"decoder.cls.predictions.decoder.weight\", \"decoder.cls.predictions.decoder.bias\". \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 원본 코드"
      ],
      "metadata": {
        "id": "rXvT31FJ6pt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parlai interactive -m transformer/polyencoder \\\n",
        "    -mf zoo:pretrained_transformers/model_poly/model \\\n",
        "    --encode-candidate-vecs true \\\n",
        "    --eval-candidates fixed  \\\n",
        "    --fixed-candidates-path data/models/pretrained_transformers/convai_trainset_cands.txt"
      ],
      "metadata": {
        "id": "O0jlAQDWUcRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다른 git코드"
      ],
      "metadata": {
        "id": "h4rhBueuqhW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubdinMpPqlWU",
        "outputId": "bb54ed92-b536-459d-d907-5a8e149fa488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: You must specify a repository to clone.\n",
            "\n",
            "usage: git clone [<options>] [--] <repo> [<dir>]\n",
            "\n",
            "    -v, --verbose         be more verbose\n",
            "    -q, --quiet           be more quiet\n",
            "    --progress            force progress reporting\n",
            "    --reject-shallow      don't clone shallow repository\n",
            "    -n, --no-checkout     don't create a checkout\n",
            "    --bare                create a bare repository\n",
            "    --mirror              create a mirror repository (implies bare)\n",
            "    -l, --local           to clone from a local repository\n",
            "    --no-hardlinks        don't use local hardlinks, always copy\n",
            "    -s, --shared          setup as shared repository\n",
            "    --recurse-submodules[=<pathspec>]\n",
            "                          initialize submodules in the clone\n",
            "    --recursive ...       alias of --recurse-submodules\n",
            "    -j, --jobs <n>        number of submodules cloned in parallel\n",
            "    --template <template-directory>\n",
            "                          directory from which templates will be used\n",
            "    --reference <repo>    reference repository\n",
            "    --reference-if-able <repo>\n",
            "                          reference repository\n",
            "    --dissociate          use --reference only while cloning\n",
            "    -o, --origin <name>   use <name> instead of 'origin' to track upstream\n",
            "    -b, --branch <branch>\n",
            "                          checkout <branch> instead of the remote's HEAD\n",
            "    -u, --upload-pack <path>\n",
            "                          path to git-upload-pack on the remote\n",
            "    --depth <depth>       create a shallow clone of that depth\n",
            "    --shallow-since <time>\n",
            "                          create a shallow clone since a specific time\n",
            "    --shallow-exclude <revision>\n",
            "                          deepen history of shallow clone, excluding rev\n",
            "    --single-branch       clone only one branch, HEAD or --branch\n",
            "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
            "    --shallow-submodules  any cloned submodules will be shallow\n",
            "    --separate-git-dir <gitdir>\n",
            "                          separate git dir from working tree\n",
            "    -c, --config <key=value>\n",
            "                          set config inside the new repository\n",
            "    --server-option <server-specific>\n",
            "                          option to transmit\n",
            "    -4, --ipv4            use IPv4 addresses only\n",
            "    -6, --ipv6            use IPv6 addresses only\n",
            "    --filter <args>       object filtering\n",
            "    --remote-submodules   any cloned submodules will use their remote-tracking branch\n",
            "    --sparse              initialize sparse-checkout file to include only files at root\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python3 run.py --bert_model bert_model/ --output_dir output_dstc7/ --train_dir dstc7/ --use_pretrain --architecture poly --poly_m 16 --eval"
      ],
      "metadata": {
        "id": "JehVX2Mcq9tw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}