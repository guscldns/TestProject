{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmL3Fh92iYeskG8LD21pDm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guscldns/TestProject/blob/main/%EA%B3%BC%EC%A0%9C/json_to_text%2C_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNSgmmwVafim"
      },
      "outputs": [],
      "source": [
        "# 샘플파일\n",
        "!gdown 1rswWV67Idv8OXI1qQ7o5aSSWvP_uA5MW\n",
        "# 맑음고딕 폰트\n",
        "!gdown 1G4jAcJLy_1PC9YQR36t7jMapj9da4vPd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "from PIL import Image, ImageDraw, ImageFont"
      ],
      "metadata": {
        "id": "oQxQ_E0DauX1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/sample\n",
        "%cd /content/sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3KtH-jqbRPA",
        "outputId": "40636c6e-30be-4dfa-de42-15f376c1cf79"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/sample.zip"
      ],
      "metadata": {
        "id": "26U5g5OJbJLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/text\n",
        "!mkdir /content/jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIrMmITWetH8",
        "outputId": "b4fc0bd1-ffdf-4f19-c916-f503a404ae6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "foilderlist = os.listdir('/content/sample')\n",
        "for i in foilderlist:\n",
        "    per_path = f'/content/sample/{i}/20per'\n",
        "    sent_path = f'/content/sample/{i}/2~3sent'\n",
        "    per_list = os.listdir(per_path)\n",
        "    sent_list = os.listdir(sent_path)\n",
        "    for j in per_list:\n",
        "\n",
        "        with open(f'{per_path}/{j}', 'r', encoding='utf-8') as file:\n",
        "            text = json.load(file)\n",
        "            passage =f\"  {text['Meta(Refine)']['passage']}\"\n",
        "\n",
        "        # Save the extracted passage to the 'test' directory\n",
        "            with open(f'/content/text/{j[:-4]}.txt', 'w', encoding='utf-8') as f:\n",
        "                f.write(passage)\n",
        "\n",
        "        # Create an image with the text\n",
        "        image_width = 800  # Adjust as needed\n",
        "        font_size = 18\n",
        "        font_path = \"/content/malgun.ttf\"  # Replace with your font path\n",
        "\n",
        "        # Load a Unicode font\n",
        "        font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "        # Calculate image height and initialize variables\n",
        "        lines = []\n",
        "        line = \"\"\n",
        "        left_margin = 50\n",
        "        right_margin = 50\n",
        "        for word in passage.split():\n",
        "            # Check if adding the current word exceeds the available width\n",
        "            if font.getsize(line + \" \" + word)[0] <= (image_width - left_margin - right_margin):\n",
        "                line += \" \" + word\n",
        "            else:\n",
        "                lines.append(line)\n",
        "                line = word\n",
        "\n",
        "        lines.append(line)  # Append the last line\n",
        "\n",
        "        # Calculate image height based on the number of lines\n",
        "        vertical_space = 10\n",
        "        top_margin = 50\n",
        "        bottom_margin = 50\n",
        "        line_height = font.getsize('A')[1]  # Height of a line of text\n",
        "        image_height = line_height * len(lines) + (len(lines) - 1) * vertical_space + top_margin + bottom_margin\n",
        "\n",
        "        # Create a new image with margins\n",
        "        image = Image.new('RGB', (image_width, image_height), color='white')\n",
        "        draw = ImageDraw.Draw(image)\n",
        "\n",
        "        # Draw the text on the image with margins\n",
        "        y_position = top_margin  # Adjust the starting y position\n",
        "        text_color = (0, 0, 0)  # Black color\n",
        "\n",
        "        for line in lines:\n",
        "            x_position = left_margin  # Adjust the starting x position\n",
        "            draw.text((x_position, y_position), line, fill=text_color, font=font)\n",
        "            y_position += line_height + vertical_space\n",
        "\n",
        "        # Save the image as JPG\n",
        "        image.save(f'/content/jpg/{j[:-4]}.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nPAFNSabL18",
        "outputId": "d348d2b3-8366-494a-bbd5-45e92d8988c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-4ee7ab1f3460>:32: DeprecationWarning: getsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use getbbox or getlength instead.\n",
            "  if font.getsize(line + \" \" + word)[0] <= (image_width - left_margin - right_margin):\n",
            "<ipython-input-6-4ee7ab1f3460>:44: DeprecationWarning: getsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use getbbox or getlength instead.\n",
            "  line_height = font.getsize('A')[1]  # Height of a line of text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dount 실험"
      ],
      "metadata": {
        "id": "mD1c0GD_pmMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/clovaai/donut.git\n",
        "%cd donut"
      ],
      "metadata": {
        "id": "tXMYLzVPpoIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.25.1\n",
        "!pip install pytorch-lightning==1.6.4\n",
        "!pip install timm==0.5.4\n",
        "!pip install gradio\n",
        "!pip install donut-python"
      ],
      "metadata": {
        "id": "_D754Ti-pob1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이미지 넣고 실험"
      ],
      "metadata": {
        "id": "mgtuG9BVp7MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print ( \"CUDA 사용 가능:\" , torch.cuda.is_available())\n",
        "!nvcc --version\n",
        "# 이제 관련 파일과 라이브러리를 다운로드할 수 있습니다. 다음 코드 줄은 donut 라이브러리를 포함하여 모든 종속성을 설치해야 합니다\n",
        "#pip install donut-python.\n",
        "\n",
        "!git clone https://github.com/clovaai/donut.git\n",
        "!cd donut && pip install .\n",
        "# Making an inference using the CORD fine-tuned model\n",
        "# First, we’ll demonstrate basic usage of the model."
      ],
      "metadata": {
        "id": "NYk2UoP0p_Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from donut import DonutModel\n",
        "from PIL import Image\n",
        "\n",
        "model = DonutModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
        "if torch.cuda.is_available():\n",
        "    model.half()\n",
        "    device = torch.device(\"cuda\")\n",
        "    model.to(device)\n",
        "else:\n",
        "    model.encoder.to(torch.bfloat16)\n",
        "model.eval()\n",
        "image = Image.open(\"/content/test.PNG\")\n",
        "image.convert(\"RGB\")\n",
        "output = model.inference(image=image, prompt=\"<s_cord-v2>\")\n",
        "output"
      ],
      "metadata": {
        "id": "JEH_4GmYokZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 훈련"
      ],
      "metadata": {
        "id": "DZmDVGcfrVu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_folder, text_folder, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.text_folder = text_folder\n",
        "        self.image_names = os.listdir(image_folder)\n",
        "        self.text_names = os.listdir(text_folder)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.image_names[idx]\n",
        "        text_name = image_name.replace(\".jpg\", \".txt\")  # Assuming TXT files have matching names\n",
        "\n",
        "        image_path = os.path.join(self.image_folder, image_name)\n",
        "        text_path = os.path.join(self.text_folder, text_name)\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Apply transformations to convert the PIL image to a PyTorch tensor\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        with open(text_path, 'r') as f:\n",
        "            text_data = f.read()\n",
        "\n",
        "        return {'images': image, 'targets': text_data}"
      ],
      "metadata": {
        "id": "n0LaemNGrBpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths and other settings\n",
        "image_folder = '/content/jpg'\n",
        "text_folder = '/content/text'\n",
        "batch_size = 16\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 10\n",
        "desired_height = 800\n",
        "desired_width = 1200\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((desired_height, desired_width)),  # Resize images to a common size\n",
        "    transforms.ToTensor(),  # Converts PIL image to a PyTorch tensor\n",
        "    # Add any other transformations you need here\n",
        "])\n",
        "\n",
        "# Create the custom dataset with the defined transformations\n",
        "train_dataset = CustomDataset(image_folder, text_folder, transform=transform)\n",
        "\n",
        "# Create DataLoader for batching\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "Y9pBZW4fslXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from donut import DonutModel\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# 데이터셋과 DataLoader를 여기에 정의하세요\n",
        "# ...\n",
        "\n",
        "# CPU 또는 GPU에서 훈련할 device를 정의합니다\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 이미 정의하고 준비한 train_dataset을 가정합니다\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# DonutModel 및 다른 훈련 설정을 정의합니다\n",
        "model = DonutModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
        "model.to(device)  # 모델을 지정한 device로 이동합니다\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.MSELoss()  # 적절한 손실 함수를 사용하세요\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "# 훈련 루프\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_data_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 배치가 이미지와 다른 필요한 입력을 포함한다고 가정합니다\n",
        "        images = batch['images'].to(device)  # 이미지를 지정한 device로 이동합니다\n",
        "        targets = batch['targets']  # 타겟이 텍스트 데이터라고 가정합니다\n",
        "\n",
        "        # 텍스트 데이터를 전처리하여 'decoder_input_ids' 및 'decoder_labels'를 생성합니다\n",
        "        tokenizer = ...  # 토크나이저를 초기화합니다\n",
        "        inputs = tokenizer(targets, return_tensors='pt', padding='max_length', truncation=True, max_length=desired_max_length)\n",
        "\n",
        "        # 순방향 패스\n",
        "        outputs = model(encoder_input_ids=inputs['input_ids'].to(device),\n",
        "                        decoder_input_ids=inputs['input_ids'].to(device),  # 이를 적절하게 수정해야 합니다\n",
        "                        decoder_labels=inputs['input_ids'].to(device))  # 이를 적절하게 수정해야 합니다\n",
        "\n",
        "        # 손실 계산\n",
        "        loss = criterion(outputs, targets)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # 역전파 및 최적화\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    average_loss = total_loss / len(train_data_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")"
      ],
      "metadata": {
        "id": "UzJ57-4Cp438"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qe7ADgpOs2DU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}